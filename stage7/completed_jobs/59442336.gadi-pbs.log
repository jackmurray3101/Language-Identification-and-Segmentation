1.12.1+cu102
cuda:0
Trainable Parameters : 594696
Start training...
epoch 0, loss: 2.07, train 25.00%
epoch 0, loss: 2.01, train 17.50%
epoch 0, loss: 2.82, train 15.00%
epoch 0, loss: 2.51, train 16.25%
epoch 0, loss: 2.24, train 20.00%
epoch 0, loss: 2.64, train 18.33%
epoch 0, loss: 1.99, train 19.29%
epoch 0, loss: 2.13, train 17.50%
epoch 0, loss: 2.35, train 18.33%
epoch 0, loss: 2.02, train 21.00%
epoch 0, loss: 1.78, train 21.82%
epoch 0, loss: 1.69, train 24.17%
epoch 0, loss: 1.80, train 25.38%
epoch 0, loss: 2.14, train 25.71%
epoch 0, loss: 2.50, train 25.33%
epoch 0, loss: 1.55, train 26.88%
epoch 0, loss: 1.86, train 27.35%
epoch 0, loss: 2.22, train 27.22%
epoch 0, loss: 1.84, train 27.37%
epoch 0, loss: 1.71, train 27.75%
epoch 0, loss: 1.54, train 28.33%
epoch 0, loss: 1.56, train 28.86%
epoch 0, loss: 1.55, train 30.00%
epoch 0, loss: 1.17, train 31.04%
epoch 0, loss: 1.62, train 31.80%
epoch 0, loss: 1.99, train 31.54%
epoch 0, loss: 1.65, train 31.85%
epoch 0, loss: 1.54, train 32.50%
epoch 0, loss: 1.56, train 32.76%
epoch 0, loss: 1.46, train 33.50%
epoch 0, loss: 1.76, train 33.71%
epoch 0, loss: 1.23, train 34.53%
epoch 0, loss: 1.10, train 35.45%
epoch 0, loss: 1.34, train 35.88%
epoch 0, loss: 1.08, train 36.86%
epoch 0, loss: 1.24, train 37.50%
epoch 0, loss: 1.23, train 38.11%
epoch 0, loss: 1.31, train 38.55%
epoch 0, loss: 1.54, train 38.97%
epoch 0, loss: 1.22, train 39.50%
epoch 0, loss: 1.40, train 39.88%
epoch 0, loss: 1.40, train 40.36%
epoch 0, loss: 1.22, train 40.93%
epoch 0, loss: 1.58, train 41.02%
epoch 0, loss: 1.41, train 41.44%
epoch 0, loss: 2.03, train 41.20%
epoch 0, loss: 1.18, train 41.70%
epoch 0, loss: 1.29, train 41.88%
epoch 0, loss: 1.10, train 42.45%
epoch 0, loss: 1.64, train 42.40%
epoch 0, loss: 1.00, train 42.75%
epoch 0, loss: 1.36, train 42.98%
epoch 0, loss: 1.29, train 43.21%
epoch 0, loss: 1.11, train 43.61%
epoch 0, loss: 1.26, train 43.82%
epoch 0, loss: 1.09, train 44.20%
epoch 0, loss: 1.01, train 44.47%
epoch 0, loss: 1.27, train 44.66%
epoch 0, loss: 1.49, train 44.75%
epoch 0, loss: 0.75, train 45.25%
epoch 0, loss: 1.36, train 45.41%
epoch 0, loss: 1.52, train 45.56%
epoch 0, loss: 1.11, train 45.87%
epoch 0, loss: 1.24, train 46.02%
epoch 0, loss: 1.50, train 46.15%
epoch 0, loss: 0.91, train 46.36%
epoch 0, loss: 1.10, train 46.64%
epoch 0, loss: 1.35, train 46.84%
epoch 0, loss: 1.05, train 47.03%
epoch 0, loss: 1.39, train 47.21%
epoch 0, loss: 1.07, train 47.54%
epoch 0, loss: 1.05, train 47.85%
epoch 0, loss: 1.20, train 48.01%
epoch 0, loss: 0.74, train 48.45%
epoch 0, loss: 1.20, train 48.73%
epoch 0, loss: 0.91, train 48.95%
epoch 0, loss: 0.89, train 49.35%
epoch 0, loss: 1.10, train 49.36%
epoch 0, loss: 1.35, train 49.30%
epoch 0, loss: 1.55, train 49.44%
epoch 0, loss: 1.44, train 49.38%
epoch 0, loss: 0.92, train 49.70%
epoch 0, loss: 1.09, train 49.82%
epoch 0, loss: 0.86, train 50.12%
epoch 0, loss: 1.16, train 50.24%
epoch 0, loss: 1.26, train 50.23%
epoch 0, loss: 1.14, train 50.23%
epoch 0, loss: 0.97, train 50.28%
epoch 0, loss: 1.14, train 50.51%
epoch 0, loss: 1.41, train 50.56%
epoch 0, loss: 1.23, train 50.82%
epoch 0, loss: 0.57, train 51.36%
epoch 0, loss: 1.44, train 51.29%
epoch 0, loss: 1.07, train 51.28%
epoch 0, loss: 0.83, train 51.53%
epoch 0, loss: 1.09, train 51.61%
epoch 0, loss: 1.02, train 51.70%
epoch 0, loss: 1.80, train 51.58%
epoch 0, loss: 1.08, train 51.62%
epoch 0, loss: 1.02, train 51.85%
epoch 0, loss: 0.94, train 51.98%
epoch 0, loss: 1.21, train 52.16%
epoch 0, loss: 0.85, train 52.33%
epoch 0, loss: 1.26, train 52.31%
epoch 0, loss: 1.11, train 52.38%
epoch 0, loss: 1.86, train 52.31%
epoch 0, loss: 1.33, train 52.34%
epoch 0, loss: 1.31, train 52.41%
epoch 0, loss: 1.30, train 52.39%
epoch 0, loss: 1.56, train 52.32%
epoch 0, loss: 1.19, train 52.48%
epoch 0, loss: 0.82, train 52.46%
epoch 0, loss: 1.24, train 52.48%
epoch 0, loss: 1.32, train 52.50%
epoch 0, loss: 1.02, train 52.57%
epoch 0, loss: 1.74, train 52.59%
epoch 0, loss: 1.33, train 52.65%
epoch 0, loss: 1.60, train 52.67%
epoch 0, loss: 0.77, train 52.86%
epoch 0, loss: 1.07, train 52.96%
Epoch completed!
epoch 0, total signals 2400, average_loss_per_batch: 1.394982, train 52.96%
Validating
Val set size: 320, validation accuracy 70.94%
epoch 1, loss: 0.93, train 65.00%
epoch 1, loss: 0.58, train 77.50%
epoch 1, loss: 1.18, train 70.00%
epoch 1, loss: 1.06, train 68.75%
epoch 1, loss: 1.31, train 67.00%
epoch 1, loss: 1.01, train 67.50%
epoch 1, loss: 0.81, train 68.57%
epoch 1, loss: 0.77, train 69.38%
epoch 1, loss: 0.67, train 71.11%
epoch 1, loss: 0.58, train 72.50%
epoch 1, loss: 0.94, train 71.82%
epoch 1, loss: 1.10, train 70.00%
epoch 1, loss: 1.06, train 69.62%
epoch 1, loss: 0.68, train 70.00%
epoch 1, loss: 0.79, train 70.33%
epoch 1, loss: 1.04, train 70.00%
epoch 1, loss: 0.59, train 70.88%
epoch 1, loss: 0.99, train 70.28%
epoch 1, loss: 0.89, train 69.74%
epoch 1, loss: 0.51, train 70.75%
epoch 1, loss: 0.77, train 70.95%
epoch 1, loss: 0.76, train 71.14%
epoch 1, loss: 1.59, train 69.57%
epoch 1, loss: 0.69, train 70.21%
epoch 1, loss: 2.63, train 68.60%
epoch 1, loss: 0.50, train 69.42%
epoch 1, loss: 1.03, train 69.07%
epoch 1, loss: 0.54, train 69.82%
epoch 1, loss: 1.20, train 69.48%
epoch 1, loss: 0.67, train 69.83%
epoch 1, loss: 1.02, train 69.35%
epoch 1, loss: 1.47, train 69.06%
epoch 1, loss: 0.79, train 69.09%
epoch 1, loss: 1.19, train 68.82%
epoch 1, loss: 0.63, train 69.14%
epoch 1, loss: 0.68, train 69.58%
epoch 1, loss: 0.65, train 70.00%
epoch 1, loss: 0.82, train 70.13%
epoch 1, loss: 0.84, train 70.38%
epoch 1, loss: 0.61, train 71.12%
epoch 1, loss: 1.04, train 70.85%
epoch 1, loss: 1.16, train 70.83%
epoch 1, loss: 1.04, train 70.70%
epoch 1, loss: 0.74, train 71.02%
epoch 1, loss: 1.04, train 70.89%
epoch 1, loss: 0.61, train 71.09%
epoch 1, loss: 0.71, train 71.28%
epoch 1, loss: 0.52, train 71.56%
epoch 1, loss: 1.23, train 71.22%
epoch 1, loss: 1.25, train 70.80%
epoch 1, loss: 1.16, train 70.69%
epoch 1, loss: 0.75, train 70.77%
epoch 1, loss: 0.65, train 70.94%
epoch 1, loss: 0.98, train 70.93%
epoch 1, loss: 0.77, train 71.18%
epoch 1, loss: 0.97, train 71.16%
epoch 1, loss: 0.90, train 71.05%
epoch 1, loss: 1.43, train 70.60%
epoch 1, loss: 0.44, train 70.85%
epoch 1, loss: 0.70, train 70.92%
epoch 1, loss: 1.33, train 70.66%
epoch 1, loss: 1.28, train 70.56%
epoch 1, loss: 1.34, train 70.32%
epoch 1, loss: 0.97, train 70.31%
epoch 1, loss: 0.69, train 70.46%
epoch 1, loss: 0.82, train 70.53%
epoch 1, loss: 0.57, train 70.75%
epoch 1, loss: 0.65, train 70.88%
epoch 1, loss: 1.25, train 70.65%
epoch 1, loss: 1.31, train 70.43%
epoch 1, loss: 1.14, train 70.35%
epoch 1, loss: 0.66, train 70.49%
epoch 1, loss: 1.27, train 70.48%
epoch 1, loss: 0.79, train 70.61%
epoch 1, loss: 0.53, train 70.80%
epoch 1, loss: 1.15, train 70.66%
epoch 1, loss: 0.76, train 70.78%
epoch 1, loss: 0.76, train 70.77%
epoch 1, loss: 0.79, train 70.82%
epoch 1, loss: 0.86, train 70.81%
epoch 1, loss: 0.40, train 70.99%
epoch 1, loss: 1.18, train 70.73%
epoch 1, loss: 1.49, train 70.42%
epoch 1, loss: 0.83, train 70.36%
epoch 1, loss: 0.67, train 70.47%
epoch 1, loss: 1.10, train 70.47%
epoch 1, loss: 1.33, train 70.23%
epoch 1, loss: 0.73, train 70.34%
epoch 1, loss: 0.47, train 70.56%
epoch 1, loss: 1.08, train 70.56%
epoch 1, loss: 1.34, train 70.55%
epoch 1, loss: 1.18, train 70.43%
epoch 1, loss: 0.77, train 70.54%
epoch 1, loss: 1.03, train 70.43%
epoch 1, loss: 0.81, train 70.47%
epoch 1, loss: 0.50, train 70.73%
epoch 1, loss: 0.71, train 70.72%
epoch 1, loss: 0.33, train 70.92%
epoch 1, loss: 0.75, train 71.16%
epoch 1, loss: 1.05, train 71.15%
epoch 1, loss: 0.95, train 71.09%
epoch 1, loss: 0.64, train 71.08%
epoch 1, loss: 1.10, train 71.02%
epoch 1, loss: 0.63, train 71.11%
epoch 1, loss: 0.86, train 71.05%
epoch 1, loss: 0.79, train 71.13%
epoch 1, loss: 0.76, train 71.26%
epoch 1, loss: 1.02, train 71.16%
epoch 1, loss: 0.70, train 71.19%
epoch 1, loss: 0.62, train 71.27%
epoch 1, loss: 0.86, train 71.26%
epoch 1, loss: 0.62, train 71.29%
epoch 1, loss: 0.83, train 71.33%
epoch 1, loss: 0.86, train 71.45%
epoch 1, loss: 1.12, train 71.35%
epoch 1, loss: 0.92, train 71.21%
epoch 1, loss: 1.01, train 71.20%
epoch 1, loss: 0.92, train 71.14%
epoch 1, loss: 0.90, train 71.18%
epoch 1, loss: 0.87, train 71.12%
Epoch completed!
epoch 1, total signals 2400, average_loss_per_batch: 0.902763, train 71.12%
Validating
Val set size: 320, validation accuracy 78.12%
epoch 2, loss: 0.86, train 75.00%
epoch 2, loss: 0.75, train 75.00%
epoch 2, loss: 0.43, train 80.00%
epoch 2, loss: 0.63, train 78.75%
epoch 2, loss: 0.60, train 81.00%
epoch 2, loss: 0.45, train 82.50%
epoch 2, loss: 0.53, train 83.57%
epoch 2, loss: 0.76, train 83.12%
epoch 2, loss: 0.69, train 81.67%
epoch 2, loss: 0.58, train 82.00%
epoch 2, loss: 0.63, train 81.82%
epoch 2, loss: 0.86, train 80.42%
epoch 2, loss: 0.96, train 78.85%
epoch 2, loss: 1.23, train 76.43%
epoch 2, loss: 0.59, train 76.33%
epoch 2, loss: 0.59, train 76.88%
epoch 2, loss: 0.45, train 77.35%
epoch 2, loss: 0.69, train 76.94%
epoch 2, loss: 1.03, train 76.05%
epoch 2, loss: 0.72, train 76.00%
epoch 2, loss: 0.68, train 76.43%
epoch 2, loss: 0.36, train 77.27%
epoch 2, loss: 0.52, train 77.61%
epoch 2, loss: 0.39, train 78.12%
epoch 2, loss: 0.51, train 78.20%
epoch 2, loss: 0.39, train 78.46%
epoch 2, loss: 0.83, train 78.33%
epoch 2, loss: 0.66, train 78.21%
epoch 2, loss: 1.13, train 78.28%
epoch 2, loss: 0.93, train 77.83%
epoch 2, loss: 0.42, train 78.23%
epoch 2, loss: 0.45, train 78.59%
epoch 2, loss: 1.26, train 78.18%
epoch 2, loss: 0.57, train 78.53%
epoch 2, loss: 0.76, train 78.14%
epoch 2, loss: 0.63, train 78.19%
epoch 2, loss: 0.87, train 77.70%
epoch 2, loss: 0.92, train 77.37%
epoch 2, loss: 0.62, train 77.56%
epoch 2, loss: 0.68, train 77.75%
epoch 2, loss: 0.69, train 77.68%
epoch 2, loss: 1.01, train 77.26%
epoch 2, loss: 1.01, train 77.09%
epoch 2, loss: 0.63, train 76.82%
epoch 2, loss: 0.62, train 77.00%
epoch 2, loss: 0.85, train 76.74%
epoch 2, loss: 0.63, train 76.70%
epoch 2, loss: 0.65, train 76.67%
epoch 2, loss: 0.80, train 76.53%
epoch 2, loss: 0.51, train 76.50%
epoch 2, loss: 0.74, train 76.57%
epoch 2, loss: 0.80, train 76.44%
epoch 2, loss: 0.59, train 76.51%
epoch 2, loss: 1.10, train 76.39%
epoch 2, loss: 0.55, train 76.45%
epoch 2, loss: 1.00, train 76.07%
epoch 2, loss: 0.81, train 75.96%
epoch 2, loss: 0.80, train 76.03%
epoch 2, loss: 0.70, train 76.02%
epoch 2, loss: 1.04, train 75.83%
epoch 2, loss: 0.72, train 75.90%
epoch 2, loss: 0.83, train 75.73%
epoch 2, loss: 0.78, train 75.71%
epoch 2, loss: 0.63, train 75.78%
epoch 2, loss: 0.78, train 75.62%
epoch 2, loss: 0.62, train 75.76%
epoch 2, loss: 0.88, train 75.67%
epoch 2, loss: 1.46, train 75.44%
epoch 2, loss: 0.46, train 75.65%
epoch 2, loss: 1.32, train 75.36%
epoch 2, loss: 0.39, train 75.56%
epoch 2, loss: 0.82, train 75.56%
epoch 2, loss: 0.99, train 75.41%
epoch 2, loss: 0.74, train 75.41%
epoch 2, loss: 0.76, train 75.47%
epoch 2, loss: 0.52, train 75.53%
epoch 2, loss: 0.63, train 75.58%
epoch 2, loss: 0.67, train 75.58%
epoch 2, loss: 0.66, train 75.70%
epoch 2, loss: 0.42, train 75.88%
epoch 2, loss: 0.84, train 75.74%
epoch 2, loss: 0.58, train 75.73%
epoch 2, loss: 0.79, train 75.78%
epoch 2, loss: 0.29, train 76.01%
epoch 2, loss: 1.13, train 76.00%
epoch 2, loss: 0.53, train 76.10%
epoch 2, loss: 0.32, train 76.32%
epoch 2, loss: 0.86, train 76.36%
epoch 2, loss: 0.57, train 76.46%
epoch 2, loss: 0.58, train 76.44%
epoch 2, loss: 1.00, train 76.32%
epoch 2, loss: 0.60, train 76.36%
epoch 2, loss: 1.43, train 76.08%
epoch 2, loss: 1.28, train 75.85%
epoch 2, loss: 0.57, train 75.89%
epoch 2, loss: 0.46, train 75.99%
epoch 2, loss: 0.36, train 76.13%
epoch 2, loss: 0.66, train 76.17%
epoch 2, loss: 0.56, train 76.21%
epoch 2, loss: 0.67, train 76.30%
epoch 2, loss: 0.57, train 76.29%
epoch 2, loss: 1.24, train 76.08%
epoch 2, loss: 0.95, train 75.97%
epoch 2, loss: 0.44, train 76.06%
epoch 2, loss: 0.73, train 75.95%
epoch 2, loss: 0.46, train 76.04%
epoch 2, loss: 0.52, train 76.12%
epoch 2, loss: 0.59, train 76.25%
epoch 2, loss: 0.63, train 76.38%
epoch 2, loss: 0.38, train 76.50%
epoch 2, loss: 0.54, train 76.49%
epoch 2, loss: 0.44, train 76.52%
epoch 2, loss: 0.56, train 76.55%
epoch 2, loss: 0.90, train 76.58%
epoch 2, loss: 0.82, train 76.52%
epoch 2, loss: 0.46, train 76.51%
epoch 2, loss: 0.49, train 76.58%
epoch 2, loss: 0.46, train 76.69%
epoch 2, loss: 0.39, train 76.81%
epoch 2, loss: 0.82, train 76.79%
Epoch completed!
epoch 2, total signals 2400, average_loss_per_batch: 0.706153, train 76.79%
Validating
Val set size: 320, validation accuracy 77.81%
epoch 3, loss: 0.32, train 90.00%
epoch 3, loss: 0.48, train 82.50%
epoch 3, loss: 0.65, train 80.00%
epoch 3, loss: 0.45, train 82.50%
epoch 3, loss: 0.57, train 82.00%
epoch 3, loss: 0.44, train 81.67%
epoch 3, loss: 0.75, train 80.71%
epoch 3, loss: 0.44, train 81.25%
epoch 3, loss: 0.53, train 80.56%
epoch 3, loss: 0.43, train 81.50%
epoch 3, loss: 0.52, train 81.36%
epoch 3, loss: 0.56, train 80.42%
epoch 3, loss: 0.69, train 80.00%
epoch 3, loss: 0.90, train 78.57%
epoch 3, loss: 0.22, train 79.67%
epoch 3, loss: 0.63, train 78.44%
epoch 3, loss: 0.62, train 77.94%
epoch 3, loss: 0.87, train 77.78%
epoch 3, loss: 0.55, train 77.89%
epoch 3, loss: 0.61, train 77.75%
epoch 3, loss: 0.49, train 78.10%
epoch 3, loss: 0.36, train 78.41%
epoch 3, loss: 0.43, train 78.48%
epoch 3, loss: 0.55, train 78.75%
epoch 3, loss: 0.33, train 79.40%
epoch 3, loss: 0.98, train 79.23%
epoch 3, loss: 0.49, train 79.63%
epoch 3, loss: 0.57, train 79.82%
epoch 3, loss: 0.51, train 80.00%
epoch 3, loss: 0.74, train 79.83%
epoch 3, loss: 0.69, train 79.68%
epoch 3, loss: 0.41, train 80.00%
epoch 3, loss: 0.39, train 80.45%
epoch 3, loss: 0.81, train 80.29%
epoch 3, loss: 0.46, train 80.43%
epoch 3, loss: 0.44, train 80.56%
epoch 3, loss: 0.59, train 80.27%
epoch 3, loss: 0.44, train 80.39%
epoch 3, loss: 0.49, train 80.38%
epoch 3, loss: 0.80, train 80.25%
epoch 3, loss: 0.59, train 80.12%
epoch 3, loss: 0.41, train 80.36%
epoch 3, loss: 0.32, train 80.47%
epoch 3, loss: 0.92, train 80.23%
epoch 3, loss: 0.63, train 80.22%
epoch 3, loss: 0.94, train 79.78%
epoch 3, loss: 0.82, train 79.57%
epoch 3, loss: 0.59, train 79.48%
epoch 3, loss: 0.36, train 79.69%
epoch 3, loss: 0.88, train 79.70%
epoch 3, loss: 0.41, train 79.90%
epoch 3, loss: 0.55, train 79.81%
epoch 3, loss: 0.50, train 79.91%
epoch 3, loss: 0.63, train 79.91%
epoch 3, loss: 0.34, train 80.09%
epoch 3, loss: 0.58, train 80.18%
epoch 3, loss: 0.40, train 80.35%
epoch 3, loss: 0.57, train 80.34%
epoch 3, loss: 0.46, train 80.42%
epoch 3, loss: 0.75, train 80.25%
epoch 3, loss: 0.42, train 80.33%
epoch 3, loss: 0.95, train 80.16%
epoch 3, loss: 0.74, train 80.24%
epoch 3, loss: 0.60, train 80.16%
epoch 3, loss: 0.56, train 80.15%
epoch 3, loss: 0.41, train 80.23%
epoch 3, loss: 0.75, train 80.07%
epoch 3, loss: 0.77, train 79.85%
epoch 3, loss: 0.59, train 79.78%
epoch 3, loss: 0.55, train 79.86%
epoch 3, loss: 0.27, train 80.14%
epoch 3, loss: 0.78, train 79.93%
epoch 3, loss: 0.62, train 79.86%
epoch 3, loss: 0.59, train 79.86%
epoch 3, loss: 0.54, train 79.87%
epoch 3, loss: 0.95, train 79.61%
epoch 3, loss: 0.30, train 79.74%
epoch 3, loss: 0.54, train 79.87%
epoch 3, loss: 0.51, train 79.94%
epoch 3, loss: 0.26, train 80.12%
epoch 3, loss: 0.52, train 80.12%
epoch 3, loss: 0.36, train 80.18%
epoch 3, loss: 0.28, train 80.30%
epoch 3, loss: 0.59, train 80.12%
epoch 3, loss: 0.64, train 80.06%
epoch 3, loss: 0.64, train 80.00%
epoch 3, loss: 0.48, train 80.11%
epoch 3, loss: 0.41, train 80.17%
epoch 3, loss: 0.33, train 80.17%
epoch 3, loss: 0.61, train 80.11%
epoch 3, loss: 0.67, train 80.22%
epoch 3, loss: 0.71, train 80.16%
epoch 3, loss: 0.49, train 80.22%
epoch 3, loss: 0.29, train 80.37%
epoch 3, loss: 0.88, train 80.21%
epoch 3, loss: 0.66, train 80.26%
epoch 3, loss: 0.56, train 80.26%
epoch 3, loss: 0.41, train 80.36%
epoch 3, loss: 0.54, train 80.35%
epoch 3, loss: 0.52, train 80.30%
epoch 3, loss: 0.41, train 80.35%
epoch 3, loss: 0.82, train 80.25%
epoch 3, loss: 0.95, train 80.15%
epoch 3, loss: 0.59, train 80.19%
epoch 3, loss: 0.57, train 80.29%
epoch 3, loss: 0.57, train 80.24%
epoch 3, loss: 0.73, train 80.19%
epoch 3, loss: 1.05, train 80.00%
epoch 3, loss: 0.39, train 80.09%
epoch 3, loss: 0.57, train 80.09%
epoch 3, loss: 0.73, train 80.05%
epoch 3, loss: 0.53, train 79.91%
epoch 3, loss: 0.93, train 79.87%
epoch 3, loss: 0.99, train 79.69%
epoch 3, loss: 0.50, train 79.65%
epoch 3, loss: 1.07, train 79.57%
epoch 3, loss: 0.50, train 79.57%
epoch 3, loss: 1.56, train 79.19%
epoch 3, loss: 0.67, train 79.20%
epoch 3, loss: 0.72, train 79.21%
Epoch completed!
epoch 3, total signals 2400, average_loss_per_batch: 0.591654, train 79.21%
Validating
Val set size: 320, validation accuracy 73.44%
epoch 4, loss: 0.45, train 90.00%
epoch 4, loss: 0.62, train 82.50%
epoch 4, loss: 1.20, train 75.00%
epoch 4, loss: 0.39, train 77.50%
epoch 4, loss: 1.21, train 74.00%
epoch 4, loss: 0.46, train 75.83%
epoch 4, loss: 0.67, train 75.71%
epoch 4, loss: 1.22, train 72.50%
epoch 4, loss: 0.38, train 74.44%
epoch 4, loss: 0.26, train 76.50%
epoch 4, loss: 0.71, train 76.36%
epoch 4, loss: 0.36, train 77.50%
epoch 4, loss: 0.87, train 76.54%
epoch 4, loss: 0.51, train 77.14%
epoch 4, loss: 0.37, train 78.00%
epoch 4, loss: 0.28, train 79.38%
epoch 4, loss: 0.29, train 80.00%
epoch 4, loss: 0.32, train 80.56%
epoch 4, loss: 0.60, train 80.26%
epoch 4, loss: 0.44, train 80.25%
epoch 4, loss: 0.52, train 80.00%
epoch 4, loss: 1.06, train 79.55%
epoch 4, loss: 0.65, train 79.13%
epoch 4, loss: 0.44, train 79.38%
epoch 4, loss: 0.72, train 79.00%
epoch 4, loss: 0.36, train 79.42%
epoch 4, loss: 0.53, train 79.26%
epoch 4, loss: 0.60, train 79.46%
epoch 4, loss: 0.61, train 79.48%
epoch 4, loss: 0.75, train 79.17%
epoch 4, loss: 0.38, train 79.68%
epoch 4, loss: 1.04, train 79.06%
epoch 4, loss: 0.88, train 79.09%
epoch 4, loss: 0.41, train 79.26%
epoch 4, loss: 0.68, train 78.86%
epoch 4, loss: 0.58, train 79.03%
epoch 4, loss: 0.56, train 79.05%
epoch 4, loss: 0.71, train 78.95%
epoch 4, loss: 0.23, train 79.36%
epoch 4, loss: 0.61, train 79.25%
epoch 4, loss: 0.37, train 79.39%
epoch 4, loss: 0.43, train 79.52%
epoch 4, loss: 0.51, train 79.42%
epoch 4, loss: 0.85, train 79.09%
epoch 4, loss: 0.49, train 79.22%
epoch 4, loss: 0.69, train 79.13%
epoch 4, loss: 0.52, train 79.04%
epoch 4, loss: 0.67, train 79.06%
epoch 4, loss: 0.71, train 78.88%
epoch 4, loss: 0.66, train 78.80%
epoch 4, loss: 0.51, train 78.73%
epoch 4, loss: 0.83, train 78.56%
epoch 4, loss: 0.90, train 78.30%
epoch 4, loss: 0.66, train 78.33%
epoch 4, loss: 0.65, train 78.36%
epoch 4, loss: 0.72, train 78.21%
epoch 4, loss: 0.37, train 78.42%
epoch 4, loss: 0.72, train 78.53%
epoch 4, loss: 0.61, train 78.47%
epoch 4, loss: 0.62, train 78.33%
epoch 4, loss: 0.63, train 78.36%
epoch 4, loss: 0.65, train 78.55%
epoch 4, loss: 0.59, train 78.41%
epoch 4, loss: 0.51, train 78.36%
epoch 4, loss: 0.77, train 78.23%
epoch 4, loss: 0.40, train 78.48%
epoch 4, loss: 0.59, train 78.36%
epoch 4, loss: 0.30, train 78.53%
epoch 4, loss: 0.41, train 78.62%
epoch 4, loss: 0.40, train 78.86%
epoch 4, loss: 0.57, train 78.87%
epoch 4, loss: 0.45, train 79.03%
epoch 4, loss: 0.46, train 79.11%
epoch 4, loss: 0.74, train 78.92%
epoch 4, loss: 0.57, train 78.87%
epoch 4, loss: 0.77, train 78.95%
epoch 4, loss: 0.58, train 78.96%
epoch 4, loss: 1.10, train 78.72%
epoch 4, loss: 0.79, train 78.67%
epoch 4, loss: 0.50, train 78.75%
epoch 4, loss: 0.65, train 78.64%
epoch 4, loss: 0.46, train 78.78%
epoch 4, loss: 0.60, train 78.80%
epoch 4, loss: 0.60, train 78.87%
epoch 4, loss: 0.42, train 78.94%
epoch 4, loss: 0.75, train 79.01%
epoch 4, loss: 0.52, train 79.02%
epoch 4, loss: 0.43, train 79.15%
epoch 4, loss: 0.89, train 79.04%
epoch 4, loss: 0.82, train 79.00%
epoch 4, loss: 0.75, train 78.90%
epoch 4, loss: 0.41, train 79.08%
epoch 4, loss: 0.81, train 79.09%
epoch 4, loss: 1.41, train 78.94%
epoch 4, loss: 0.40, train 79.00%
epoch 4, loss: 0.61, train 78.80%
epoch 4, loss: 0.65, train 78.76%
epoch 4, loss: 0.70, train 78.72%
epoch 4, loss: 0.65, train 78.84%
epoch 4, loss: 0.44, train 78.90%
epoch 4, loss: 0.84, train 78.81%
epoch 4, loss: 0.56, train 78.82%
epoch 4, loss: 0.49, train 78.74%
epoch 4, loss: 0.67, train 78.80%
epoch 4, loss: 0.51, train 78.86%
epoch 4, loss: 1.02, train 78.73%
epoch 4, loss: 0.35, train 78.88%
epoch 4, loss: 0.59, train 78.94%
epoch 4, loss: 0.32, train 79.04%
epoch 4, loss: 0.59, train 79.09%
epoch 4, loss: 0.82, train 79.05%
epoch 4, loss: 0.22, train 79.20%
epoch 4, loss: 0.67, train 79.25%
epoch 4, loss: 0.83, train 79.21%
epoch 4, loss: 1.11, train 79.04%
epoch 4, loss: 0.30, train 79.14%
epoch 4, loss: 0.78, train 79.06%
epoch 4, loss: 0.86, train 78.94%
epoch 4, loss: 0.63, train 78.99%
epoch 4, loss: 0.54, train 79.00%
Epoch completed!
epoch 4, total signals 2400, average_loss_per_batch: 0.616065, train 79.00%
Validating
Val set size: 320, validation accuracy 72.81%
epoch 5, loss: 0.42, train 85.00%
epoch 5, loss: 0.71, train 80.00%
epoch 5, loss: 0.46, train 78.33%
epoch 5, loss: 0.30, train 82.50%
epoch 5, loss: 0.47, train 83.00%
epoch 5, loss: 0.28, train 84.17%
epoch 5, loss: 1.08, train 81.43%
epoch 5, loss: 0.44, train 82.50%
epoch 5, loss: 0.63, train 82.22%
epoch 5, loss: 0.36, train 82.50%
epoch 5, loss: 0.70, train 81.36%
epoch 5, loss: 0.54, train 81.67%
epoch 5, loss: 0.37, train 81.92%
epoch 5, loss: 0.61, train 81.07%
epoch 5, loss: 0.69, train 80.33%
epoch 5, loss: 0.57, train 80.31%
epoch 5, loss: 0.39, train 80.88%
epoch 5, loss: 0.84, train 80.56%
epoch 5, loss: 0.62, train 80.53%
epoch 5, loss: 0.46, train 80.75%
epoch 5, loss: 0.71, train 80.48%
epoch 5, loss: 0.46, train 80.45%
epoch 5, loss: 0.59, train 80.43%
epoch 5, loss: 0.89, train 80.00%
epoch 5, loss: 0.41, train 80.20%
epoch 5, loss: 0.56, train 80.19%
epoch 5, loss: 0.61, train 80.19%
epoch 5, loss: 0.75, train 79.82%
epoch 5, loss: 0.52, train 79.83%
epoch 5, loss: 0.91, train 79.33%
epoch 5, loss: 0.42, train 79.52%
epoch 5, loss: 0.60, train 79.53%
epoch 5, loss: 0.60, train 79.24%
epoch 5, loss: 0.40, train 79.12%
epoch 5, loss: 0.58, train 79.14%
epoch 5, loss: 0.61, train 79.03%
epoch 5, loss: 0.31, train 79.32%
epoch 5, loss: 0.45, train 79.47%
epoch 5, loss: 0.47, train 79.49%
epoch 5, loss: 0.53, train 79.62%
epoch 5, loss: 0.21, train 80.12%
epoch 5, loss: 0.76, train 79.88%
epoch 5, loss: 0.70, train 79.65%
epoch 5, loss: 1.10, train 79.20%
epoch 5, loss: 0.43, train 79.33%
epoch 5, loss: 0.43, train 79.46%
epoch 5, loss: 0.82, train 79.15%
epoch 5, loss: 0.41, train 79.38%
epoch 5, loss: 1.07, train 79.08%
epoch 5, loss: 1.09, train 78.80%
epoch 5, loss: 0.38, train 79.02%
epoch 5, loss: 0.62, train 78.85%
epoch 5, loss: 0.28, train 79.06%
epoch 5, loss: 0.66, train 79.17%
epoch 5, loss: 0.36, train 79.45%
epoch 5, loss: 0.45, train 79.64%
epoch 5, loss: 0.65, train 79.56%
epoch 5, loss: 0.56, train 79.40%
epoch 5, loss: 0.72, train 79.07%
epoch 5, loss: 0.86, train 79.08%
epoch 5, loss: 0.30, train 79.26%
epoch 5, loss: 0.27, train 79.52%
epoch 5, loss: 0.52, train 79.52%
epoch 5, loss: 0.53, train 79.61%
epoch 5, loss: 0.42, train 79.62%
epoch 5, loss: 0.56, train 79.70%
epoch 5, loss: 0.48, train 79.85%
epoch 5, loss: 0.99, train 79.63%
epoch 5, loss: 0.30, train 79.86%
epoch 5, loss: 0.43, train 79.86%
epoch 5, loss: 0.67, train 79.79%
epoch 5, loss: 0.85, train 79.65%
epoch 5, loss: 0.59, train 79.66%
epoch 5, loss: 0.56, train 79.73%
epoch 5, loss: 0.64, train 79.80%
epoch 5, loss: 0.75, train 79.80%
epoch 5, loss: 0.73, train 79.55%
epoch 5, loss: 0.74, train 79.42%
epoch 5, loss: 0.44, train 79.49%
epoch 5, loss: 0.27, train 79.62%
epoch 5, loss: 0.76, train 79.44%
epoch 5, loss: 0.44, train 79.51%
epoch 5, loss: 0.33, train 79.58%
epoch 5, loss: 0.96, train 79.52%
epoch 5, loss: 0.76, train 79.53%
epoch 5, loss: 0.42, train 79.59%
epoch 5, loss: 0.87, train 79.48%
epoch 5, loss: 0.69, train 79.49%
epoch 5, loss: 0.28, train 79.72%
epoch 5, loss: 0.61, train 79.83%
epoch 5, loss: 0.59, train 79.73%
epoch 5, loss: 0.91, train 79.57%
epoch 5, loss: 0.62, train 79.62%
epoch 5, loss: 0.67, train 79.52%
epoch 5, loss: 0.50, train 79.53%
epoch 5, loss: 0.80, train 79.43%
epoch 5, loss: 0.54, train 79.48%
epoch 5, loss: 0.55, train 79.54%
epoch 5, loss: 0.48, train 79.49%
epoch 5, loss: 0.49, train 79.50%
epoch 5, loss: 0.53, train 79.55%
epoch 5, loss: 1.11, train 79.46%
epoch 5, loss: 0.73, train 79.42%
epoch 5, loss: 0.86, train 79.33%
epoch 5, loss: 0.32, train 79.48%
epoch 5, loss: 0.52, train 79.53%
epoch 5, loss: 0.65, train 79.44%
epoch 5, loss: 0.57, train 79.35%
epoch 5, loss: 1.61, train 79.08%
epoch 5, loss: 0.29, train 79.27%
epoch 5, loss: 0.90, train 79.23%
epoch 5, loss: 0.66, train 79.24%
epoch 5, loss: 0.44, train 79.25%
epoch 5, loss: 0.70, train 79.25%
epoch 5, loss: 0.62, train 79.30%
epoch 5, loss: 0.77, train 79.31%
epoch 5, loss: 0.75, train 79.32%
epoch 5, loss: 0.62, train 79.41%
epoch 5, loss: 0.65, train 79.37%
epoch 5, loss: 0.40, train 79.50%
Epoch completed!
epoch 5, total signals 2400, average_loss_per_batch: 0.599029, train 79.50%
Validating
Val set size: 320, validation accuracy 81.56%
epoch 6, loss: 0.85, train 65.00%
epoch 6, loss: 0.84, train 70.00%
epoch 6, loss: 0.38, train 75.00%
epoch 6, loss: 0.57, train 75.00%
epoch 6, loss: 0.20, train 79.00%
epoch 6, loss: 0.27, train 81.67%
epoch 6, loss: 0.75, train 80.00%
epoch 6, loss: 0.48, train 80.00%
epoch 6, loss: 0.67, train 80.00%
epoch 6, loss: 0.33, train 81.50%
epoch 6, loss: 0.40, train 82.73%
epoch 6, loss: 0.52, train 82.50%
epoch 6, loss: 0.51, train 82.69%
epoch 6, loss: 0.74, train 81.79%
epoch 6, loss: 0.45, train 82.00%
epoch 6, loss: 0.30, train 82.50%
epoch 6, loss: 0.24, train 83.53%
epoch 6, loss: 0.42, train 83.33%
epoch 6, loss: 0.92, train 82.63%
epoch 6, loss: 0.24, train 83.25%
epoch 6, loss: 0.59, train 83.33%
epoch 6, loss: 0.23, train 83.86%
epoch 6, loss: 0.39, train 84.13%
epoch 6, loss: 0.23, train 84.58%
epoch 6, loss: 0.33, train 84.60%
epoch 6, loss: 0.30, train 84.81%
epoch 6, loss: 0.78, train 84.44%
epoch 6, loss: 0.78, train 84.29%
epoch 6, loss: 0.37, train 84.31%
epoch 6, loss: 0.91, train 83.67%
epoch 6, loss: 0.51, train 83.71%
epoch 6, loss: 0.45, train 83.91%
epoch 6, loss: 0.48, train 83.94%
epoch 6, loss: 0.75, train 83.82%
epoch 6, loss: 0.25, train 84.00%
epoch 6, loss: 0.41, train 84.17%
epoch 6, loss: 0.66, train 83.78%
epoch 6, loss: 0.23, train 84.08%
epoch 6, loss: 0.31, train 84.23%
epoch 6, loss: 0.34, train 84.38%
epoch 6, loss: 0.19, train 84.63%
epoch 6, loss: 0.36, train 84.76%
epoch 6, loss: 0.48, train 84.53%
epoch 6, loss: 0.83, train 84.09%
epoch 6, loss: 0.57, train 84.11%
epoch 6, loss: 0.79, train 83.91%
epoch 6, loss: 0.69, train 83.72%
epoch 6, loss: 0.78, train 83.44%
epoch 6, loss: 0.70, train 83.37%
epoch 6, loss: 0.35, train 83.50%
epoch 6, loss: 0.58, train 83.53%
epoch 6, loss: 0.75, train 83.27%
epoch 6, loss: 0.57, train 83.11%
epoch 6, loss: 0.47, train 82.96%
epoch 6, loss: 0.71, train 82.82%
epoch 6, loss: 0.61, train 82.68%
epoch 6, loss: 0.46, train 82.63%
epoch 6, loss: 0.34, train 82.76%
epoch 6, loss: 0.72, train 82.71%
epoch 6, loss: 0.64, train 82.50%
epoch 6, loss: 0.53, train 82.54%
epoch 6, loss: 0.42, train 82.58%
epoch 6, loss: 0.72, train 82.30%
epoch 6, loss: 0.45, train 82.42%
epoch 6, loss: 0.44, train 82.46%
epoch 6, loss: 0.93, train 82.12%
epoch 6, loss: 0.29, train 82.31%
epoch 6, loss: 0.33, train 82.43%
epoch 6, loss: 0.43, train 82.54%
epoch 6, loss: 0.37, train 82.64%
epoch 6, loss: 0.80, train 82.39%
epoch 6, loss: 0.39, train 82.36%
epoch 6, loss: 0.50, train 82.26%
epoch 6, loss: 0.71, train 82.23%
epoch 6, loss: 0.80, train 82.07%
epoch 6, loss: 2.73, train 81.45%
epoch 6, loss: 0.40, train 81.56%
epoch 6, loss: 0.39, train 81.67%
epoch 6, loss: 0.15, train 81.90%
epoch 6, loss: 0.82, train 81.69%
epoch 6, loss: 0.56, train 81.73%
epoch 6, loss: 0.67, train 81.65%
epoch 6, loss: 0.70, train 81.63%
epoch 6, loss: 1.67, train 81.25%
epoch 6, loss: 0.64, train 81.24%
epoch 6, loss: 0.47, train 81.28%
epoch 6, loss: 0.49, train 81.26%
epoch 6, loss: 0.62, train 81.19%
epoch 6, loss: 0.60, train 81.07%
epoch 6, loss: 0.52, train 81.00%
epoch 6, loss: 0.57, train 81.04%
epoch 6, loss: 0.81, train 80.87%
epoch 6, loss: 0.99, train 80.81%
epoch 6, loss: 1.08, train 80.59%
epoch 6, loss: 0.51, train 80.79%
epoch 6, loss: 0.58, train 80.68%
epoch 6, loss: 0.43, train 80.82%
epoch 6, loss: 0.84, train 80.66%
epoch 6, loss: 0.69, train 80.61%
epoch 6, loss: 0.54, train 80.65%
epoch 6, loss: 0.97, train 80.64%
epoch 6, loss: 0.36, train 80.74%
epoch 6, loss: 0.43, train 80.87%
epoch 6, loss: 0.59, train 80.87%
epoch 6, loss: 0.81, train 80.86%
epoch 6, loss: 0.76, train 80.71%
epoch 6, loss: 0.62, train 80.61%
epoch 6, loss: 0.57, train 80.65%
epoch 6, loss: 0.73, train 80.60%
epoch 6, loss: 1.01, train 80.41%
epoch 6, loss: 0.68, train 80.36%
epoch 6, loss: 0.32, train 80.49%
epoch 6, loss: 0.36, train 80.58%
epoch 6, loss: 1.36, train 80.35%
epoch 6, loss: 0.63, train 80.30%
epoch 6, loss: 0.56, train 80.26%
epoch 6, loss: 0.56, train 80.26%
epoch 6, loss: 0.53, train 80.17%
epoch 6, loss: 0.64, train 80.17%
epoch 6, loss: 0.38, train 80.25%
Epoch completed!
epoch 6, total signals 2400, average_loss_per_batch: 0.586676, train 80.25%
Validating
Val set size: 320, validation accuracy 75.31%
epoch 7, loss: 0.69, train 75.00%
epoch 7, loss: 0.48, train 82.50%
epoch 7, loss: 0.70, train 78.33%
epoch 7, loss: 0.43, train 81.25%
epoch 7, loss: 0.41, train 83.00%
epoch 7, loss: 0.35, train 83.33%
epoch 7, loss: 0.28, train 85.00%
epoch 7, loss: 0.49, train 85.00%
epoch 7, loss: 0.44, train 85.56%
epoch 7, loss: 0.40, train 86.00%
epoch 7, loss: 0.61, train 85.45%
epoch 7, loss: 0.45, train 85.83%
epoch 7, loss: 0.38, train 85.38%
epoch 7, loss: 0.30, train 86.07%
epoch 7, loss: 0.44, train 86.00%
epoch 7, loss: 0.47, train 85.94%
epoch 7, loss: 0.58, train 85.29%
epoch 7, loss: 0.27, train 85.83%
epoch 7, loss: 0.61, train 85.00%
epoch 7, loss: 0.27, train 85.00%
epoch 7, loss: 0.42, train 85.24%
epoch 7, loss: 0.35, train 85.45%
epoch 7, loss: 0.60, train 85.43%
epoch 7, loss: 0.81, train 84.79%
epoch 7, loss: 0.33, train 85.00%
epoch 7, loss: 1.21, train 83.65%
epoch 7, loss: 0.46, train 83.52%
epoch 7, loss: 0.39, train 83.75%
epoch 7, loss: 0.30, train 83.97%
epoch 7, loss: 0.60, train 84.17%
epoch 7, loss: 0.33, train 84.52%
epoch 7, loss: 0.26, train 85.00%
epoch 7, loss: 0.35, train 85.30%
epoch 7, loss: 0.70, train 85.00%
epoch 7, loss: 0.62, train 84.43%
epoch 7, loss: 0.38, train 84.58%
epoch 7, loss: 0.49, train 84.46%
epoch 7, loss: 0.31, train 84.61%
epoch 7, loss: 0.26, train 84.87%
epoch 7, loss: 0.32, train 85.12%
epoch 7, loss: 0.25, train 85.37%
epoch 7, loss: 0.49, train 85.24%
epoch 7, loss: 0.42, train 85.35%
epoch 7, loss: 0.69, train 85.34%
epoch 7, loss: 0.51, train 85.33%
epoch 7, loss: 0.76, train 85.33%
epoch 7, loss: 0.35, train 85.53%
epoch 7, loss: 0.44, train 85.52%
epoch 7, loss: 0.88, train 85.00%
epoch 7, loss: 0.56, train 84.80%
epoch 7, loss: 0.47, train 84.80%
epoch 7, loss: 0.49, train 84.81%
epoch 7, loss: 0.92, train 84.62%
epoch 7, loss: 0.66, train 84.44%
epoch 7, loss: 0.31, train 84.45%
epoch 7, loss: 0.58, train 84.55%
epoch 7, loss: 0.78, train 84.39%
epoch 7, loss: 0.54, train 84.31%
epoch 7, loss: 0.50, train 84.32%
epoch 7, loss: 0.44, train 84.33%
epoch 7, loss: 0.32, train 84.43%
epoch 7, loss: 0.47, train 84.44%
epoch 7, loss: 0.68, train 84.29%
epoch 7, loss: 0.24, train 84.45%
epoch 7, loss: 0.80, train 84.23%
epoch 7, loss: 0.52, train 84.24%
epoch 7, loss: 0.75, train 84.18%
epoch 7, loss: 0.43, train 84.26%
epoch 7, loss: 0.35, train 84.35%
epoch 7, loss: 0.16, train 84.57%
epoch 7, loss: 0.47, train 84.58%
epoch 7, loss: 0.34, train 84.58%
epoch 7, loss: 0.48, train 84.52%
epoch 7, loss: 0.78, train 84.39%
epoch 7, loss: 0.26, train 84.53%
epoch 7, loss: 0.54, train 84.34%
epoch 7, loss: 0.35, train 84.48%
epoch 7, loss: 0.63, train 84.29%
epoch 7, loss: 0.85, train 84.11%
epoch 7, loss: 0.73, train 83.88%
epoch 7, loss: 0.27, train 84.01%
epoch 7, loss: 0.28, train 84.15%
epoch 7, loss: 0.64, train 84.22%
epoch 7, loss: 0.68, train 84.29%
epoch 7, loss: 0.49, train 84.24%
epoch 7, loss: 0.40, train 84.30%
epoch 7, loss: 0.56, train 84.25%
epoch 7, loss: 0.60, train 84.15%
epoch 7, loss: 0.34, train 84.33%
epoch 7, loss: 0.34, train 84.39%
epoch 7, loss: 0.79, train 84.23%
epoch 7, loss: 0.19, train 84.40%
epoch 7, loss: 0.29, train 84.41%
epoch 7, loss: 0.28, train 84.52%
epoch 7, loss: 0.88, train 84.32%
epoch 7, loss: 0.48, train 84.32%
epoch 7, loss: 0.51, train 84.33%
epoch 7, loss: 0.73, train 84.29%
epoch 7, loss: 0.45, train 84.29%
epoch 7, loss: 0.34, train 84.40%
epoch 7, loss: 0.68, train 84.26%
epoch 7, loss: 0.31, train 84.31%
epoch 7, loss: 0.33, train 84.37%
epoch 7, loss: 0.17, train 84.47%
epoch 7, loss: 0.39, train 84.52%
epoch 7, loss: 0.26, train 84.62%
epoch 7, loss: 0.59, train 84.53%
epoch 7, loss: 0.52, train 84.44%
epoch 7, loss: 0.22, train 84.54%
epoch 7, loss: 0.54, train 84.50%
epoch 7, loss: 0.42, train 84.50%
epoch 7, loss: 0.34, train 84.51%
epoch 7, loss: 0.82, train 84.38%
epoch 7, loss: 1.04, train 84.21%
epoch 7, loss: 0.44, train 84.22%
epoch 7, loss: 0.89, train 84.09%
epoch 7, loss: 0.64, train 84.02%
epoch 7, loss: 0.71, train 83.90%
epoch 7, loss: 0.73, train 83.91%
epoch 7, loss: 0.38, train 84.00%
Epoch completed!
epoch 7, total signals 2400, average_loss_per_batch: 0.497261, train 84.00%
Validating
Val set size: 320, validation accuracy 75.62%
epoch 8, loss: 0.57, train 80.00%
epoch 8, loss: 0.60, train 75.00%
epoch 8, loss: 0.28, train 80.00%
epoch 8, loss: 0.33, train 81.25%
epoch 8, loss: 0.51, train 83.00%
epoch 8, loss: 0.24, train 85.00%
epoch 8, loss: 0.49, train 84.29%
epoch 8, loss: 0.65, train 83.12%
epoch 8, loss: 0.43, train 82.78%
epoch 8, loss: 0.50, train 82.50%
epoch 8, loss: 0.57, train 82.27%
epoch 8, loss: 0.31, train 82.92%
epoch 8, loss: 0.46, train 83.08%
epoch 8, loss: 0.32, train 82.86%
epoch 8, loss: 0.34, train 83.00%
epoch 8, loss: 0.51, train 83.44%
epoch 8, loss: 0.31, train 83.53%
epoch 8, loss: 0.57, train 83.33%
epoch 8, loss: 0.48, train 83.42%
epoch 8, loss: 0.18, train 84.00%
epoch 8, loss: 0.23, train 84.52%
epoch 8, loss: 0.49, train 84.32%
epoch 8, loss: 0.43, train 84.13%
epoch 8, loss: 0.34, train 84.17%
epoch 8, loss: 0.53, train 83.80%
epoch 8, loss: 0.55, train 83.46%
epoch 8, loss: 0.50, train 83.52%
epoch 8, loss: 0.36, train 83.75%
epoch 8, loss: 0.29, train 83.97%
epoch 8, loss: 0.42, train 84.00%
epoch 8, loss: 0.39, train 84.19%
epoch 8, loss: 0.73, train 84.22%
epoch 8, loss: 0.23, train 84.39%
epoch 8, loss: 0.70, train 84.26%
epoch 8, loss: 0.26, train 84.43%
epoch 8, loss: 0.52, train 84.31%
epoch 8, loss: 0.34, train 84.32%
epoch 8, loss: 0.83, train 83.68%
epoch 8, loss: 0.12, train 84.10%
epoch 8, loss: 0.33, train 84.38%
epoch 8, loss: 0.31, train 84.63%
epoch 8, loss: 0.44, train 84.64%
epoch 8, loss: 0.68, train 84.30%
epoch 8, loss: 0.26, train 84.32%
epoch 8, loss: 0.39, train 84.33%
epoch 8, loss: 0.38, train 84.35%
epoch 8, loss: 0.50, train 84.26%
epoch 8, loss: 1.03, train 83.96%
epoch 8, loss: 0.52, train 83.98%
epoch 8, loss: 0.34, train 84.10%
epoch 8, loss: 0.42, train 84.12%
epoch 8, loss: 0.67, train 84.13%
epoch 8, loss: 0.89, train 83.77%
epoch 8, loss: 0.43, train 83.80%
epoch 8, loss: 0.24, train 83.91%
epoch 8, loss: 0.47, train 83.93%
epoch 8, loss: 0.60, train 83.77%
epoch 8, loss: 0.58, train 83.45%
epoch 8, loss: 0.73, train 83.22%
epoch 8, loss: 0.51, train 83.17%
epoch 8, loss: 0.66, train 83.20%
epoch 8, loss: 0.33, train 83.31%
epoch 8, loss: 0.51, train 83.33%
epoch 8, loss: 0.74, train 83.20%
epoch 8, loss: 0.25, train 83.31%
epoch 8, loss: 0.94, train 83.03%
epoch 8, loss: 0.41, train 82.91%
epoch 8, loss: 0.67, train 82.79%
epoch 8, loss: 0.17, train 83.04%
epoch 8, loss: 0.36, train 83.21%
epoch 8, loss: 0.62, train 83.24%
epoch 8, loss: 0.42, train 83.26%
epoch 8, loss: 0.32, train 83.36%
epoch 8, loss: 0.62, train 83.38%
epoch 8, loss: 0.90, train 83.27%
epoch 8, loss: 0.34, train 83.36%
epoch 8, loss: 0.30, train 83.51%
epoch 8, loss: 0.38, train 83.53%
epoch 8, loss: 0.62, train 83.54%
epoch 8, loss: 0.45, train 83.56%
epoch 8, loss: 0.20, train 83.77%
epoch 8, loss: 0.80, train 83.66%
epoch 8, loss: 0.47, train 83.73%
epoch 8, loss: 0.39, train 83.81%
epoch 8, loss: 0.59, train 83.59%
epoch 8, loss: 0.29, train 83.60%
epoch 8, loss: 0.33, train 83.62%
epoch 8, loss: 0.73, train 83.58%
epoch 8, loss: 0.48, train 83.54%
epoch 8, loss: 0.17, train 83.67%
epoch 8, loss: 0.89, train 83.57%
epoch 8, loss: 0.60, train 83.64%
epoch 8, loss: 0.47, train 83.71%
epoch 8, loss: 0.88, train 83.62%
epoch 8, loss: 0.38, train 83.58%
epoch 8, loss: 0.68, train 83.44%
epoch 8, loss: 0.51, train 83.45%
epoch 8, loss: 0.39, train 83.47%
epoch 8, loss: 0.48, train 83.43%
epoch 8, loss: 0.46, train 83.45%
epoch 8, loss: 1.05, train 83.27%
epoch 8, loss: 0.41, train 83.28%
epoch 8, loss: 0.94, train 83.20%
epoch 8, loss: 0.52, train 83.17%
epoch 8, loss: 0.33, train 83.14%
epoch 8, loss: 0.72, train 83.07%
epoch 8, loss: 0.83, train 82.94%
epoch 8, loss: 0.58, train 82.87%
epoch 8, loss: 0.62, train 82.84%
epoch 8, loss: 0.70, train 82.73%
epoch 8, loss: 1.10, train 82.52%
epoch 8, loss: 0.49, train 82.50%
epoch 8, loss: 0.66, train 82.43%
epoch 8, loss: 0.53, train 82.41%
epoch 8, loss: 0.32, train 82.48%
epoch 8, loss: 0.48, train 82.50%
epoch 8, loss: 0.32, train 82.61%
epoch 8, loss: 0.50, train 82.58%
epoch 8, loss: 0.54, train 82.52%
epoch 8, loss: 0.22, train 82.58%
Epoch completed!
epoch 8, total signals 2400, average_loss_per_batch: 0.497512, train 82.58%
Validating
Val set size: 320, validation accuracy 80.00%
epoch 9, loss: 0.25, train 85.00%
epoch 9, loss: 0.59, train 77.50%
epoch 9, loss: 0.41, train 80.00%
epoch 9, loss: 0.22, train 83.75%
epoch 9, loss: 0.23, train 87.00%
epoch 9, loss: 0.34, train 87.50%
epoch 9, loss: 0.43, train 87.14%
epoch 9, loss: 0.34, train 86.88%
epoch 9, loss: 0.26, train 87.22%
epoch 9, loss: 0.34, train 87.00%
epoch 9, loss: 0.41, train 86.36%
epoch 9, loss: 0.34, train 86.25%
epoch 9, loss: 0.35, train 86.54%
epoch 9, loss: 0.28, train 87.14%
epoch 9, loss: 0.29, train 87.67%
epoch 9, loss: 0.19, train 88.12%
epoch 9, loss: 1.24, train 85.59%
epoch 9, loss: 0.92, train 84.44%
epoch 9, loss: 0.46, train 84.21%
epoch 9, loss: 0.24, train 84.75%
epoch 9, loss: 0.45, train 84.52%
epoch 9, loss: 0.39, train 84.55%
epoch 9, loss: 0.71, train 84.35%
epoch 9, loss: 0.47, train 84.38%
epoch 9, loss: 0.34, train 84.80%
epoch 9, loss: 0.14, train 85.38%
epoch 9, loss: 0.57, train 85.00%
epoch 9, loss: 0.71, train 84.46%
epoch 9, loss: 0.35, train 84.66%
epoch 9, loss: 0.59, train 84.50%
epoch 9, loss: 0.65, train 84.19%
epoch 9, loss: 0.23, train 84.53%
epoch 9, loss: 0.70, train 84.24%
epoch 9, loss: 0.38, train 84.26%
epoch 9, loss: 0.54, train 84.00%
epoch 9, loss: 0.48, train 84.03%
epoch 9, loss: 0.23, train 84.05%
epoch 9, loss: 0.72, train 83.82%
epoch 9, loss: 1.22, train 83.08%
epoch 9, loss: 0.26, train 83.50%
epoch 9, loss: 0.24, train 83.78%
epoch 9, loss: 0.42, train 83.81%
epoch 9, loss: 0.22, train 84.07%
epoch 9, loss: 0.26, train 84.20%
epoch 9, loss: 0.41, train 84.22%
epoch 9, loss: 0.55, train 84.24%
epoch 9, loss: 0.81, train 83.83%
epoch 9, loss: 0.54, train 83.65%
epoch 9, loss: 0.58, train 83.47%
epoch 9, loss: 0.56, train 83.60%
epoch 9, loss: 1.43, train 83.04%
epoch 9, loss: 0.65, train 83.08%
epoch 9, loss: 0.58, train 82.92%
epoch 9, loss: 0.37, train 83.06%
epoch 9, loss: 0.27, train 83.18%
epoch 9, loss: 0.43, train 83.21%
epoch 9, loss: 0.38, train 83.33%
epoch 9, loss: 0.70, train 83.28%
epoch 9, loss: 0.31, train 83.47%
epoch 9, loss: 0.33, train 83.58%
epoch 9, loss: 0.49, train 83.69%
epoch 9, loss: 0.35, train 83.71%
epoch 9, loss: 0.52, train 83.73%
epoch 9, loss: 0.19, train 83.91%
epoch 9, loss: 0.61, train 83.77%
epoch 9, loss: 0.52, train 83.79%
epoch 9, loss: 0.50, train 83.88%
epoch 9, loss: 0.35, train 83.90%
epoch 9, loss: 0.79, train 83.70%
epoch 9, loss: 0.38, train 83.64%
epoch 9, loss: 0.49, train 83.59%
epoch 9, loss: 0.53, train 83.61%
epoch 9, loss: 0.24, train 83.70%
epoch 9, loss: 0.35, train 83.78%
epoch 9, loss: 0.43, train 83.73%
epoch 9, loss: 1.01, train 83.49%
epoch 9, loss: 0.41, train 83.51%
epoch 9, loss: 0.98, train 83.33%
epoch 9, loss: 0.56, train 83.42%
epoch 9, loss: 0.74, train 83.31%
epoch 9, loss: 0.55, train 83.33%
epoch 9, loss: 1.19, train 83.05%
epoch 9, loss: 0.47, train 83.07%
epoch 9, loss: 0.65, train 83.04%
epoch 9, loss: 0.62, train 83.00%
epoch 9, loss: 0.87, train 82.79%
epoch 9, loss: 0.43, train 82.82%
epoch 9, loss: 0.74, train 82.67%
epoch 9, loss: 0.55, train 82.64%
epoch 9, loss: 0.39, train 82.67%
epoch 9, loss: 0.52, train 82.64%
epoch 9, loss: 0.42, train 82.66%
epoch 9, loss: 0.43, train 82.69%
epoch 9, loss: 0.52, train 82.66%
epoch 9, loss: 0.40, train 82.63%
epoch 9, loss: 0.45, train 82.66%
epoch 9, loss: 0.40, train 82.68%
epoch 9, loss: 0.34, train 82.76%
epoch 9, loss: 0.25, train 82.83%
epoch 9, loss: 0.46, train 82.80%
epoch 9, loss: 0.36, train 82.92%
epoch 9, loss: 0.51, train 82.84%
epoch 9, loss: 0.38, train 82.96%
epoch 9, loss: 0.50, train 82.93%
epoch 9, loss: 0.29, train 82.95%
epoch 9, loss: 0.30, train 83.02%
epoch 9, loss: 0.55, train 83.04%
epoch 9, loss: 0.77, train 82.92%
epoch 9, loss: 0.63, train 82.94%
epoch 9, loss: 1.11, train 82.73%
epoch 9, loss: 0.65, train 82.61%
epoch 9, loss: 0.42, train 82.63%
epoch 9, loss: 0.45, train 82.65%
epoch 9, loss: 0.41, train 82.68%
epoch 9, loss: 0.30, train 82.74%
epoch 9, loss: 0.66, train 82.80%
epoch 9, loss: 0.33, train 82.86%
epoch 9, loss: 0.49, train 82.92%
epoch 9, loss: 0.61, train 82.98%
epoch 9, loss: 0.66, train 82.96%
Epoch completed!
epoch 9, total signals 2400, average_loss_per_batch: 0.497784, train 82.96%
Validating
Val set size: 320, validation accuracy 73.44%
epoch 10, loss: 0.33, train 90.00%
epoch 10, loss: 0.62, train 85.00%
epoch 10, loss: 0.22, train 88.33%
epoch 10, loss: 0.43, train 88.75%
epoch 10, loss: 0.28, train 89.00%
epoch 10, loss: 0.38, train 89.17%
epoch 10, loss: 0.14, train 90.71%
epoch 10, loss: 0.22, train 91.25%
epoch 10, loss: 0.22, train 91.67%
epoch 10, loss: 0.31, train 91.50%
epoch 10, loss: 0.54, train 91.82%
epoch 10, loss: 0.45, train 91.67%
epoch 10, loss: 0.51, train 90.77%
epoch 10, loss: 0.24, train 90.71%
epoch 10, loss: 0.27, train 90.67%
epoch 10, loss: 0.55, train 90.31%
epoch 10, loss: 0.29, train 90.29%
epoch 10, loss: 0.21, train 90.56%
epoch 10, loss: 0.36, train 90.53%
epoch 10, loss: 0.26, train 90.50%
epoch 10, loss: 0.73, train 89.52%
epoch 10, loss: 0.39, train 89.55%
epoch 10, loss: 0.24, train 89.78%
epoch 10, loss: 0.14, train 90.21%
epoch 10, loss: 0.39, train 90.40%
epoch 10, loss: 0.77, train 89.81%
epoch 10, loss: 0.60, train 89.63%
epoch 10, loss: 0.21, train 90.00%
epoch 10, loss: 0.35, train 90.00%
epoch 10, loss: 0.42, train 90.17%
epoch 10, loss: 1.17, train 89.35%
epoch 10, loss: 0.39, train 89.38%
epoch 10, loss: 0.13, train 89.70%
epoch 10, loss: 0.24, train 89.85%
epoch 10, loss: 0.42, train 89.86%
epoch 10, loss: 0.58, train 89.44%
epoch 10, loss: 0.37, train 89.19%
epoch 10, loss: 1.24, train 88.16%
epoch 10, loss: 0.60, train 87.95%
epoch 10, loss: 0.27, train 88.12%
epoch 10, loss: 0.16, train 88.29%
epoch 10, loss: 0.46, train 88.10%
epoch 10, loss: 0.22, train 88.14%
epoch 10, loss: 0.31, train 88.30%
epoch 10, loss: 1.39, train 87.78%
epoch 10, loss: 0.07, train 88.04%
epoch 10, loss: 1.48, train 87.34%
epoch 10, loss: 1.06, train 86.67%
epoch 10, loss: 0.29, train 86.73%
epoch 10, loss: 0.34, train 86.80%
epoch 10, loss: 0.64, train 86.67%
epoch 10, loss: 1.12, train 86.25%
epoch 10, loss: 1.23, train 85.75%
epoch 10, loss: 0.37, train 85.83%
epoch 10, loss: 0.55, train 85.55%
epoch 10, loss: 0.43, train 85.54%
epoch 10, loss: 0.37, train 85.61%
epoch 10, loss: 0.40, train 85.69%
epoch 10, loss: 0.26, train 85.85%
epoch 10, loss: 0.52, train 85.83%
epoch 10, loss: 0.73, train 85.66%
epoch 10, loss: 0.41, train 85.65%
epoch 10, loss: 0.47, train 85.48%
epoch 10, loss: 0.14, train 85.70%
epoch 10, loss: 0.46, train 85.69%
epoch 10, loss: 0.45, train 85.68%
epoch 10, loss: 1.13, train 85.22%
epoch 10, loss: 0.51, train 85.22%
epoch 10, loss: 0.79, train 85.14%
epoch 10, loss: 0.36, train 85.14%
epoch 10, loss: 0.41, train 85.14%
epoch 10, loss: 0.31, train 85.14%
epoch 10, loss: 0.37, train 85.14%
epoch 10, loss: 0.73, train 84.93%
epoch 10, loss: 0.69, train 84.80%
epoch 10, loss: 0.52, train 84.74%
epoch 10, loss: 0.84, train 84.55%
epoch 10, loss: 0.62, train 84.36%
epoch 10, loss: 0.63, train 84.43%
epoch 10, loss: 0.40, train 84.44%
epoch 10, loss: 0.60, train 84.38%
epoch 10, loss: 0.43, train 84.39%
epoch 10, loss: 0.36, train 84.46%
epoch 10, loss: 0.27, train 84.58%
epoch 10, loss: 0.39, train 84.53%
epoch 10, loss: 1.71, train 84.30%
epoch 10, loss: 0.39, train 84.37%
epoch 10, loss: 0.65, train 84.26%
epoch 10, loss: 0.73, train 84.10%
epoch 10, loss: 0.26, train 84.17%
epoch 10, loss: 0.82, train 84.01%
epoch 10, loss: 0.79, train 83.86%
epoch 10, loss: 0.28, train 83.92%
epoch 10, loss: 0.52, train 83.83%
epoch 10, loss: 0.50, train 83.84%
epoch 10, loss: 0.64, train 83.75%
epoch 10, loss: 0.48, train 83.76%
epoch 10, loss: 0.24, train 83.93%
epoch 10, loss: 0.41, train 83.94%
epoch 10, loss: 0.39, train 83.90%
epoch 10, loss: 0.56, train 83.96%
epoch 10, loss: 0.47, train 84.02%
epoch 10, loss: 0.88, train 83.88%
epoch 10, loss: 0.49, train 83.85%
epoch 10, loss: 0.52, train 83.86%
epoch 10, loss: 0.56, train 83.82%
epoch 10, loss: 0.50, train 83.83%
epoch 10, loss: 0.38, train 83.84%
epoch 10, loss: 0.38, train 83.85%
epoch 10, loss: 0.78, train 83.82%
epoch 10, loss: 0.46, train 83.87%
epoch 10, loss: 0.37, train 83.93%
epoch 10, loss: 0.29, train 84.03%
epoch 10, loss: 0.50, train 84.04%
epoch 10, loss: 0.52, train 84.04%
epoch 10, loss: 0.41, train 84.05%
epoch 10, loss: 0.38, train 84.15%
epoch 10, loss: 0.68, train 84.03%
epoch 10, loss: 0.32, train 84.12%
epoch 10, loss: 0.93, train 83.96%
Epoch completed!
epoch 10, total signals 2400, average_loss_per_batch: 0.503037, train 83.96%
Validating
Val set size: 320, validation accuracy 81.56%
epoch 11, loss: 0.87, train 70.00%
epoch 11, loss: 0.30, train 80.00%
epoch 11, loss: 0.61, train 83.33%
epoch 11, loss: 0.32, train 82.50%
epoch 11, loss: 0.39, train 82.00%
epoch 11, loss: 0.50, train 82.50%
epoch 11, loss: 0.25, train 84.29%
epoch 11, loss: 0.38, train 85.62%
epoch 11, loss: 0.24, train 86.67%
epoch 11, loss: 0.26, train 87.50%
epoch 11, loss: 0.36, train 87.73%
epoch 11, loss: 0.16, train 88.75%
epoch 11, loss: 0.24, train 89.23%
epoch 11, loss: 0.33, train 89.29%
epoch 11, loss: 0.35, train 89.00%
epoch 11, loss: 0.24, train 89.38%
epoch 11, loss: 1.00, train 88.53%
epoch 11, loss: 0.41, train 87.78%
epoch 11, loss: 0.35, train 87.89%
epoch 11, loss: 0.18, train 88.50%
epoch 11, loss: 0.47, train 87.86%
epoch 11, loss: 0.52, train 87.05%
epoch 11, loss: 0.21, train 87.39%
epoch 11, loss: 0.65, train 86.88%
epoch 11, loss: 0.53, train 86.60%
epoch 11, loss: 0.26, train 86.73%
epoch 11, loss: 0.22, train 87.04%
epoch 11, loss: 0.56, train 86.61%
epoch 11, loss: 0.80, train 86.03%
epoch 11, loss: 0.30, train 86.00%
epoch 11, loss: 0.26, train 86.29%
epoch 11, loss: 0.47, train 86.41%
epoch 11, loss: 0.36, train 86.52%
epoch 11, loss: 0.24, train 86.76%
epoch 11, loss: 0.45, train 86.43%
epoch 11, loss: 0.20, train 86.67%
epoch 11, loss: 0.40, train 86.62%
epoch 11, loss: 0.74, train 86.32%
epoch 11, loss: 0.45, train 86.41%
epoch 11, loss: 0.82, train 85.88%
epoch 11, loss: 1.34, train 85.49%
epoch 11, loss: 0.32, train 85.71%
epoch 11, loss: 0.53, train 85.70%
epoch 11, loss: 0.71, train 85.34%
epoch 11, loss: 0.56, train 85.11%
epoch 11, loss: 0.17, train 85.43%
epoch 11, loss: 0.35, train 85.43%
epoch 11, loss: 0.34, train 85.52%
epoch 11, loss: 0.88, train 85.31%
epoch 11, loss: 0.24, train 85.50%
epoch 11, loss: 0.42, train 85.59%
epoch 11, loss: 0.70, train 85.48%
epoch 11, loss: 0.76, train 85.38%
epoch 11, loss: 0.37, train 85.46%
epoch 11, loss: 0.34, train 85.55%
epoch 11, loss: 0.26, train 85.62%
epoch 11, loss: 0.25, train 85.79%
epoch 11, loss: 0.19, train 86.03%
epoch 11, loss: 0.38, train 86.10%
epoch 11, loss: 0.29, train 86.25%
epoch 11, loss: 0.29, train 86.31%
epoch 11, loss: 0.72, train 86.05%
epoch 11, loss: 0.52, train 86.03%
epoch 11, loss: 0.28, train 86.09%
epoch 11, loss: 0.91, train 85.85%
epoch 11, loss: 0.67, train 85.68%
epoch 11, loss: 0.82, train 85.52%
epoch 11, loss: 0.56, train 85.44%
epoch 11, loss: 0.66, train 85.29%
epoch 11, loss: 0.51, train 85.21%
epoch 11, loss: 0.46, train 85.21%
epoch 11, loss: 0.33, train 85.35%
epoch 11, loss: 0.53, train 85.27%
epoch 11, loss: 0.40, train 85.14%
epoch 11, loss: 0.35, train 85.20%
epoch 11, loss: 0.42, train 85.20%
epoch 11, loss: 0.44, train 85.13%
epoch 11, loss: 0.37, train 85.13%
epoch 11, loss: 0.35, train 85.19%
epoch 11, loss: 1.11, train 84.94%
epoch 11, loss: 0.30, train 85.06%
epoch 11, loss: 0.43, train 85.06%
epoch 11, loss: 0.46, train 85.00%
epoch 11, loss: 0.47, train 84.94%
epoch 11, loss: 0.42, train 84.94%
epoch 11, loss: 0.21, train 85.06%
epoch 11, loss: 0.23, train 85.11%
epoch 11, loss: 0.56, train 85.06%
epoch 11, loss: 0.29, train 85.11%
epoch 11, loss: 0.25, train 85.17%
epoch 11, loss: 0.53, train 85.11%
epoch 11, loss: 0.56, train 85.05%
epoch 11, loss: 0.77, train 84.95%
epoch 11, loss: 0.41, train 85.00%
epoch 11, loss: 0.67, train 84.89%
epoch 11, loss: 0.34, train 84.95%
epoch 11, loss: 0.12, train 85.10%
epoch 11, loss: 0.88, train 84.95%
epoch 11, loss: 0.25, train 85.05%
epoch 11, loss: 0.97, train 84.90%
epoch 11, loss: 0.34, train 85.00%
epoch 11, loss: 0.32, train 85.10%
epoch 11, loss: 0.46, train 85.15%
epoch 11, loss: 0.64, train 85.10%
epoch 11, loss: 0.66, train 85.00%
epoch 11, loss: 0.52, train 85.00%
epoch 11, loss: 0.53, train 85.05%
epoch 11, loss: 0.47, train 85.09%
epoch 11, loss: 0.46, train 85.05%
epoch 11, loss: 1.30, train 84.77%
epoch 11, loss: 0.45, train 84.73%
epoch 11, loss: 0.52, train 84.64%
epoch 11, loss: 0.39, train 84.69%
epoch 11, loss: 0.49, train 84.61%
epoch 11, loss: 0.52, train 84.61%
epoch 11, loss: 0.72, train 84.48%
epoch 11, loss: 0.46, train 84.44%
epoch 11, loss: 0.43, train 84.49%
epoch 11, loss: 0.36, train 84.45%
epoch 11, loss: 0.47, train 84.42%
Epoch completed!
epoch 11, total signals 2400, average_loss_per_batch: 0.469558, train 84.42%
Validating
Val set size: 320, validation accuracy 79.06%
epoch 12, loss: 0.43, train 85.00%
epoch 12, loss: 0.23, train 87.50%
epoch 12, loss: 0.68, train 85.00%
epoch 12, loss: 0.37, train 85.00%
epoch 12, loss: 0.34, train 87.00%
epoch 12, loss: 0.20, train 87.50%
epoch 12, loss: 0.13, train 89.29%
epoch 12, loss: 0.30, train 89.38%
epoch 12, loss: 0.47, train 90.00%
epoch 12, loss: 0.57, train 89.50%
epoch 12, loss: 0.50, train 88.18%
epoch 12, loss: 0.77, train 86.67%
epoch 12, loss: 0.43, train 86.54%
epoch 12, loss: 0.25, train 87.14%
epoch 12, loss: 0.42, train 86.00%
epoch 12, loss: 0.35, train 86.25%
epoch 12, loss: 0.28, train 86.47%
epoch 12, loss: 0.69, train 85.56%
epoch 12, loss: 0.60, train 85.26%
epoch 12, loss: 0.30, train 85.50%
epoch 12, loss: 0.20, train 85.95%
epoch 12, loss: 0.41, train 85.68%
epoch 12, loss: 0.47, train 85.65%
epoch 12, loss: 0.38, train 85.62%
epoch 12, loss: 0.81, train 85.20%
epoch 12, loss: 0.48, train 85.00%
epoch 12, loss: 0.21, train 85.37%
epoch 12, loss: 0.17, train 85.71%
epoch 12, loss: 0.69, train 85.69%
epoch 12, loss: 0.30, train 85.83%
epoch 12, loss: 0.43, train 85.65%
epoch 12, loss: 0.86, train 85.47%
epoch 12, loss: 0.51, train 85.30%
epoch 12, loss: 0.14, train 85.59%
epoch 12, loss: 0.55, train 85.29%
epoch 12, loss: 0.52, train 85.28%
epoch 12, loss: 0.53, train 85.14%
epoch 12, loss: 0.48, train 85.00%
epoch 12, loss: 0.52, train 84.74%
epoch 12, loss: 0.43, train 84.50%
epoch 12, loss: 0.32, train 84.63%
epoch 12, loss: 0.40, train 84.52%
epoch 12, loss: 0.70, train 84.42%
epoch 12, loss: 0.31, train 84.43%
epoch 12, loss: 0.54, train 84.56%
epoch 12, loss: 0.47, train 84.35%
epoch 12, loss: 0.64, train 84.15%
epoch 12, loss: 0.35, train 84.17%
epoch 12, loss: 0.61, train 83.98%
epoch 12, loss: 0.44, train 84.10%
epoch 12, loss: 0.36, train 84.31%
epoch 12, loss: 0.29, train 84.42%
epoch 12, loss: 0.66, train 84.34%
epoch 12, loss: 1.08, train 83.80%
epoch 12, loss: 0.55, train 83.82%
epoch 12, loss: 0.55, train 83.57%
epoch 12, loss: 0.64, train 83.51%
epoch 12, loss: 0.22, train 83.79%
epoch 12, loss: 0.43, train 83.81%
epoch 12, loss: 0.70, train 83.67%
epoch 12, loss: 0.91, train 83.69%
epoch 12, loss: 0.36, train 83.79%
epoch 12, loss: 0.24, train 83.97%
epoch 12, loss: 0.17, train 84.22%
epoch 12, loss: 0.33, train 84.38%
epoch 12, loss: 0.45, train 84.47%
epoch 12, loss: 0.47, train 84.40%
epoch 12, loss: 0.40, train 84.34%
epoch 12, loss: 0.34, train 84.42%
epoch 12, loss: 0.31, train 84.50%
epoch 12, loss: 0.37, train 84.51%
epoch 12, loss: 0.53, train 84.51%
epoch 12, loss: 0.36, train 84.59%
epoch 12, loss: 0.28, train 84.73%
epoch 12, loss: 0.34, train 84.80%
epoch 12, loss: 0.50, train 84.74%
epoch 12, loss: 0.49, train 84.61%
epoch 12, loss: 0.51, train 84.55%
epoch 12, loss: 0.61, train 84.49%
epoch 12, loss: 0.38, train 84.50%
epoch 12, loss: 0.50, train 84.57%
epoch 12, loss: 0.65, train 84.51%
epoch 12, loss: 0.38, train 84.52%
epoch 12, loss: 0.38, train 84.46%
epoch 12, loss: 0.34, train 84.53%
epoch 12, loss: 0.50, train 84.36%
epoch 12, loss: 0.28, train 84.48%
epoch 12, loss: 0.83, train 84.32%
epoch 12, loss: 0.38, train 84.33%
epoch 12, loss: 0.45, train 84.33%
epoch 12, loss: 0.27, train 84.45%
epoch 12, loss: 0.28, train 84.46%
epoch 12, loss: 0.56, train 84.35%
epoch 12, loss: 0.60, train 84.31%
epoch 12, loss: 0.42, train 84.32%
epoch 12, loss: 0.29, train 84.43%
epoch 12, loss: 0.84, train 84.28%
epoch 12, loss: 0.49, train 84.29%
epoch 12, loss: 0.44, train 84.24%
epoch 12, loss: 0.49, train 84.25%
epoch 12, loss: 0.88, train 84.06%
epoch 12, loss: 0.54, train 84.02%
epoch 12, loss: 0.23, train 84.13%
epoch 12, loss: 0.63, train 84.13%
epoch 12, loss: 0.50, train 84.24%
epoch 12, loss: 0.19, train 84.39%
epoch 12, loss: 0.58, train 84.30%
epoch 12, loss: 0.97, train 84.21%
epoch 12, loss: 0.21, train 84.27%
epoch 12, loss: 0.75, train 84.18%
epoch 12, loss: 0.41, train 84.23%
epoch 12, loss: 0.26, train 84.38%
epoch 12, loss: 0.37, train 84.34%
epoch 12, loss: 1.01, train 84.17%
epoch 12, loss: 0.62, train 84.09%
epoch 12, loss: 0.24, train 84.14%
epoch 12, loss: 0.78, train 84.06%
epoch 12, loss: 0.69, train 84.03%
epoch 12, loss: 0.26, train 84.12%
epoch 12, loss: 0.53, train 84.00%
Epoch completed!
epoch 12, total signals 2400, average_loss_per_batch: 0.466947, train 84.00%
Validating
Val set size: 320, validation accuracy 78.44%
epoch 13, loss: 0.14, train 95.00%
epoch 13, loss: 0.26, train 95.00%
epoch 13, loss: 0.49, train 91.67%
epoch 13, loss: 0.21, train 91.25%
epoch 13, loss: 0.37, train 92.00%
epoch 13, loss: 0.23, train 92.50%
epoch 13, loss: 0.44, train 91.43%
epoch 13, loss: 0.37, train 90.00%
epoch 13, loss: 0.19, train 90.56%
epoch 13, loss: 1.00, train 87.50%
epoch 13, loss: 0.25, train 88.18%
epoch 13, loss: 0.40, train 88.33%
epoch 13, loss: 0.40, train 88.46%
epoch 13, loss: 0.91, train 86.79%
epoch 13, loss: 0.75, train 86.00%
epoch 13, loss: 0.46, train 85.94%
epoch 13, loss: 0.42, train 85.88%
epoch 13, loss: 0.34, train 86.11%
epoch 13, loss: 0.39, train 86.05%
epoch 13, loss: 0.15, train 86.75%
epoch 13, loss: 0.85, train 85.95%
epoch 13, loss: 0.75, train 85.68%
epoch 13, loss: 0.36, train 85.87%
epoch 13, loss: 0.79, train 85.62%
epoch 13, loss: 0.59, train 85.60%
epoch 13, loss: 0.43, train 85.77%
epoch 13, loss: 0.65, train 85.56%
epoch 13, loss: 0.26, train 85.89%
epoch 13, loss: 0.43, train 86.21%
epoch 13, loss: 0.66, train 86.00%
epoch 13, loss: 0.34, train 85.97%
epoch 13, loss: 0.48, train 85.94%
epoch 13, loss: 0.40, train 85.91%
epoch 13, loss: 0.30, train 86.03%
epoch 13, loss: 0.75, train 85.86%
epoch 13, loss: 0.22, train 86.11%
epoch 13, loss: 0.51, train 86.22%
epoch 13, loss: 1.04, train 85.53%
epoch 13, loss: 0.73, train 85.13%
epoch 13, loss: 0.25, train 85.38%
epoch 13, loss: 0.36, train 85.49%
epoch 13, loss: 0.24, train 85.71%
epoch 13, loss: 0.30, train 85.81%
epoch 13, loss: 0.11, train 86.14%
epoch 13, loss: 0.72, train 86.00%
epoch 13, loss: 0.89, train 85.76%
epoch 13, loss: 0.92, train 85.53%
epoch 13, loss: 0.76, train 85.31%
epoch 13, loss: 0.39, train 85.51%
epoch 13, loss: 0.24, train 85.70%
epoch 13, loss: 0.92, train 85.29%
epoch 13, loss: 0.40, train 85.29%
epoch 13, loss: 0.82, train 85.00%
epoch 13, loss: 0.63, train 84.63%
epoch 13, loss: 0.70, train 84.45%
epoch 13, loss: 0.54, train 84.38%
epoch 13, loss: 0.32, train 84.56%
epoch 13, loss: 0.65, train 84.57%
epoch 13, loss: 0.21, train 84.83%
epoch 13, loss: 0.13, train 85.08%
epoch 13, loss: 0.45, train 85.00%
epoch 13, loss: 0.59, train 84.84%
epoch 13, loss: 0.42, train 84.84%
epoch 13, loss: 0.35, train 84.84%
epoch 13, loss: 0.54, train 84.85%
epoch 13, loss: 0.60, train 84.62%
epoch 13, loss: 0.79, train 84.48%
epoch 13, loss: 0.92, train 84.34%
epoch 13, loss: 0.61, train 84.28%
epoch 13, loss: 0.56, train 84.14%
epoch 13, loss: 0.13, train 84.30%
epoch 13, loss: 0.74, train 84.10%
epoch 13, loss: 0.44, train 84.18%
epoch 13, loss: 0.74, train 83.99%
epoch 13, loss: 1.57, train 83.33%
epoch 13, loss: 1.82, train 82.76%
epoch 13, loss: 0.50, train 82.73%
epoch 13, loss: 0.58, train 82.69%
epoch 13, loss: 0.37, train 82.78%
epoch 13, loss: 0.63, train 82.81%
epoch 13, loss: 0.76, train 82.72%
epoch 13, loss: 0.70, train 82.74%
epoch 13, loss: 0.77, train 82.65%
epoch 13, loss: 0.78, train 82.56%
epoch 13, loss: 1.27, train 82.41%
epoch 13, loss: 0.59, train 82.38%
epoch 13, loss: 0.35, train 82.53%
epoch 13, loss: 0.38, train 82.67%
epoch 13, loss: 0.26, train 82.81%
epoch 13, loss: 0.51, train 82.78%
epoch 13, loss: 0.31, train 82.80%
epoch 13, loss: 0.53, train 82.77%
epoch 13, loss: 0.40, train 82.85%
epoch 13, loss: 1.05, train 82.55%
epoch 13, loss: 0.83, train 82.47%
epoch 13, loss: 0.50, train 82.55%
epoch 13, loss: 0.29, train 82.68%
epoch 13, loss: 0.30, train 82.70%
epoch 13, loss: 0.73, train 82.63%
epoch 13, loss: 0.52, train 82.60%
epoch 13, loss: 0.72, train 82.57%
epoch 13, loss: 0.54, train 82.50%
epoch 13, loss: 0.48, train 82.57%
epoch 13, loss: 1.21, train 82.31%
epoch 13, loss: 0.19, train 82.48%
epoch 13, loss: 0.22, train 82.55%
epoch 13, loss: 0.68, train 82.52%
epoch 13, loss: 0.58, train 82.50%
epoch 13, loss: 0.92, train 82.39%
epoch 13, loss: 0.88, train 82.27%
epoch 13, loss: 0.39, train 82.30%
epoch 13, loss: 0.39, train 82.32%
epoch 13, loss: 0.32, train 82.39%
epoch 13, loss: 0.67, train 82.41%
epoch 13, loss: 2.46, train 81.96%
epoch 13, loss: 0.57, train 81.94%
epoch 13, loss: 0.65, train 81.92%
epoch 13, loss: 1.08, train 81.69%
epoch 13, loss: 0.49, train 81.72%
epoch 13, loss: 0.61, train 81.71%
Epoch completed!
epoch 13, total signals 2400, average_loss_per_batch: 0.570516, train 81.71%
Validating
Val set size: 320, validation accuracy 66.88%
epoch 14, loss: 0.71, train 65.00%
epoch 14, loss: 1.02, train 67.50%
epoch 14, loss: 0.38, train 75.00%
epoch 14, loss: 0.68, train 76.25%
epoch 14, loss: 0.78, train 73.00%
epoch 14, loss: 1.54, train 71.67%
epoch 14, loss: 0.40, train 74.29%
epoch 14, loss: 0.75, train 73.75%
epoch 14, loss: 0.82, train 73.89%
epoch 14, loss: 1.32, train 73.00%
epoch 14, loss: 0.61, train 72.73%
epoch 14, loss: 0.67, train 72.92%
epoch 14, loss: 0.57, train 73.46%
epoch 14, loss: 0.69, train 73.21%
epoch 14, loss: 0.58, train 74.00%
epoch 14, loss: 0.25, train 75.31%
epoch 14, loss: 0.79, train 75.00%
epoch 14, loss: 0.36, train 75.83%
epoch 14, loss: 0.84, train 76.05%
epoch 14, loss: 0.97, train 76.25%
epoch 14, loss: 0.59, train 76.19%
epoch 14, loss: 0.41, train 76.59%
epoch 14, loss: 0.52, train 76.96%
epoch 14, loss: 0.40, train 77.50%
epoch 14, loss: 0.40, train 77.80%
epoch 14, loss: 0.44, train 78.27%
epoch 14, loss: 0.25, train 78.89%
epoch 14, loss: 0.38, train 79.29%
epoch 14, loss: 1.39, train 78.28%
epoch 14, loss: 0.43, train 78.33%
epoch 14, loss: 0.87, train 78.06%
epoch 14, loss: 0.64, train 77.81%
epoch 14, loss: 0.46, train 78.03%
epoch 14, loss: 0.45, train 78.09%
epoch 14, loss: 0.31, train 78.43%
epoch 14, loss: 0.43, train 78.75%
epoch 14, loss: 1.00, train 78.51%
epoch 14, loss: 0.60, train 78.55%
epoch 14, loss: 0.25, train 78.85%
epoch 14, loss: 0.42, train 79.00%
epoch 14, loss: 0.33, train 79.15%
epoch 14, loss: 0.61, train 79.29%
epoch 14, loss: 0.56, train 79.30%
epoch 14, loss: 1.32, train 78.75%
epoch 14, loss: 0.85, train 78.78%
epoch 14, loss: 0.38, train 79.02%
epoch 14, loss: 0.24, train 79.26%
epoch 14, loss: 0.40, train 79.38%
epoch 14, loss: 0.60, train 79.49%
epoch 14, loss: 0.61, train 79.40%
epoch 14, loss: 0.32, train 79.71%
epoch 14, loss: 0.30, train 79.81%
epoch 14, loss: 0.32, train 79.91%
epoch 14, loss: 1.26, train 79.81%
epoch 14, loss: 0.85, train 79.36%
epoch 14, loss: 0.33, train 79.55%
epoch 14, loss: 0.92, train 79.21%
epoch 14, loss: 0.59, train 79.31%
epoch 14, loss: 0.37, train 79.32%
epoch 14, loss: 0.90, train 79.00%
epoch 14, loss: 0.45, train 79.18%
epoch 14, loss: 0.71, train 79.03%
epoch 14, loss: 0.37, train 79.21%
epoch 14, loss: 0.20, train 79.45%
epoch 14, loss: 0.78, train 79.31%
epoch 14, loss: 0.53, train 79.55%
epoch 14, loss: 0.38, train 79.63%
epoch 14, loss: 0.73, train 79.49%
epoch 14, loss: 0.62, train 79.64%
epoch 14, loss: 0.38, train 79.71%
epoch 14, loss: 0.35, train 79.79%
epoch 14, loss: 1.51, train 79.38%
epoch 14, loss: 0.34, train 79.52%
epoch 14, loss: 0.20, train 79.73%
epoch 14, loss: 1.38, train 79.33%
epoch 14, loss: 1.05, train 79.14%
epoch 14, loss: 0.78, train 79.16%
epoch 14, loss: 0.33, train 79.36%
epoch 14, loss: 0.32, train 79.37%
epoch 14, loss: 0.70, train 79.31%
epoch 14, loss: 0.45, train 79.32%
epoch 14, loss: 0.37, train 79.45%
epoch 14, loss: 0.24, train 79.64%
epoch 14, loss: 1.35, train 79.46%
epoch 14, loss: 0.48, train 79.59%
epoch 14, loss: 0.47, train 79.53%
epoch 14, loss: 0.61, train 79.60%
epoch 14, loss: 0.30, train 79.77%
epoch 14, loss: 0.38, train 79.78%
epoch 14, loss: 0.74, train 79.67%
epoch 14, loss: 0.67, train 79.62%
epoch 14, loss: 0.36, train 79.73%
epoch 14, loss: 0.38, train 79.78%
epoch 14, loss: 0.71, train 79.79%
epoch 14, loss: 0.57, train 79.74%
epoch 14, loss: 0.55, train 79.69%
epoch 14, loss: 0.46, train 79.64%
epoch 14, loss: 0.54, train 79.54%
epoch 14, loss: 0.55, train 79.60%
epoch 14, loss: 0.57, train 79.55%
epoch 14, loss: 0.92, train 79.36%
epoch 14, loss: 0.34, train 79.41%
epoch 14, loss: 0.45, train 79.51%
epoch 14, loss: 0.59, train 79.47%
epoch 14, loss: 0.48, train 79.48%
epoch 14, loss: 0.52, train 79.43%
epoch 14, loss: 0.43, train 79.44%
epoch 14, loss: 0.63, train 79.40%
epoch 14, loss: 0.64, train 79.36%
epoch 14, loss: 0.52, train 79.36%
epoch 14, loss: 1.15, train 79.14%
epoch 14, loss: 0.80, train 79.06%
epoch 14, loss: 0.68, train 79.03%
epoch 14, loss: 0.26, train 79.17%
epoch 14, loss: 0.47, train 79.13%
epoch 14, loss: 0.61, train 79.09%
epoch 14, loss: 0.50, train 79.10%
epoch 14, loss: 0.32, train 79.15%
epoch 14, loss: 0.40, train 79.16%
epoch 14, loss: 0.50, train 79.17%
Epoch completed!
epoch 14, total signals 2400, average_loss_per_batch: 0.595744, train 79.17%
Validating
Val set size: 320, validation accuracy 78.75%
epoch 15, loss: 0.29, train 95.00%
epoch 15, loss: 0.29, train 97.50%
epoch 15, loss: 0.67, train 90.00%
epoch 15, loss: 0.45, train 90.00%
epoch 15, loss: 0.33, train 89.00%
epoch 15, loss: 0.32, train 89.17%
epoch 15, loss: 0.33, train 90.00%
epoch 15, loss: 0.38, train 89.38%
epoch 15, loss: 0.27, train 88.89%
epoch 15, loss: 0.36, train 88.50%
epoch 15, loss: 0.26, train 89.09%
epoch 15, loss: 0.32, train 89.58%
epoch 15, loss: 0.34, train 89.62%
epoch 15, loss: 0.49, train 88.93%
epoch 15, loss: 0.26, train 89.00%
epoch 15, loss: 0.56, train 88.12%
epoch 15, loss: 0.63, train 87.35%
epoch 15, loss: 0.24, train 87.50%
epoch 15, loss: 0.24, train 87.63%
epoch 15, loss: 0.30, train 87.75%
epoch 15, loss: 0.28, train 87.86%
epoch 15, loss: 0.22, train 88.18%
epoch 15, loss: 0.58, train 87.61%
epoch 15, loss: 0.32, train 87.71%
epoch 15, loss: 0.32, train 87.80%
epoch 15, loss: 0.44, train 87.50%
epoch 15, loss: 0.27, train 87.41%
epoch 15, loss: 0.60, train 87.14%
epoch 15, loss: 0.62, train 87.07%
epoch 15, loss: 0.26, train 87.17%
epoch 15, loss: 0.46, train 87.10%
epoch 15, loss: 0.48, train 87.03%
epoch 15, loss: 0.47, train 87.27%
epoch 15, loss: 0.34, train 87.21%
epoch 15, loss: 0.27, train 87.43%
epoch 15, loss: 0.56, train 87.36%
epoch 15, loss: 0.07, train 87.70%
epoch 15, loss: 0.18, train 88.03%
epoch 15, loss: 0.20, train 88.21%
epoch 15, loss: 0.51, train 88.00%
epoch 15, loss: 0.62, train 87.80%
epoch 15, loss: 0.39, train 87.86%
epoch 15, loss: 0.51, train 87.79%
epoch 15, loss: 1.15, train 87.27%
epoch 15, loss: 0.54, train 87.22%
epoch 15, loss: 0.52, train 87.17%
epoch 15, loss: 0.49, train 87.13%
epoch 15, loss: 0.67, train 86.88%
epoch 15, loss: 0.36, train 86.73%
epoch 15, loss: 0.55, train 86.60%
epoch 15, loss: 0.43, train 86.47%
epoch 15, loss: 0.28, train 86.63%
epoch 15, loss: 0.75, train 86.32%
epoch 15, loss: 0.93, train 86.11%
epoch 15, loss: 0.41, train 86.09%
epoch 15, loss: 0.39, train 86.07%
epoch 15, loss: 0.34, train 86.05%
epoch 15, loss: 0.32, train 86.12%
epoch 15, loss: 0.37, train 86.10%
epoch 15, loss: 0.27, train 86.25%
epoch 15, loss: 0.37, train 86.39%
epoch 15, loss: 0.51, train 86.37%
epoch 15, loss: 0.33, train 86.35%
epoch 15, loss: 2.02, train 85.70%
epoch 15, loss: 0.57, train 85.69%
epoch 15, loss: 0.18, train 85.83%
epoch 15, loss: 0.26, train 85.97%
epoch 15, loss: 0.63, train 85.96%
epoch 15, loss: 0.33, train 86.01%
epoch 15, loss: 0.15, train 86.14%
epoch 15, loss: 0.50, train 86.27%
epoch 15, loss: 0.33, train 86.39%
epoch 15, loss: 0.22, train 86.51%
epoch 15, loss: 0.45, train 86.49%
epoch 15, loss: 0.23, train 86.60%
epoch 15, loss: 0.55, train 86.64%
epoch 15, loss: 0.51, train 86.62%
epoch 15, loss: 0.12, train 86.73%
epoch 15, loss: 1.04, train 86.39%
epoch 15, loss: 0.53, train 86.31%
epoch 15, loss: 0.62, train 86.23%
epoch 15, loss: 0.42, train 86.22%
epoch 15, loss: 0.43, train 86.27%
epoch 15, loss: 0.14, train 86.43%
epoch 15, loss: 0.40, train 86.47%
epoch 15, loss: 0.66, train 86.22%
epoch 15, loss: 0.50, train 86.09%
epoch 15, loss: 0.50, train 86.08%
epoch 15, loss: 0.55, train 86.12%
epoch 15, loss: 0.79, train 86.06%
epoch 15, loss: 0.32, train 86.10%
epoch 15, loss: 0.63, train 85.98%
epoch 15, loss: 0.29, train 86.08%
epoch 15, loss: 0.24, train 86.17%
epoch 15, loss: 0.55, train 86.16%
epoch 15, loss: 0.46, train 86.15%
epoch 15, loss: 0.61, train 86.13%
epoch 15, loss: 0.50, train 86.12%
epoch 15, loss: 0.32, train 86.16%
epoch 15, loss: 0.41, train 86.15%
epoch 15, loss: 0.55, train 86.09%
epoch 15, loss: 0.51, train 86.03%
epoch 15, loss: 0.55, train 85.92%
epoch 15, loss: 0.29, train 86.01%
epoch 15, loss: 0.80, train 85.95%
epoch 15, loss: 0.57, train 85.90%
epoch 15, loss: 0.38, train 85.89%
epoch 15, loss: 0.53, train 85.83%
epoch 15, loss: 0.43, train 85.83%
epoch 15, loss: 0.85, train 85.73%
epoch 15, loss: 0.44, train 85.77%
epoch 15, loss: 0.21, train 85.89%
epoch 15, loss: 0.54, train 85.88%
epoch 15, loss: 0.82, train 85.83%
epoch 15, loss: 0.44, train 85.87%
epoch 15, loss: 0.29, train 85.91%
epoch 15, loss: 0.52, train 85.85%
epoch 15, loss: 0.60, train 85.76%
epoch 15, loss: 0.33, train 85.80%
epoch 15, loss: 0.56, train 85.79%
Epoch completed!
epoch 15, total signals 2400, average_loss_per_batch: 0.454273, train 85.79%
Validating
Val set size: 320, validation accuracy 78.75%
epoch 16, loss: 0.31, train 90.00%
epoch 16, loss: 0.71, train 85.00%
epoch 16, loss: 0.22, train 88.33%
epoch 16, loss: 0.18, train 90.00%
epoch 16, loss: 0.26, train 90.00%
epoch 16, loss: 1.18, train 86.67%
epoch 16, loss: 0.51, train 86.43%
epoch 16, loss: 0.70, train 83.75%
epoch 16, loss: 0.24, train 85.56%
epoch 16, loss: 0.29, train 85.50%
epoch 16, loss: 0.54, train 85.91%
epoch 16, loss: 0.15, train 86.67%
epoch 16, loss: 0.20, train 87.31%
epoch 16, loss: 0.22, train 87.50%
epoch 16, loss: 0.28, train 87.33%
epoch 16, loss: 0.78, train 86.25%
epoch 16, loss: 0.22, train 86.76%
epoch 16, loss: 0.16, train 87.50%
epoch 16, loss: 0.31, train 87.63%
epoch 16, loss: 0.25, train 88.00%
epoch 16, loss: 0.22, train 88.10%
epoch 16, loss: 0.40, train 88.18%
epoch 16, loss: 0.58, train 88.04%
epoch 16, loss: 0.56, train 87.92%
epoch 16, loss: 0.80, train 87.40%
epoch 16, loss: 0.18, train 87.69%
epoch 16, loss: 0.50, train 87.78%
epoch 16, loss: 0.24, train 88.04%
epoch 16, loss: 0.59, train 87.59%
epoch 16, loss: 0.66, train 87.17%
epoch 16, loss: 0.30, train 87.10%
epoch 16, loss: 0.27, train 87.34%
epoch 16, loss: 0.56, train 87.42%
epoch 16, loss: 0.40, train 87.35%
epoch 16, loss: 0.93, train 87.14%
epoch 16, loss: 0.35, train 86.94%
epoch 16, loss: 0.30, train 87.16%
epoch 16, loss: 0.27, train 87.24%
epoch 16, loss: 0.45, train 87.31%
epoch 16, loss: 0.31, train 87.38%
epoch 16, loss: 0.72, train 86.95%
epoch 16, loss: 0.21, train 87.02%
epoch 16, loss: 0.46, train 86.98%
epoch 16, loss: 0.19, train 87.27%
epoch 16, loss: 0.94, train 86.67%
epoch 16, loss: 0.38, train 86.63%
epoch 16, loss: 0.77, train 86.28%
epoch 16, loss: 1.23, train 85.83%
epoch 16, loss: 0.49, train 85.51%
epoch 16, loss: 0.40, train 85.60%
epoch 16, loss: 0.14, train 85.78%
epoch 16, loss: 0.33, train 85.87%
epoch 16, loss: 0.21, train 86.04%
epoch 16, loss: 0.32, train 86.11%
epoch 16, loss: 0.49, train 86.00%
epoch 16, loss: 0.28, train 85.98%
epoch 16, loss: 0.24, train 86.14%
epoch 16, loss: 0.75, train 85.95%
epoch 16, loss: 0.66, train 85.76%
epoch 16, loss: 0.22, train 85.83%
epoch 16, loss: 0.50, train 85.90%
epoch 16, loss: 0.36, train 85.97%
epoch 16, loss: 0.24, train 86.03%
epoch 16, loss: 0.55, train 85.86%
epoch 16, loss: 0.34, train 85.92%
epoch 16, loss: 0.38, train 85.91%
epoch 16, loss: 0.38, train 85.97%
epoch 16, loss: 0.65, train 85.74%
epoch 16, loss: 0.35, train 85.80%
epoch 16, loss: 0.95, train 85.43%
epoch 16, loss: 0.43, train 85.35%
epoch 16, loss: 0.40, train 85.35%
epoch 16, loss: 0.57, train 85.27%
epoch 16, loss: 0.65, train 85.14%
epoch 16, loss: 0.40, train 85.13%
epoch 16, loss: 0.22, train 85.26%
epoch 16, loss: 0.35, train 85.26%
epoch 16, loss: 0.28, train 85.32%
epoch 16, loss: 0.68, train 85.19%
epoch 16, loss: 0.54, train 85.25%
epoch 16, loss: 0.32, train 85.31%
epoch 16, loss: 0.32, train 85.37%
epoch 16, loss: 0.25, train 85.54%
epoch 16, loss: 0.28, train 85.60%
epoch 16, loss: 0.61, train 85.47%
epoch 16, loss: 0.22, train 85.58%
epoch 16, loss: 0.52, train 85.63%
epoch 16, loss: 1.21, train 85.28%
epoch 16, loss: 0.47, train 85.28%
epoch 16, loss: 0.47, train 85.22%
epoch 16, loss: 0.61, train 85.05%
epoch 16, loss: 0.43, train 85.05%
epoch 16, loss: 0.25, train 85.16%
epoch 16, loss: 0.90, train 85.05%
epoch 16, loss: 0.31, train 85.16%
epoch 16, loss: 0.47, train 85.16%
epoch 16, loss: 0.61, train 85.15%
epoch 16, loss: 0.37, train 85.15%
epoch 16, loss: 0.40, train 85.15%
epoch 16, loss: 0.45, train 85.20%
epoch 16, loss: 0.82, train 85.05%
epoch 16, loss: 0.51, train 85.00%
epoch 16, loss: 0.60, train 85.05%
epoch 16, loss: 0.60, train 84.95%
epoch 16, loss: 0.31, train 84.95%
epoch 16, loss: 0.31, train 84.95%
epoch 16, loss: 0.68, train 84.81%
epoch 16, loss: 0.24, train 84.91%
epoch 16, loss: 0.40, train 84.91%
epoch 16, loss: 0.51, train 84.91%
epoch 16, loss: 0.69, train 84.86%
epoch 16, loss: 0.62, train 84.78%
epoch 16, loss: 0.51, train 84.82%
epoch 16, loss: 0.75, train 84.74%
epoch 16, loss: 0.72, train 84.61%
epoch 16, loss: 0.28, train 84.66%
epoch 16, loss: 0.42, train 84.66%
epoch 16, loss: 0.63, train 84.58%
epoch 16, loss: 0.62, train 84.58%
epoch 16, loss: 0.64, train 84.42%
Epoch completed!
epoch 16, total signals 2400, average_loss_per_batch: 0.463066, train 84.42%
Validating
Val set size: 320, validation accuracy 75.62%
epoch 17, loss: 0.29, train 85.00%
epoch 17, loss: 0.28, train 87.50%
epoch 17, loss: 0.05, train 91.67%
epoch 17, loss: 0.32, train 92.50%
epoch 17, loss: 0.11, train 94.00%
epoch 17, loss: 0.61, train 91.67%
epoch 17, loss: 0.19, train 92.14%
epoch 17, loss: 0.40, train 92.50%
epoch 17, loss: 0.21, train 92.78%
epoch 17, loss: 0.36, train 92.50%
epoch 17, loss: 0.22, train 92.27%
epoch 17, loss: 0.34, train 91.67%
epoch 17, loss: 0.35, train 91.92%
epoch 17, loss: 0.40, train 91.07%
epoch 17, loss: 0.21, train 91.33%
epoch 17, loss: 0.22, train 91.88%
epoch 17, loss: 0.30, train 91.47%
epoch 17, loss: 0.18, train 91.67%
epoch 17, loss: 0.26, train 91.58%
epoch 17, loss: 0.09, train 92.00%
epoch 17, loss: 0.38, train 91.90%
epoch 17, loss: 0.41, train 91.59%
epoch 17, loss: 0.25, train 91.74%
epoch 17, loss: 0.55, train 90.83%
epoch 17, loss: 0.29, train 90.80%
epoch 17, loss: 1.09, train 89.42%
epoch 17, loss: 0.51, train 88.70%
epoch 17, loss: 0.33, train 88.57%
epoch 17, loss: 0.38, train 88.28%
epoch 17, loss: 0.18, train 88.33%
epoch 17, loss: 0.29, train 88.39%
epoch 17, loss: 0.24, train 88.59%
epoch 17, loss: 0.69, train 88.03%
epoch 17, loss: 0.42, train 88.09%
epoch 17, loss: 0.19, train 88.43%
epoch 17, loss: 0.44, train 88.75%
epoch 17, loss: 0.68, train 88.38%
epoch 17, loss: 0.53, train 88.03%
epoch 17, loss: 0.44, train 87.82%
epoch 17, loss: 0.42, train 87.75%
epoch 17, loss: 0.20, train 87.93%
epoch 17, loss: 0.33, train 87.98%
epoch 17, loss: 0.99, train 87.44%
epoch 17, loss: 0.57, train 87.50%
epoch 17, loss: 0.33, train 87.56%
epoch 17, loss: 0.34, train 87.61%
epoch 17, loss: 0.29, train 87.66%
epoch 17, loss: 0.65, train 87.50%
epoch 17, loss: 0.29, train 87.55%
epoch 17, loss: 0.28, train 87.70%
epoch 17, loss: 0.45, train 87.75%
epoch 17, loss: 0.20, train 87.98%
epoch 17, loss: 0.35, train 88.02%
epoch 17, loss: 0.19, train 88.06%
epoch 17, loss: 0.28, train 88.00%
epoch 17, loss: 0.25, train 88.12%
epoch 17, loss: 0.45, train 88.16%
epoch 17, loss: 0.48, train 88.10%
epoch 17, loss: 1.23, train 87.63%
epoch 17, loss: 0.55, train 87.50%
epoch 17, loss: 0.24, train 87.54%
epoch 17, loss: 0.29, train 87.66%
epoch 17, loss: 0.38, train 87.54%
epoch 17, loss: 0.33, train 87.42%
epoch 17, loss: 0.52, train 87.46%
epoch 17, loss: 0.28, train 87.58%
epoch 17, loss: 0.15, train 87.61%
epoch 17, loss: 0.27, train 87.72%
epoch 17, loss: 0.75, train 87.46%
epoch 17, loss: 0.57, train 87.43%
epoch 17, loss: 0.29, train 87.46%
epoch 17, loss: 0.42, train 87.43%
epoch 17, loss: 0.52, train 87.33%
epoch 17, loss: 0.43, train 87.23%
epoch 17, loss: 0.82, train 87.07%
epoch 17, loss: 0.43, train 87.04%
epoch 17, loss: 0.78, train 86.82%
epoch 17, loss: 1.05, train 86.47%
epoch 17, loss: 0.48, train 86.39%
epoch 17, loss: 0.30, train 86.44%
epoch 17, loss: 0.73, train 86.42%
epoch 17, loss: 0.32, train 86.40%
epoch 17, loss: 0.61, train 86.33%
epoch 17, loss: 0.67, train 86.19%
epoch 17, loss: 0.35, train 86.18%
epoch 17, loss: 0.34, train 86.22%
epoch 17, loss: 0.51, train 86.15%
epoch 17, loss: 0.43, train 86.19%
epoch 17, loss: 0.39, train 86.18%
epoch 17, loss: 0.41, train 86.17%
epoch 17, loss: 0.16, train 86.32%
epoch 17, loss: 0.41, train 86.30%
epoch 17, loss: 0.45, train 86.29%
epoch 17, loss: 0.23, train 86.33%
epoch 17, loss: 0.28, train 86.47%
epoch 17, loss: 0.23, train 86.61%
epoch 17, loss: 0.55, train 86.60%
epoch 17, loss: 0.07, train 86.73%
epoch 17, loss: 0.20, train 86.82%
epoch 17, loss: 1.19, train 86.50%
epoch 17, loss: 1.10, train 86.34%
epoch 17, loss: 0.59, train 86.23%
epoch 17, loss: 0.40, train 86.21%
epoch 17, loss: 0.86, train 86.11%
epoch 17, loss: 0.35, train 86.05%
epoch 17, loss: 1.69, train 85.66%
epoch 17, loss: 0.44, train 85.61%
epoch 17, loss: 0.19, train 85.74%
epoch 17, loss: 0.45, train 85.73%
epoch 17, loss: 0.37, train 85.77%
epoch 17, loss: 0.39, train 85.77%
epoch 17, loss: 0.27, train 85.85%
epoch 17, loss: 0.53, train 85.84%
epoch 17, loss: 0.75, train 85.70%
epoch 17, loss: 0.27, train 85.83%
epoch 17, loss: 0.30, train 85.91%
epoch 17, loss: 0.19, train 86.03%
epoch 17, loss: 0.54, train 86.02%
epoch 17, loss: 0.90, train 85.92%
epoch 17, loss: 0.66, train 85.79%
Epoch completed!
epoch 17, total signals 2400, average_loss_per_batch: 0.432346, train 85.79%
Validating
Val set size: 320, validation accuracy 74.06%
epoch 18, loss: 0.41, train 90.00%
epoch 18, loss: 0.42, train 90.00%
epoch 18, loss: 0.27, train 90.00%
epoch 18, loss: 0.22, train 91.25%
epoch 18, loss: 0.29, train 92.00%
epoch 18, loss: 0.87, train 90.00%
epoch 18, loss: 0.37, train 90.00%
epoch 18, loss: 0.57, train 88.12%
epoch 18, loss: 0.20, train 88.89%
epoch 18, loss: 0.21, train 89.50%
epoch 18, loss: 0.15, train 90.45%
epoch 18, loss: 0.33, train 90.42%
epoch 18, loss: 0.21, train 90.77%
epoch 18, loss: 0.40, train 90.36%
epoch 18, loss: 0.57, train 89.67%
epoch 18, loss: 0.74, train 89.06%
epoch 18, loss: 0.71, train 88.53%
epoch 18, loss: 0.58, train 88.06%
epoch 18, loss: 0.31, train 87.89%
epoch 18, loss: 0.32, train 88.25%
epoch 18, loss: 0.58, train 87.62%
epoch 18, loss: 0.53, train 87.50%
epoch 18, loss: 0.32, train 87.61%
epoch 18, loss: 0.25, train 87.71%
epoch 18, loss: 0.60, train 87.20%
epoch 18, loss: 0.28, train 87.69%
epoch 18, loss: 0.31, train 87.78%
epoch 18, loss: 0.34, train 87.68%
epoch 18, loss: 0.34, train 87.41%
epoch 18, loss: 0.28, train 87.50%
epoch 18, loss: 0.33, train 87.42%
epoch 18, loss: 0.48, train 87.03%
epoch 18, loss: 0.21, train 87.27%
epoch 18, loss: 0.66, train 87.06%
epoch 18, loss: 0.40, train 86.86%
epoch 18, loss: 0.57, train 86.67%
epoch 18, loss: 0.50, train 86.49%
epoch 18, loss: 0.37, train 86.32%
epoch 18, loss: 0.49, train 86.28%
epoch 18, loss: 0.49, train 86.25%
epoch 18, loss: 0.91, train 85.37%
epoch 18, loss: 0.70, train 85.24%
epoch 18, loss: 0.86, train 84.77%
epoch 18, loss: 0.92, train 84.32%
epoch 18, loss: 0.23, train 84.56%
epoch 18, loss: 0.39, train 84.57%
epoch 18, loss: 0.38, train 84.47%
epoch 18, loss: 0.75, train 84.38%
epoch 18, loss: 0.33, train 84.49%
epoch 18, loss: 1.08, train 84.30%
epoch 18, loss: 0.70, train 84.12%
epoch 18, loss: 0.55, train 84.23%
epoch 18, loss: 0.17, train 84.53%
epoch 18, loss: 0.39, train 84.54%
epoch 18, loss: 0.59, train 84.55%
epoch 18, loss: 0.34, train 84.73%
epoch 18, loss: 0.37, train 84.65%
epoch 18, loss: 0.59, train 84.57%
epoch 18, loss: 0.43, train 84.58%
epoch 18, loss: 0.22, train 84.75%
epoch 18, loss: 0.50, train 84.75%
epoch 18, loss: 0.41, train 84.76%
epoch 18, loss: 0.40, train 84.84%
epoch 18, loss: 0.57, train 84.61%
epoch 18, loss: 0.12, train 84.85%
epoch 18, loss: 0.11, train 85.08%
epoch 18, loss: 0.25, train 85.22%
epoch 18, loss: 1.20, train 84.93%
epoch 18, loss: 0.18, train 85.07%
epoch 18, loss: 0.75, train 84.86%
epoch 18, loss: 0.47, train 84.86%
epoch 18, loss: 0.17, train 85.00%
epoch 18, loss: 0.73, train 84.86%
epoch 18, loss: 0.49, train 84.86%
epoch 18, loss: 0.52, train 84.87%
epoch 18, loss: 0.20, train 85.00%
epoch 18, loss: 0.51, train 85.00%
epoch 18, loss: 0.44, train 85.06%
epoch 18, loss: 0.25, train 85.13%
epoch 18, loss: 0.46, train 85.12%
epoch 18, loss: 0.35, train 85.12%
epoch 18, loss: 0.63, train 85.00%
epoch 18, loss: 0.32, train 85.06%
epoch 18, loss: 0.28, train 85.06%
epoch 18, loss: 0.49, train 84.94%
epoch 18, loss: 0.64, train 84.83%
epoch 18, loss: 0.45, train 84.89%
epoch 18, loss: 0.28, train 84.89%
epoch 18, loss: 0.33, train 84.94%
epoch 18, loss: 0.49, train 84.89%
epoch 18, loss: 0.75, train 84.89%
epoch 18, loss: 0.38, train 84.95%
epoch 18, loss: 0.77, train 84.89%
epoch 18, loss: 0.63, train 84.84%
epoch 18, loss: 0.61, train 84.63%
epoch 18, loss: 0.91, train 84.43%
epoch 18, loss: 0.89, train 84.28%
epoch 18, loss: 0.36, train 84.34%
epoch 18, loss: 0.33, train 84.39%
epoch 18, loss: 1.00, train 84.25%
epoch 18, loss: 0.40, train 84.26%
epoch 18, loss: 0.67, train 84.17%
epoch 18, loss: 0.38, train 84.17%
epoch 18, loss: 0.50, train 84.28%
epoch 18, loss: 0.58, train 84.14%
epoch 18, loss: 0.50, train 84.10%
epoch 18, loss: 0.52, train 84.02%
epoch 18, loss: 0.39, train 84.03%
epoch 18, loss: 0.83, train 83.90%
epoch 18, loss: 0.26, train 84.00%
epoch 18, loss: 0.39, train 84.05%
epoch 18, loss: 0.43, train 84.06%
epoch 18, loss: 0.38, train 84.12%
epoch 18, loss: 0.79, train 84.12%
epoch 18, loss: 1.10, train 83.96%
epoch 18, loss: 0.82, train 83.88%
epoch 18, loss: 0.43, train 83.89%
epoch 18, loss: 0.71, train 83.81%
epoch 18, loss: 1.01, train 83.70%
epoch 18, loss: 0.36, train 83.71%
Epoch completed!
epoch 18, total signals 2400, average_loss_per_batch: 0.486788, train 83.71%
Validating
Val set size: 320, validation accuracy 77.19%
epoch 19, loss: 0.16, train 100.00%
epoch 19, loss: 0.36, train 92.50%
epoch 19, loss: 0.27, train 91.67%
epoch 19, loss: 0.22, train 93.75%
epoch 19, loss: 0.22, train 94.00%
epoch 19, loss: 0.47, train 93.33%
epoch 19, loss: 0.43, train 91.43%
epoch 19, loss: 0.41, train 91.25%
epoch 19, loss: 0.41, train 90.56%
epoch 19, loss: 0.27, train 91.00%
epoch 19, loss: 0.26, train 90.91%
epoch 19, loss: 0.33, train 90.42%
epoch 19, loss: 0.35, train 90.38%
epoch 19, loss: 0.19, train 91.07%
epoch 19, loss: 0.63, train 90.00%
epoch 19, loss: 0.31, train 90.00%
epoch 19, loss: 0.82, train 88.82%
epoch 19, loss: 0.17, train 89.17%
epoch 19, loss: 0.20, train 89.47%
epoch 19, loss: 0.21, train 90.00%
epoch 19, loss: 1.07, train 88.57%
epoch 19, loss: 0.45, train 88.41%
epoch 19, loss: 0.51, train 88.48%
epoch 19, loss: 0.28, train 88.54%
epoch 19, loss: 0.27, train 88.60%
epoch 19, loss: 0.10, train 88.85%
epoch 19, loss: 0.53, train 88.52%
epoch 19, loss: 0.47, train 88.39%
epoch 19, loss: 0.55, train 88.10%
epoch 19, loss: 0.33, train 88.33%
epoch 19, loss: 0.40, train 88.39%
epoch 19, loss: 0.50, train 88.28%
epoch 19, loss: 0.44, train 88.18%
epoch 19, loss: 0.21, train 88.38%
epoch 19, loss: 0.10, train 88.71%
epoch 19, loss: 0.58, train 88.47%
epoch 19, loss: 0.58, train 88.38%
epoch 19, loss: 0.33, train 88.42%
epoch 19, loss: 0.30, train 88.33%
epoch 19, loss: 0.42, train 88.25%
epoch 19, loss: 0.63, train 87.93%
epoch 19, loss: 0.42, train 88.10%
epoch 19, loss: 0.50, train 87.91%
epoch 19, loss: 0.51, train 87.84%
epoch 19, loss: 0.36, train 87.89%
epoch 19, loss: 0.23, train 88.04%
epoch 19, loss: 0.12, train 88.30%
epoch 19, loss: 0.76, train 88.12%
epoch 19, loss: 0.49, train 88.06%
epoch 19, loss: 0.31, train 88.10%
epoch 19, loss: 0.75, train 87.75%
epoch 19, loss: 0.68, train 87.79%
epoch 19, loss: 0.31, train 87.83%
epoch 19, loss: 0.41, train 87.69%
epoch 19, loss: 0.39, train 87.64%
epoch 19, loss: 0.68, train 87.32%
epoch 19, loss: 0.34, train 87.19%
epoch 19, loss: 0.32, train 87.16%
epoch 19, loss: 0.67, train 86.95%
epoch 19, loss: 0.40, train 86.83%
epoch 19, loss: 0.23, train 86.97%
epoch 19, loss: 0.46, train 86.85%
epoch 19, loss: 0.24, train 86.90%
epoch 19, loss: 0.72, train 86.72%
epoch 19, loss: 0.22, train 86.85%
epoch 19, loss: 0.28, train 86.89%
epoch 19, loss: 0.15, train 87.01%
epoch 19, loss: 0.18, train 87.13%
epoch 19, loss: 0.35, train 87.03%
epoch 19, loss: 0.63, train 86.93%
epoch 19, loss: 0.54, train 86.83%
epoch 19, loss: 0.23, train 86.94%
epoch 19, loss: 0.68, train 86.78%
epoch 19, loss: 0.38, train 86.82%
epoch 19, loss: 0.94, train 86.60%
epoch 19, loss: 0.38, train 86.58%
epoch 19, loss: 0.63, train 86.36%
epoch 19, loss: 0.51, train 86.35%
epoch 19, loss: 0.28, train 86.33%
epoch 19, loss: 0.15, train 86.50%
epoch 19, loss: 0.69, train 86.42%
epoch 19, loss: 1.01, train 86.10%
epoch 19, loss: 0.40, train 86.08%
epoch 19, loss: 0.41, train 86.01%
epoch 19, loss: 0.46, train 86.00%
epoch 19, loss: 0.71, train 85.93%
epoch 19, loss: 0.53, train 85.98%
epoch 19, loss: 0.29, train 86.08%
epoch 19, loss: 0.86, train 85.84%
epoch 19, loss: 0.29, train 85.94%
epoch 19, loss: 0.26, train 85.99%
epoch 19, loss: 0.26, train 86.09%
epoch 19, loss: 0.68, train 85.97%
epoch 19, loss: 0.76, train 85.74%
epoch 19, loss: 0.42, train 85.68%
epoch 19, loss: 0.46, train 85.62%
epoch 19, loss: 0.54, train 85.52%
epoch 19, loss: 0.42, train 85.51%
epoch 19, loss: 0.45, train 85.51%
epoch 19, loss: 0.63, train 85.35%
epoch 19, loss: 0.36, train 85.30%
epoch 19, loss: 0.39, train 85.29%
epoch 19, loss: 0.24, train 85.39%
epoch 19, loss: 0.63, train 85.34%
epoch 19, loss: 0.29, train 85.29%
epoch 19, loss: 0.60, train 85.28%
epoch 19, loss: 0.52, train 85.28%
epoch 19, loss: 0.20, train 85.37%
epoch 19, loss: 1.30, train 85.09%
epoch 19, loss: 0.41, train 85.14%
epoch 19, loss: 0.66, train 85.05%
epoch 19, loss: 0.77, train 85.00%
epoch 19, loss: 0.67, train 84.91%
epoch 19, loss: 0.20, train 84.96%
epoch 19, loss: 0.23, train 85.04%
epoch 19, loss: 0.35, train 85.09%
epoch 19, loss: 0.29, train 85.09%
epoch 19, loss: 0.68, train 84.96%
epoch 19, loss: 0.52, train 85.00%
epoch 19, loss: 0.58, train 84.92%
Epoch completed!
epoch 19, total signals 2400, average_loss_per_batch: 0.441923, train 84.92%
Validating
Val set size: 320, validation accuracy 78.44%
epoch 20, loss: 0.29, train 90.00%
epoch 20, loss: 0.92, train 75.00%
epoch 20, loss: 0.97, train 71.67%
epoch 20, loss: 0.74, train 72.50%
epoch 20, loss: 0.38, train 76.00%
epoch 20, loss: 0.42, train 78.33%
epoch 20, loss: 0.55, train 79.29%
epoch 20, loss: 0.39, train 79.38%
epoch 20, loss: 0.47, train 80.00%
epoch 20, loss: 0.48, train 80.00%
epoch 20, loss: 0.27, train 80.45%
epoch 20, loss: 0.86, train 79.58%
epoch 20, loss: 1.93, train 76.15%
epoch 20, loss: 0.26, train 77.14%
epoch 20, loss: 0.21, train 78.33%
epoch 20, loss: 0.33, train 79.38%
epoch 20, loss: 0.69, train 79.12%
epoch 20, loss: 0.72, train 78.61%
epoch 20, loss: 0.21, train 79.21%
epoch 20, loss: 0.72, train 79.50%
epoch 20, loss: 0.53, train 79.52%
epoch 20, loss: 0.60, train 79.32%
epoch 20, loss: 0.38, train 79.35%
epoch 20, loss: 0.33, train 79.79%
epoch 20, loss: 0.33, train 80.00%
epoch 20, loss: 0.61, train 79.81%
epoch 20, loss: 0.37, train 80.19%
epoch 20, loss: 1.74, train 78.39%
epoch 20, loss: 0.51, train 78.45%
epoch 20, loss: 0.20, train 79.00%
epoch 20, loss: 0.40, train 79.03%
epoch 20, loss: 0.50, train 79.38%
epoch 20, loss: 0.49, train 79.70%
epoch 20, loss: 1.02, train 79.12%
epoch 20, loss: 0.22, train 79.43%
epoch 20, loss: 0.38, train 79.44%
epoch 20, loss: 0.23, train 79.86%
epoch 20, loss: 0.62, train 79.74%
epoch 20, loss: 0.56, train 79.87%
epoch 20, loss: 0.36, train 80.12%
epoch 20, loss: 0.62, train 80.00%
epoch 20, loss: 0.45, train 80.24%
epoch 20, loss: 0.31, train 80.58%
epoch 20, loss: 0.50, train 80.45%
epoch 20, loss: 0.80, train 80.22%
epoch 20, loss: 0.27, train 80.43%
epoch 20, loss: 0.41, train 80.43%
epoch 20, loss: 0.29, train 80.62%
epoch 20, loss: 0.59, train 80.61%
epoch 20, loss: 1.32, train 80.50%
epoch 20, loss: 0.70, train 80.29%
epoch 20, loss: 0.32, train 80.38%
epoch 20, loss: 0.53, train 80.66%
epoch 20, loss: 1.48, train 80.09%
epoch 20, loss: 0.45, train 80.27%
epoch 20, loss: 0.38, train 80.36%
epoch 20, loss: 0.18, train 80.70%
epoch 20, loss: 0.27, train 80.86%
epoch 20, loss: 0.24, train 81.10%
epoch 20, loss: 0.54, train 81.00%
epoch 20, loss: 0.47, train 80.98%
epoch 20, loss: 0.36, train 81.13%
epoch 20, loss: 0.36, train 81.27%
epoch 20, loss: 0.80, train 81.17%
epoch 20, loss: 0.29, train 81.31%
epoch 20, loss: 0.34, train 81.44%
epoch 20, loss: 0.50, train 81.57%
epoch 20, loss: 1.18, train 81.10%
epoch 20, loss: 0.50, train 81.16%
epoch 20, loss: 0.53, train 81.29%
epoch 20, loss: 0.19, train 81.41%
epoch 20, loss: 0.32, train 81.53%
epoch 20, loss: 0.44, train 81.51%
epoch 20, loss: 0.42, train 81.55%
epoch 20, loss: 0.26, train 81.67%
epoch 20, loss: 0.39, train 81.78%
epoch 20, loss: 0.27, train 81.88%
epoch 20, loss: 0.27, train 81.99%
epoch 20, loss: 0.54, train 82.03%
epoch 20, loss: 0.19, train 82.25%
epoch 20, loss: 0.29, train 82.41%
epoch 20, loss: 0.29, train 82.56%
epoch 20, loss: 0.30, train 82.65%
epoch 20, loss: 0.32, train 82.74%
epoch 20, loss: 0.64, train 82.65%
epoch 20, loss: 0.55, train 82.67%
epoch 20, loss: 0.47, train 82.59%
epoch 20, loss: 0.32, train 82.73%
epoch 20, loss: 0.44, train 82.75%
epoch 20, loss: 0.30, train 82.83%
epoch 20, loss: 0.57, train 82.80%
epoch 20, loss: 0.65, train 82.66%
epoch 20, loss: 0.28, train 82.74%
epoch 20, loss: 0.24, train 82.82%
epoch 20, loss: 0.53, train 82.79%
epoch 20, loss: 0.41, train 82.81%
epoch 20, loss: 0.39, train 82.84%
epoch 20, loss: 0.50, train 82.76%
epoch 20, loss: 0.44, train 82.73%
epoch 20, loss: 0.37, train 82.70%
epoch 20, loss: 0.20, train 82.82%
epoch 20, loss: 0.20, train 82.94%
epoch 20, loss: 0.65, train 82.86%
epoch 20, loss: 0.97, train 82.74%
epoch 20, loss: 0.43, train 82.76%
epoch 20, loss: 0.58, train 82.69%
epoch 20, loss: 0.31, train 82.76%
epoch 20, loss: 0.56, train 82.69%
epoch 20, loss: 0.77, train 82.66%
epoch 20, loss: 0.57, train 82.55%
epoch 20, loss: 0.37, train 82.57%
epoch 20, loss: 0.96, train 82.46%
epoch 20, loss: 0.28, train 82.52%
epoch 20, loss: 0.77, train 82.50%
epoch 20, loss: 0.49, train 82.48%
epoch 20, loss: 0.23, train 82.59%
epoch 20, loss: 0.30, train 82.69%
epoch 20, loss: 0.65, train 82.67%
epoch 20, loss: 0.55, train 82.65%
epoch 20, loss: 0.40, train 82.62%
Epoch completed!
epoch 20, total signals 2400, average_loss_per_batch: 0.500462, train 82.62%
Validating
Val set size: 320, validation accuracy 78.75%
epoch 21, loss: 0.18, train 95.00%
epoch 21, loss: 0.43, train 90.00%
epoch 21, loss: 0.41, train 88.33%
epoch 21, loss: 0.22, train 90.00%
epoch 21, loss: 0.56, train 88.00%
epoch 21, loss: 0.35, train 88.33%
epoch 21, loss: 0.49, train 87.14%
epoch 21, loss: 0.32, train 88.12%
epoch 21, loss: 0.32, train 88.89%
epoch 21, loss: 1.30, train 85.50%
epoch 21, loss: 0.38, train 85.45%
epoch 21, loss: 2.02, train 80.42%
epoch 21, loss: 0.24, train 81.15%
epoch 21, loss: 0.19, train 81.79%
epoch 21, loss: 0.73, train 80.67%
epoch 21, loss: 0.21, train 81.88%
epoch 21, loss: 0.38, train 82.35%
epoch 21, loss: 0.37, train 82.78%
epoch 21, loss: 0.39, train 83.16%
epoch 21, loss: 0.74, train 82.75%
epoch 21, loss: 0.37, train 83.10%
epoch 21, loss: 0.29, train 83.18%
epoch 21, loss: 0.47, train 83.26%
epoch 21, loss: 0.19, train 83.75%
epoch 21, loss: 0.41, train 83.60%
epoch 21, loss: 0.33, train 83.65%
epoch 21, loss: 0.41, train 83.70%
epoch 21, loss: 0.17, train 84.11%
epoch 21, loss: 0.11, train 84.66%
epoch 21, loss: 1.00, train 83.83%
epoch 21, loss: 0.31, train 84.03%
epoch 21, loss: 0.23, train 84.38%
epoch 21, loss: 0.71, train 84.24%
epoch 21, loss: 0.46, train 84.12%
epoch 21, loss: 0.20, train 84.29%
epoch 21, loss: 0.52, train 84.31%
epoch 21, loss: 0.70, train 84.19%
epoch 21, loss: 0.28, train 84.34%
epoch 21, loss: 0.92, train 83.97%
epoch 21, loss: 0.58, train 83.75%
epoch 21, loss: 0.48, train 83.78%
epoch 21, loss: 0.58, train 83.69%
epoch 21, loss: 0.46, train 83.72%
epoch 21, loss: 0.40, train 83.86%
epoch 21, loss: 0.57, train 83.67%
epoch 21, loss: 0.56, train 83.70%
epoch 21, loss: 0.79, train 83.51%
epoch 21, loss: 0.27, train 83.75%
epoch 21, loss: 0.27, train 83.98%
epoch 21, loss: 0.18, train 84.20%
epoch 21, loss: 0.40, train 84.22%
epoch 21, loss: 0.26, train 84.33%
epoch 21, loss: 0.83, train 83.77%
epoch 21, loss: 0.50, train 83.80%
epoch 21, loss: 0.59, train 83.55%
epoch 21, loss: 0.34, train 83.75%
epoch 21, loss: 0.34, train 83.68%
epoch 21, loss: 0.50, train 83.53%
epoch 21, loss: 0.53, train 83.56%
epoch 21, loss: 0.17, train 83.75%
epoch 21, loss: 0.07, train 84.02%
epoch 21, loss: 0.68, train 83.79%
epoch 21, loss: 0.45, train 83.73%
epoch 21, loss: 0.40, train 83.75%
epoch 21, loss: 0.54, train 83.62%
epoch 21, loss: 0.40, train 83.64%
epoch 21, loss: 0.41, train 83.73%
epoch 21, loss: 0.31, train 83.75%
epoch 21, loss: 0.44, train 83.77%
epoch 21, loss: 0.49, train 83.71%
epoch 21, loss: 0.17, train 83.94%
epoch 21, loss: 0.35, train 84.03%
epoch 21, loss: 1.01, train 83.84%
epoch 21, loss: 0.36, train 83.99%
epoch 21, loss: 0.81, train 83.93%
epoch 21, loss: 0.24, train 84.01%
epoch 21, loss: 0.64, train 83.90%
epoch 21, loss: 0.31, train 83.91%
epoch 21, loss: 0.12, train 84.11%
epoch 21, loss: 0.38, train 84.12%
epoch 21, loss: 0.87, train 83.89%
epoch 21, loss: 0.37, train 83.84%
epoch 21, loss: 0.50, train 83.92%
epoch 21, loss: 0.14, train 84.11%
epoch 21, loss: 0.54, train 84.18%
epoch 21, loss: 0.48, train 84.19%
epoch 21, loss: 0.29, train 84.25%
epoch 21, loss: 0.39, train 84.26%
epoch 21, loss: 0.19, train 84.38%
epoch 21, loss: 0.22, train 84.50%
epoch 21, loss: 0.26, train 84.62%
epoch 21, loss: 0.23, train 84.73%
epoch 21, loss: 0.68, train 84.62%
epoch 21, loss: 0.66, train 84.68%
epoch 21, loss: 0.54, train 84.79%
epoch 21, loss: 0.56, train 84.79%
epoch 21, loss: 0.36, train 84.90%
epoch 21, loss: 0.58, train 84.85%
epoch 21, loss: 0.34, train 84.85%
epoch 21, loss: 0.73, train 84.75%
epoch 21, loss: 0.63, train 84.70%
epoch 21, loss: 0.30, train 84.75%
epoch 21, loss: 0.56, train 84.76%
epoch 21, loss: 0.41, train 84.81%
epoch 21, loss: 0.43, train 84.81%
epoch 21, loss: 0.58, train 84.81%
epoch 21, loss: 0.38, train 84.86%
epoch 21, loss: 0.35, train 84.91%
epoch 21, loss: 0.21, train 85.00%
epoch 21, loss: 0.20, train 85.09%
epoch 21, loss: 0.61, train 85.05%
epoch 21, loss: 0.90, train 85.00%
epoch 21, loss: 0.96, train 84.91%
epoch 21, loss: 1.11, train 84.74%
epoch 21, loss: 0.71, train 84.61%
epoch 21, loss: 0.69, train 84.53%
epoch 21, loss: 0.28, train 84.57%
epoch 21, loss: 0.68, train 84.41%
epoch 21, loss: 0.28, train 84.41%
epoch 21, loss: 0.67, train 84.38%
Epoch completed!
epoch 21, total signals 2400, average_loss_per_batch: 0.469280, train 84.38%
Validating
Val set size: 320, validation accuracy 74.38%
epoch 22, loss: 0.23, train 95.00%
epoch 22, loss: 0.57, train 82.50%
epoch 22, loss: 0.48, train 85.00%
epoch 22, loss: 0.23, train 87.50%
epoch 22, loss: 0.28, train 88.00%
epoch 22, loss: 0.40, train 87.50%
epoch 22, loss: 0.40, train 88.57%
epoch 22, loss: 0.25, train 89.38%
epoch 22, loss: 0.21, train 89.44%
epoch 22, loss: 0.33, train 89.50%
epoch 22, loss: 0.13, train 90.45%
epoch 22, loss: 0.27, train 90.83%
epoch 22, loss: 0.45, train 90.77%
epoch 22, loss: 0.18, train 91.43%
epoch 22, loss: 0.17, train 91.67%
epoch 22, loss: 0.13, train 92.19%
epoch 22, loss: 0.52, train 91.76%
epoch 22, loss: 0.25, train 91.94%
epoch 22, loss: 0.29, train 91.84%
epoch 22, loss: 0.63, train 90.75%
epoch 22, loss: 0.26, train 90.71%
epoch 22, loss: 0.44, train 90.45%
epoch 22, loss: 0.75, train 89.78%
epoch 22, loss: 0.14, train 90.21%
epoch 22, loss: 0.17, train 90.20%
epoch 22, loss: 0.52, train 90.00%
epoch 22, loss: 0.24, train 90.19%
epoch 22, loss: 0.52, train 90.00%
epoch 22, loss: 0.35, train 90.00%
epoch 22, loss: 0.40, train 90.00%
epoch 22, loss: 0.28, train 90.00%
epoch 22, loss: 0.34, train 90.00%
epoch 22, loss: 0.36, train 90.00%
epoch 22, loss: 0.62, train 90.15%
epoch 22, loss: 0.21, train 90.43%
epoch 22, loss: 0.43, train 90.14%
epoch 22, loss: 0.22, train 90.27%
epoch 22, loss: 0.39, train 90.13%
epoch 22, loss: 0.20, train 90.38%
epoch 22, loss: 0.49, train 90.12%
epoch 22, loss: 0.28, train 90.24%
epoch 22, loss: 0.13, train 90.48%
epoch 22, loss: 1.17, train 89.88%
epoch 22, loss: 0.17, train 90.11%
epoch 22, loss: 0.39, train 90.11%
epoch 22, loss: 0.79, train 89.78%
epoch 22, loss: 0.34, train 89.79%
epoch 22, loss: 0.35, train 89.79%
epoch 22, loss: 0.56, train 89.69%
epoch 22, loss: 0.25, train 89.70%
epoch 22, loss: 0.21, train 89.71%
epoch 22, loss: 0.32, train 89.81%
epoch 22, loss: 0.51, train 89.72%
epoch 22, loss: 0.30, train 89.63%
epoch 22, loss: 0.81, train 89.36%
epoch 22, loss: 0.87, train 88.93%
epoch 22, loss: 0.38, train 88.86%
epoch 22, loss: 0.45, train 88.71%
epoch 22, loss: 0.29, train 88.81%
epoch 22, loss: 0.50, train 88.75%
epoch 22, loss: 0.25, train 88.85%
epoch 22, loss: 0.36, train 88.87%
epoch 22, loss: 0.81, train 88.57%
epoch 22, loss: 0.23, train 88.67%
epoch 22, loss: 0.50, train 88.54%
epoch 22, loss: 0.25, train 88.56%
epoch 22, loss: 0.30, train 88.66%
epoch 22, loss: 0.73, train 88.46%
epoch 22, loss: 0.20, train 88.55%
epoch 22, loss: 0.27, train 88.64%
epoch 22, loss: 0.84, train 88.52%
epoch 22, loss: 0.87, train 88.19%
epoch 22, loss: 0.44, train 88.15%
epoch 22, loss: 0.45, train 88.04%
epoch 22, loss: 0.21, train 88.13%
epoch 22, loss: 0.38, train 88.09%
epoch 22, loss: 0.65, train 87.92%
epoch 22, loss: 0.71, train 87.69%
epoch 22, loss: 1.01, train 87.34%
epoch 22, loss: 0.34, train 87.44%
epoch 22, loss: 0.96, train 87.16%
epoch 22, loss: 0.37, train 87.13%
epoch 22, loss: 1.00, train 86.99%
epoch 22, loss: 0.59, train 86.85%
epoch 22, loss: 0.70, train 86.59%
epoch 22, loss: 0.51, train 86.63%
epoch 22, loss: 0.22, train 86.72%
epoch 22, loss: 0.63, train 86.59%
epoch 22, loss: 1.18, train 86.24%
epoch 22, loss: 1.18, train 85.94%
epoch 22, loss: 0.56, train 85.88%
epoch 22, loss: 0.22, train 85.92%
epoch 22, loss: 0.54, train 85.86%
epoch 22, loss: 0.30, train 85.90%
epoch 22, loss: 0.85, train 85.74%
epoch 22, loss: 1.09, train 85.52%
epoch 22, loss: 0.39, train 85.57%
epoch 22, loss: 0.40, train 85.56%
epoch 22, loss: 0.15, train 85.66%
epoch 22, loss: 0.54, train 85.60%
epoch 22, loss: 0.30, train 85.59%
epoch 22, loss: 0.64, train 85.59%
epoch 22, loss: 0.66, train 85.53%
epoch 22, loss: 0.28, train 85.62%
epoch 22, loss: 0.21, train 85.76%
epoch 22, loss: 0.76, train 85.66%
epoch 22, loss: 1.10, train 85.56%
epoch 22, loss: 0.58, train 85.46%
epoch 22, loss: 0.49, train 85.41%
epoch 22, loss: 0.22, train 85.50%
epoch 22, loss: 0.53, train 85.45%
epoch 22, loss: 0.16, train 85.54%
epoch 22, loss: 0.46, train 85.53%
epoch 22, loss: 0.63, train 85.31%
epoch 22, loss: 0.16, train 85.43%
epoch 22, loss: 0.23, train 85.52%
epoch 22, loss: 0.58, train 85.43%
epoch 22, loss: 0.39, train 85.38%
epoch 22, loss: 0.57, train 85.34%
epoch 22, loss: 0.90, train 85.25%
Epoch completed!
epoch 22, total signals 2400, average_loss_per_batch: 0.457249, train 85.25%
Validating
Val set size: 320, validation accuracy 70.00%
epoch 23, loss: 0.14, train 95.00%
epoch 23, loss: 0.44, train 92.50%
epoch 23, loss: 0.31, train 91.67%
epoch 23, loss: 0.19, train 92.50%
epoch 23, loss: 0.31, train 92.00%
epoch 23, loss: 0.82, train 89.17%
epoch 23, loss: 0.20, train 90.00%
epoch 23, loss: 0.51, train 89.38%
epoch 23, loss: 0.26, train 90.00%
epoch 23, loss: 0.56, train 88.50%
epoch 23, loss: 0.93, train 86.82%
epoch 23, loss: 0.42, train 86.67%
epoch 23, loss: 0.38, train 87.31%
epoch 23, loss: 0.15, train 87.86%
epoch 23, loss: 0.53, train 87.67%
epoch 23, loss: 0.40, train 87.50%
epoch 23, loss: 0.61, train 87.06%
epoch 23, loss: 0.62, train 86.67%
epoch 23, loss: 0.21, train 87.11%
epoch 23, loss: 0.36, train 87.25%
epoch 23, loss: 0.34, train 87.14%
epoch 23, loss: 0.30, train 87.27%
epoch 23, loss: 0.27, train 87.61%
epoch 23, loss: 0.51, train 87.71%
epoch 23, loss: 0.37, train 87.80%
epoch 23, loss: 0.72, train 87.12%
epoch 23, loss: 0.41, train 87.22%
epoch 23, loss: 0.83, train 86.96%
epoch 23, loss: 0.29, train 87.07%
epoch 23, loss: 0.31, train 87.17%
epoch 23, loss: 0.87, train 86.45%
epoch 23, loss: 0.27, train 86.56%
epoch 23, loss: 0.86, train 86.21%
epoch 23, loss: 0.40, train 86.03%
epoch 23, loss: 0.28, train 86.29%
epoch 23, loss: 0.21, train 86.53%
epoch 23, loss: 0.88, train 85.95%
epoch 23, loss: 0.60, train 85.79%
epoch 23, loss: 0.39, train 86.03%
epoch 23, loss: 0.55, train 85.75%
epoch 23, loss: 0.27, train 85.85%
epoch 23, loss: 0.67, train 85.48%
epoch 23, loss: 0.42, train 85.47%
epoch 23, loss: 0.34, train 85.45%
epoch 23, loss: 0.56, train 85.44%
epoch 23, loss: 0.68, train 85.43%
epoch 23, loss: 0.53, train 85.53%
epoch 23, loss: 0.26, train 85.73%
epoch 23, loss: 0.58, train 85.51%
epoch 23, loss: 0.52, train 85.50%
epoch 23, loss: 0.25, train 85.59%
epoch 23, loss: 0.44, train 85.38%
epoch 23, loss: 0.16, train 85.66%
epoch 23, loss: 0.30, train 85.74%
epoch 23, loss: 0.59, train 85.73%
epoch 23, loss: 0.34, train 85.89%
epoch 23, loss: 0.39, train 86.05%
epoch 23, loss: 0.83, train 85.95%
epoch 23, loss: 0.42, train 86.02%
epoch 23, loss: 0.45, train 86.17%
epoch 23, loss: 0.43, train 86.15%
epoch 23, loss: 0.32, train 86.21%
epoch 23, loss: 0.54, train 86.27%
epoch 23, loss: 0.27, train 86.33%
epoch 23, loss: 0.69, train 86.23%
epoch 23, loss: 0.40, train 86.21%
epoch 23, loss: 0.23, train 86.34%
epoch 23, loss: 0.23, train 86.47%
epoch 23, loss: 0.22, train 86.59%
epoch 23, loss: 0.34, train 86.57%
epoch 23, loss: 0.66, train 86.41%
epoch 23, loss: 0.71, train 86.11%
epoch 23, loss: 0.38, train 86.10%
epoch 23, loss: 0.38, train 86.15%
epoch 23, loss: 0.34, train 86.13%
epoch 23, loss: 0.30, train 86.18%
epoch 23, loss: 0.87, train 86.04%
epoch 23, loss: 0.49, train 86.03%
epoch 23, loss: 0.13, train 86.14%
epoch 23, loss: 0.56, train 86.12%
epoch 23, loss: 0.21, train 86.23%
epoch 23, loss: 0.31, train 86.28%
epoch 23, loss: 0.49, train 86.20%
epoch 23, loss: 0.44, train 86.13%
epoch 23, loss: 0.39, train 86.18%
epoch 23, loss: 0.28, train 86.28%
epoch 23, loss: 0.50, train 86.15%
epoch 23, loss: 0.48, train 86.19%
epoch 23, loss: 0.98, train 85.84%
epoch 23, loss: 0.59, train 85.83%
epoch 23, loss: 0.86, train 85.77%
epoch 23, loss: 0.67, train 85.71%
epoch 23, loss: 0.53, train 85.70%
epoch 23, loss: 0.66, train 85.64%
epoch 23, loss: 0.47, train 85.68%
epoch 23, loss: 0.79, train 85.57%
epoch 23, loss: 0.38, train 85.57%
epoch 23, loss: 0.80, train 85.41%
epoch 23, loss: 0.73, train 85.40%
epoch 23, loss: 0.51, train 85.35%
epoch 23, loss: 0.17, train 85.45%
epoch 23, loss: 0.20, train 85.59%
epoch 23, loss: 0.83, train 85.44%
epoch 23, loss: 0.62, train 85.38%
epoch 23, loss: 1.44, train 85.10%
epoch 23, loss: 0.89, train 85.00%
epoch 23, loss: 0.60, train 85.00%
epoch 23, loss: 0.54, train 85.05%
epoch 23, loss: 0.17, train 85.09%
epoch 23, loss: 0.50, train 85.00%
epoch 23, loss: 0.34, train 85.05%
epoch 23, loss: 0.62, train 85.00%
epoch 23, loss: 0.31, train 85.04%
epoch 23, loss: 0.42, train 85.04%
epoch 23, loss: 1.08, train 84.74%
epoch 23, loss: 0.57, train 84.74%
epoch 23, loss: 0.16, train 84.87%
epoch 23, loss: 0.28, train 84.92%
epoch 23, loss: 0.76, train 84.83%
epoch 23, loss: 1.02, train 84.75%
Epoch completed!
epoch 23, total signals 2400, average_loss_per_batch: 0.483999, train 84.75%
Validating
Val set size: 320, validation accuracy 78.75%
epoch 24, loss: 0.52, train 85.00%
epoch 24, loss: 1.07, train 67.50%
epoch 24, loss: 0.20, train 76.67%
epoch 24, loss: 0.26, train 80.00%
epoch 24, loss: 0.67, train 80.00%
epoch 24, loss: 0.31, train 81.67%
epoch 24, loss: 0.28, train 83.57%
epoch 24, loss: 0.15, train 85.62%
epoch 24, loss: 0.28, train 87.22%
epoch 24, loss: 0.10, train 88.50%
epoch 24, loss: 0.47, train 88.64%
epoch 24, loss: 0.23, train 89.58%
epoch 24, loss: 0.75, train 88.85%
epoch 24, loss: 0.29, train 88.57%
epoch 24, loss: 0.37, train 88.67%
epoch 24, loss: 0.17, train 89.06%
epoch 24, loss: 0.54, train 88.53%
epoch 24, loss: 0.21, train 88.89%
epoch 24, loss: 0.26, train 88.95%
epoch 24, loss: 0.23, train 89.25%
epoch 24, loss: 0.23, train 89.29%
epoch 24, loss: 0.44, train 89.32%
epoch 24, loss: 0.10, train 89.78%
epoch 24, loss: 0.14, train 90.21%
epoch 24, loss: 0.88, train 89.00%
epoch 24, loss: 0.49, train 88.46%
epoch 24, loss: 0.99, train 87.41%
epoch 24, loss: 0.24, train 87.50%
epoch 24, loss: 0.16, train 87.76%
epoch 24, loss: 0.29, train 87.83%
epoch 24, loss: 0.36, train 87.74%
epoch 24, loss: 0.34, train 87.97%
epoch 24, loss: 0.23, train 88.18%
epoch 24, loss: 0.14, train 88.53%
epoch 24, loss: 0.15, train 88.86%
epoch 24, loss: 0.29, train 88.89%
epoch 24, loss: 0.45, train 88.92%
epoch 24, loss: 0.15, train 89.08%
epoch 24, loss: 0.17, train 89.23%
epoch 24, loss: 0.56, train 89.00%
epoch 24, loss: 0.23, train 89.15%
epoch 24, loss: 0.43, train 88.93%
epoch 24, loss: 0.14, train 89.19%
epoch 24, loss: 0.61, train 88.98%
epoch 24, loss: 0.13, train 89.22%
epoch 24, loss: 0.17, train 89.35%
epoch 24, loss: 0.42, train 89.36%
epoch 24, loss: 0.40, train 89.06%
epoch 24, loss: 0.26, train 89.18%
epoch 24, loss: 0.07, train 89.40%
epoch 24, loss: 0.16, train 89.51%
epoch 24, loss: 0.24, train 89.62%
epoch 24, loss: 0.27, train 89.62%
epoch 24, loss: 0.32, train 89.54%
epoch 24, loss: 0.26, train 89.64%
epoch 24, loss: 0.17, train 89.82%
epoch 24, loss: 0.35, train 89.82%
epoch 24, loss: 0.30, train 89.83%
epoch 24, loss: 0.82, train 89.58%
epoch 24, loss: 0.20, train 89.67%
epoch 24, loss: 0.26, train 89.75%
epoch 24, loss: 0.26, train 89.84%
epoch 24, loss: 0.27, train 89.84%
epoch 24, loss: 0.43, train 89.84%
epoch 24, loss: 0.31, train 89.85%
epoch 24, loss: 0.27, train 89.92%
epoch 24, loss: 0.21, train 90.07%
epoch 24, loss: 0.43, train 90.07%
epoch 24, loss: 0.28, train 90.07%
epoch 24, loss: 0.44, train 89.93%
epoch 24, loss: 0.14, train 90.07%
epoch 24, loss: 0.25, train 90.21%
epoch 24, loss: 0.26, train 90.21%
epoch 24, loss: 0.26, train 90.27%
epoch 24, loss: 0.28, train 90.33%
epoch 24, loss: 0.21, train 90.46%
epoch 24, loss: 0.21, train 90.52%
epoch 24, loss: 0.24, train 90.64%
epoch 24, loss: 0.22, train 90.70%
epoch 24, loss: 0.31, train 90.69%
epoch 24, loss: 0.38, train 90.74%
epoch 24, loss: 0.18, train 90.85%
epoch 24, loss: 0.18, train 90.96%
epoch 24, loss: 0.42, train 90.83%
epoch 24, loss: 0.14, train 90.94%
epoch 24, loss: 0.21, train 91.05%
epoch 24, loss: 0.17, train 91.09%
epoch 24, loss: 0.19, train 91.19%
epoch 24, loss: 0.21, train 91.18%
epoch 24, loss: 0.19, train 91.22%
epoch 24, loss: 0.33, train 91.21%
epoch 24, loss: 0.14, train 91.30%
epoch 24, loss: 0.30, train 91.29%
epoch 24, loss: 0.57, train 91.17%
epoch 24, loss: 0.58, train 91.05%
epoch 24, loss: 0.48, train 91.04%
epoch 24, loss: 0.18, train 91.13%
epoch 24, loss: 0.27, train 91.12%
epoch 24, loss: 0.10, train 91.16%
epoch 24, loss: 0.42, train 91.10%
epoch 24, loss: 0.17, train 91.14%
epoch 24, loss: 0.26, train 91.18%
epoch 24, loss: 0.27, train 91.17%
epoch 24, loss: 0.22, train 91.20%
epoch 24, loss: 0.25, train 91.24%
epoch 24, loss: 0.39, train 91.23%
epoch 24, loss: 0.33, train 91.21%
epoch 24, loss: 0.29, train 91.20%
epoch 24, loss: 0.23, train 91.24%
epoch 24, loss: 0.30, train 91.18%
epoch 24, loss: 0.20, train 91.26%
epoch 24, loss: 0.12, train 91.34%
epoch 24, loss: 0.11, train 91.37%
epoch 24, loss: 0.69, train 91.27%
epoch 24, loss: 0.12, train 91.35%
epoch 24, loss: 0.14, train 91.42%
epoch 24, loss: 0.29, train 91.45%
epoch 24, loss: 0.56, train 91.44%
epoch 24, loss: 0.06, train 91.51%
epoch 24, loss: 0.54, train 91.46%
Epoch completed!
epoch 24, total signals 2400, average_loss_per_batch: 0.306507, train 91.46%
Validating
Val set size: 320, validation accuracy 80.31%
epoch 25, loss: 0.45, train 85.00%
epoch 25, loss: 0.29, train 90.00%
epoch 25, loss: 0.48, train 86.67%
epoch 25, loss: 0.16, train 90.00%
epoch 25, loss: 0.13, train 92.00%
epoch 25, loss: 0.40, train 90.83%
epoch 25, loss: 0.22, train 91.43%
epoch 25, loss: 0.26, train 91.88%
epoch 25, loss: 0.19, train 92.22%
epoch 25, loss: 0.26, train 92.00%
epoch 25, loss: 0.19, train 92.27%
epoch 25, loss: 0.23, train 92.08%
epoch 25, loss: 0.12, train 92.69%
epoch 25, loss: 0.42, train 92.86%
epoch 25, loss: 0.12, train 93.00%
epoch 25, loss: 0.24, train 93.12%
epoch 25, loss: 0.22, train 92.65%
epoch 25, loss: 0.56, train 91.67%
epoch 25, loss: 0.12, train 92.11%
epoch 25, loss: 0.19, train 92.50%
epoch 25, loss: 0.47, train 92.62%
epoch 25, loss: 0.31, train 92.50%
epoch 25, loss: 0.30, train 92.39%
epoch 25, loss: 0.15, train 92.50%
epoch 25, loss: 0.13, train 92.80%
epoch 25, loss: 0.63, train 92.50%
epoch 25, loss: 0.21, train 92.59%
epoch 25, loss: 0.22, train 92.68%
epoch 25, loss: 0.38, train 92.59%
epoch 25, loss: 0.34, train 92.50%
epoch 25, loss: 0.29, train 92.58%
epoch 25, loss: 0.31, train 92.81%
epoch 25, loss: 0.10, train 93.03%
epoch 25, loss: 0.18, train 93.24%
epoch 25, loss: 0.63, train 92.71%
epoch 25, loss: 0.19, train 92.92%
epoch 25, loss: 0.31, train 92.84%
epoch 25, loss: 0.88, train 92.50%
epoch 25, loss: 0.56, train 92.18%
epoch 25, loss: 0.30, train 92.38%
epoch 25, loss: 0.28, train 92.44%
epoch 25, loss: 0.48, train 92.38%
epoch 25, loss: 0.37, train 92.56%
epoch 25, loss: 0.20, train 92.50%
epoch 25, loss: 0.30, train 92.33%
epoch 25, loss: 0.22, train 92.39%
epoch 25, loss: 0.16, train 92.45%
epoch 25, loss: 0.07, train 92.60%
epoch 25, loss: 0.30, train 92.45%
epoch 25, loss: 0.08, train 92.60%
epoch 25, loss: 0.16, train 92.65%
epoch 25, loss: 0.34, train 92.50%
epoch 25, loss: 0.20, train 92.64%
epoch 25, loss: 0.12, train 92.78%
epoch 25, loss: 0.13, train 92.91%
epoch 25, loss: 0.25, train 92.86%
epoch 25, loss: 0.36, train 92.54%
epoch 25, loss: 0.15, train 92.67%
epoch 25, loss: 0.15, train 92.80%
epoch 25, loss: 0.16, train 92.83%
epoch 25, loss: 0.66, train 92.70%
epoch 25, loss: 0.30, train 92.74%
epoch 25, loss: 0.36, train 92.86%
epoch 25, loss: 0.12, train 92.97%
epoch 25, loss: 0.12, train 93.00%
epoch 25, loss: 0.23, train 92.95%
epoch 25, loss: 0.72, train 92.84%
epoch 25, loss: 0.48, train 92.79%
epoch 25, loss: 0.23, train 92.83%
epoch 25, loss: 0.22, train 92.79%
epoch 25, loss: 0.22, train 92.82%
epoch 25, loss: 0.13, train 92.92%
epoch 25, loss: 0.34, train 92.88%
epoch 25, loss: 0.11, train 92.97%
epoch 25, loss: 0.15, train 93.00%
epoch 25, loss: 0.14, train 93.09%
epoch 25, loss: 0.19, train 93.12%
epoch 25, loss: 0.22, train 93.08%
epoch 25, loss: 0.13, train 93.10%
epoch 25, loss: 0.18, train 93.19%
epoch 25, loss: 0.09, train 93.27%
epoch 25, loss: 0.21, train 93.29%
epoch 25, loss: 0.11, train 93.37%
epoch 25, loss: 0.31, train 93.39%
epoch 25, loss: 0.31, train 93.41%
epoch 25, loss: 0.14, train 93.49%
epoch 25, loss: 0.08, train 93.56%
epoch 25, loss: 0.09, train 93.64%
epoch 25, loss: 0.41, train 93.60%
epoch 25, loss: 0.15, train 93.67%
epoch 25, loss: 0.39, train 93.57%
epoch 25, loss: 0.18, train 93.64%
epoch 25, loss: 0.20, train 93.71%
epoch 25, loss: 0.18, train 93.72%
epoch 25, loss: 0.74, train 93.47%
epoch 25, loss: 0.10, train 93.54%
epoch 25, loss: 0.18, train 93.61%
epoch 25, loss: 0.29, train 93.57%
epoch 25, loss: 0.17, train 93.64%
epoch 25, loss: 0.17, train 93.65%
epoch 25, loss: 0.21, train 93.66%
epoch 25, loss: 0.46, train 93.63%
epoch 25, loss: 0.32, train 93.54%
epoch 25, loss: 0.33, train 93.56%
epoch 25, loss: 0.50, train 93.52%
epoch 25, loss: 0.24, train 93.49%
epoch 25, loss: 0.49, train 93.41%
epoch 25, loss: 0.17, train 93.47%
epoch 25, loss: 0.43, train 93.53%
epoch 25, loss: 0.15, train 93.55%
epoch 25, loss: 0.07, train 93.60%
epoch 25, loss: 0.17, train 93.66%
epoch 25, loss: 0.44, train 93.67%
epoch 25, loss: 0.19, train 93.73%
epoch 25, loss: 0.26, train 93.74%
epoch 25, loss: 0.19, train 93.75%
epoch 25, loss: 0.20, train 93.76%
epoch 25, loss: 0.34, train 93.73%
epoch 25, loss: 0.22, train 93.70%
epoch 25, loss: 0.19, train 93.71%
Epoch completed!
epoch 25, total signals 2400, average_loss_per_batch: 0.266894, train 93.71%
Validating
Val set size: 320, validation accuracy 81.88%
epoch 26, loss: 0.33, train 85.00%
epoch 26, loss: 0.79, train 77.50%
epoch 26, loss: 0.14, train 83.33%
epoch 26, loss: 0.18, train 86.25%
epoch 26, loss: 0.18, train 87.00%
epoch 26, loss: 0.12, train 89.17%
epoch 26, loss: 0.34, train 88.57%
epoch 26, loss: 0.25, train 89.38%
epoch 26, loss: 0.27, train 89.44%
epoch 26, loss: 0.24, train 90.00%
epoch 26, loss: 0.15, train 90.45%
epoch 26, loss: 0.53, train 89.17%
epoch 26, loss: 0.13, train 89.62%
epoch 26, loss: 0.20, train 90.00%
epoch 26, loss: 0.07, train 90.67%
epoch 26, loss: 0.09, train 91.25%
epoch 26, loss: 0.16, train 91.76%
epoch 26, loss: 0.12, train 92.22%
epoch 26, loss: 0.27, train 92.11%
epoch 26, loss: 0.10, train 92.25%
epoch 26, loss: 0.15, train 92.62%
epoch 26, loss: 0.15, train 92.95%
epoch 26, loss: 0.52, train 92.61%
epoch 26, loss: 0.13, train 92.92%
epoch 26, loss: 0.24, train 92.80%
epoch 26, loss: 0.49, train 92.50%
epoch 26, loss: 0.32, train 92.22%
epoch 26, loss: 0.20, train 92.32%
epoch 26, loss: 0.12, train 92.59%
epoch 26, loss: 0.10, train 92.83%
epoch 26, loss: 0.25, train 92.90%
epoch 26, loss: 0.46, train 92.50%
epoch 26, loss: 0.30, train 92.42%
epoch 26, loss: 0.17, train 92.50%
epoch 26, loss: 0.36, train 92.57%
epoch 26, loss: 0.34, train 92.50%
epoch 26, loss: 0.28, train 92.57%
epoch 26, loss: 0.16, train 92.50%
epoch 26, loss: 0.16, train 92.69%
epoch 26, loss: 0.17, train 92.88%
epoch 26, loss: 0.15, train 92.80%
epoch 26, loss: 0.15, train 92.86%
epoch 26, loss: 0.12, train 92.91%
epoch 26, loss: 0.15, train 92.95%
epoch 26, loss: 0.37, train 92.89%
epoch 26, loss: 0.29, train 92.83%
epoch 26, loss: 0.38, train 92.55%
epoch 26, loss: 0.61, train 92.50%
epoch 26, loss: 0.81, train 92.24%
epoch 26, loss: 0.32, train 92.10%
epoch 26, loss: 0.15, train 92.25%
epoch 26, loss: 0.27, train 92.31%
epoch 26, loss: 0.16, train 92.36%
epoch 26, loss: 0.28, train 92.22%
epoch 26, loss: 0.14, train 92.36%
epoch 26, loss: 0.52, train 92.23%
epoch 26, loss: 1.23, train 91.75%
epoch 26, loss: 0.15, train 91.90%
epoch 26, loss: 0.23, train 91.95%
epoch 26, loss: 0.22, train 91.92%
epoch 26, loss: 0.12, train 92.05%
epoch 26, loss: 0.44, train 92.10%
epoch 26, loss: 0.12, train 92.14%
epoch 26, loss: 0.14, train 92.19%
epoch 26, loss: 0.24, train 92.31%
epoch 26, loss: 0.12, train 92.42%
epoch 26, loss: 0.23, train 92.46%
epoch 26, loss: 0.08, train 92.57%
epoch 26, loss: 0.12, train 92.68%
epoch 26, loss: 0.32, train 92.57%
epoch 26, loss: 0.27, train 92.61%
epoch 26, loss: 0.12, train 92.64%
epoch 26, loss: 0.19, train 92.67%
epoch 26, loss: 0.29, train 92.70%
epoch 26, loss: 0.30, train 92.67%
epoch 26, loss: 0.35, train 92.57%
epoch 26, loss: 0.55, train 92.40%
epoch 26, loss: 0.27, train 92.37%
epoch 26, loss: 0.14, train 92.41%
epoch 26, loss: 0.40, train 92.44%
epoch 26, loss: 0.53, train 92.41%
epoch 26, loss: 0.56, train 92.38%
epoch 26, loss: 0.17, train 92.47%
epoch 26, loss: 0.15, train 92.50%
epoch 26, loss: 0.20, train 92.53%
epoch 26, loss: 0.13, train 92.56%
epoch 26, loss: 0.15, train 92.64%
epoch 26, loss: 0.19, train 92.67%
epoch 26, loss: 0.25, train 92.75%
epoch 26, loss: 0.15, train 92.83%
epoch 26, loss: 0.09, train 92.91%
epoch 26, loss: 0.26, train 92.88%
epoch 26, loss: 0.17, train 92.96%
epoch 26, loss: 0.14, train 93.03%
epoch 26, loss: 0.20, train 93.11%
epoch 26, loss: 0.39, train 93.07%
epoch 26, loss: 0.18, train 93.09%
epoch 26, loss: 0.12, train 93.16%
epoch 26, loss: 0.18, train 93.18%
epoch 26, loss: 0.15, train 93.25%
epoch 26, loss: 0.26, train 93.27%
epoch 26, loss: 0.21, train 93.33%
epoch 26, loss: 0.41, train 93.25%
epoch 26, loss: 0.10, train 93.32%
epoch 26, loss: 0.15, train 93.33%
epoch 26, loss: 0.18, train 93.35%
epoch 26, loss: 0.16, train 93.41%
epoch 26, loss: 0.41, train 93.43%
epoch 26, loss: 0.21, train 93.44%
epoch 26, loss: 0.26, train 93.41%
epoch 26, loss: 0.59, train 93.38%
epoch 26, loss: 0.22, train 93.39%
epoch 26, loss: 0.24, train 93.36%
epoch 26, loss: 0.07, train 93.42%
epoch 26, loss: 0.16, train 93.43%
epoch 26, loss: 0.36, train 93.36%
epoch 26, loss: 0.25, train 93.33%
epoch 26, loss: 0.26, train 93.35%
epoch 26, loss: 0.32, train 93.36%
epoch 26, loss: 0.20, train 93.38%
Epoch completed!
epoch 26, total signals 2400, average_loss_per_batch: 0.255871, train 93.38%
Validating
Val set size: 320, validation accuracy 82.50%
epoch 27, loss: 0.21, train 90.00%
epoch 27, loss: 0.15, train 92.50%
epoch 27, loss: 0.26, train 93.33%
epoch 27, loss: 0.30, train 92.50%
epoch 27, loss: 0.10, train 94.00%
epoch 27, loss: 0.16, train 95.00%
epoch 27, loss: 0.20, train 95.00%
epoch 27, loss: 0.11, train 95.62%
epoch 27, loss: 0.20, train 95.00%
epoch 27, loss: 0.11, train 95.50%
epoch 27, loss: 0.31, train 95.00%
epoch 27, loss: 0.21, train 94.58%
epoch 27, loss: 0.17, train 95.00%
epoch 27, loss: 0.15, train 95.00%
epoch 27, loss: 0.19, train 95.33%
epoch 27, loss: 0.12, train 95.62%
epoch 27, loss: 0.18, train 95.59%
epoch 27, loss: 0.38, train 95.00%
epoch 27, loss: 0.09, train 95.26%
epoch 27, loss: 0.14, train 95.25%
epoch 27, loss: 0.47, train 94.52%
epoch 27, loss: 0.47, train 94.32%
epoch 27, loss: 0.43, train 93.70%
epoch 27, loss: 0.06, train 93.96%
epoch 27, loss: 0.21, train 94.00%
epoch 27, loss: 0.41, train 93.85%
epoch 27, loss: 0.13, train 94.07%
epoch 27, loss: 0.16, train 94.29%
epoch 27, loss: 0.22, train 94.14%
epoch 27, loss: 0.18, train 94.00%
epoch 27, loss: 0.23, train 93.87%
epoch 27, loss: 0.16, train 94.06%
epoch 27, loss: 0.27, train 94.24%
epoch 27, loss: 0.11, train 94.26%
epoch 27, loss: 0.21, train 94.14%
epoch 27, loss: 0.38, train 94.03%
epoch 27, loss: 1.14, train 92.84%
epoch 27, loss: 0.28, train 92.89%
epoch 27, loss: 0.33, train 93.08%
epoch 27, loss: 0.12, train 93.25%
epoch 27, loss: 0.16, train 93.41%
epoch 27, loss: 0.15, train 93.57%
epoch 27, loss: 0.10, train 93.60%
epoch 27, loss: 0.16, train 93.64%
epoch 27, loss: 0.58, train 93.44%
epoch 27, loss: 0.15, train 93.59%
epoch 27, loss: 0.19, train 93.72%
epoch 27, loss: 0.26, train 93.75%
epoch 27, loss: 0.17, train 93.88%
epoch 27, loss: 0.13, train 93.90%
epoch 27, loss: 0.77, train 93.63%
epoch 27, loss: 0.34, train 93.56%
epoch 27, loss: 1.09, train 92.83%
epoch 27, loss: 0.11, train 92.96%
epoch 27, loss: 0.18, train 93.00%
epoch 27, loss: 0.13, train 93.04%
epoch 27, loss: 0.40, train 93.07%
epoch 27, loss: 0.20, train 93.02%
epoch 27, loss: 0.23, train 93.05%
epoch 27, loss: 0.21, train 93.08%
epoch 27, loss: 0.12, train 93.20%
epoch 27, loss: 0.13, train 93.31%
epoch 27, loss: 0.23, train 93.33%
epoch 27, loss: 0.25, train 93.36%
epoch 27, loss: 0.27, train 93.38%
epoch 27, loss: 0.21, train 93.41%
epoch 27, loss: 0.27, train 93.36%
epoch 27, loss: 0.15, train 93.38%
epoch 27, loss: 0.15, train 93.48%
epoch 27, loss: 0.24, train 93.50%
epoch 27, loss: 0.12, train 93.59%
epoch 27, loss: 0.07, train 93.68%
epoch 27, loss: 0.13, train 93.77%
epoch 27, loss: 0.16, train 93.78%
epoch 27, loss: 0.10, train 93.87%
epoch 27, loss: 0.37, train 93.88%
epoch 27, loss: 0.13, train 93.96%
epoch 27, loss: 0.13, train 94.04%
epoch 27, loss: 0.30, train 93.92%
epoch 27, loss: 0.26, train 93.94%
epoch 27, loss: 0.11, train 94.01%
epoch 27, loss: 0.15, train 94.09%
epoch 27, loss: 0.27, train 94.04%
epoch 27, loss: 0.39, train 93.93%
epoch 27, loss: 0.21, train 93.94%
epoch 27, loss: 0.24, train 93.90%
epoch 27, loss: 0.10, train 93.97%
epoch 27, loss: 0.19, train 93.98%
epoch 27, loss: 0.13, train 94.04%
epoch 27, loss: 0.40, train 94.00%
epoch 27, loss: 0.15, train 94.07%
epoch 27, loss: 0.12, train 94.13%
epoch 27, loss: 0.28, train 94.14%
epoch 27, loss: 0.25, train 94.15%
epoch 27, loss: 0.24, train 94.16%
epoch 27, loss: 0.09, train 94.22%
epoch 27, loss: 0.21, train 94.23%
epoch 27, loss: 0.13, train 94.29%
epoch 27, loss: 0.14, train 94.29%
epoch 27, loss: 0.19, train 94.30%
epoch 27, loss: 0.30, train 94.26%
epoch 27, loss: 0.20, train 94.26%
epoch 27, loss: 0.23, train 94.22%
epoch 27, loss: 0.31, train 94.23%
epoch 27, loss: 0.11, train 94.24%
epoch 27, loss: 0.17, train 94.25%
epoch 27, loss: 0.21, train 94.30%
epoch 27, loss: 0.10, train 94.35%
epoch 27, loss: 0.16, train 94.40%
epoch 27, loss: 0.51, train 94.27%
epoch 27, loss: 0.22, train 94.28%
epoch 27, loss: 0.09, train 94.33%
epoch 27, loss: 0.13, train 94.38%
epoch 27, loss: 0.27, train 94.34%
epoch 27, loss: 0.43, train 94.30%
epoch 27, loss: 0.21, train 94.27%
epoch 27, loss: 0.11, train 94.32%
epoch 27, loss: 0.18, train 94.32%
epoch 27, loss: 0.16, train 94.37%
epoch 27, loss: 0.23, train 94.38%
Epoch completed!
epoch 27, total signals 2400, average_loss_per_batch: 0.229153, train 94.38%
Validating
Val set size: 320, validation accuracy 80.94%
epoch 28, loss: 0.14, train 100.00%
epoch 28, loss: 0.17, train 100.00%
epoch 28, loss: 0.21, train 98.33%
epoch 28, loss: 0.27, train 95.00%
epoch 28, loss: 0.23, train 95.00%
epoch 28, loss: 0.10, train 95.83%
epoch 28, loss: 0.14, train 95.71%
epoch 28, loss: 0.10, train 96.25%
epoch 28, loss: 0.11, train 96.11%
epoch 28, loss: 0.16, train 95.50%
epoch 28, loss: 0.58, train 95.00%
epoch 28, loss: 0.16, train 95.42%
epoch 28, loss: 0.10, train 95.77%
epoch 28, loss: 0.29, train 95.71%
epoch 28, loss: 0.10, train 96.00%
epoch 28, loss: 0.23, train 95.94%
epoch 28, loss: 0.24, train 96.18%
epoch 28, loss: 0.56, train 95.83%
epoch 28, loss: 0.20, train 96.05%
epoch 28, loss: 0.24, train 96.00%
epoch 28, loss: 0.19, train 95.95%
epoch 28, loss: 0.22, train 95.91%
epoch 28, loss: 0.16, train 95.87%
epoch 28, loss: 0.18, train 95.62%
epoch 28, loss: 0.41, train 95.60%
epoch 28, loss: 0.15, train 95.58%
epoch 28, loss: 0.19, train 95.56%
epoch 28, loss: 0.44, train 95.54%
epoch 28, loss: 0.12, train 95.52%
epoch 28, loss: 0.13, train 95.67%
epoch 28, loss: 0.16, train 95.81%
epoch 28, loss: 0.45, train 95.62%
epoch 28, loss: 0.34, train 95.45%
epoch 28, loss: 0.18, train 95.44%
epoch 28, loss: 0.30, train 95.43%
epoch 28, loss: 0.51, train 95.00%
epoch 28, loss: 0.56, train 94.73%
epoch 28, loss: 0.07, train 94.87%
epoch 28, loss: 0.19, train 95.00%
epoch 28, loss: 0.17, train 95.12%
epoch 28, loss: 0.18, train 95.12%
epoch 28, loss: 0.41, train 95.00%
epoch 28, loss: 0.32, train 94.88%
epoch 28, loss: 0.43, train 94.77%
epoch 28, loss: 0.12, train 94.89%
epoch 28, loss: 0.40, train 94.78%
epoch 28, loss: 0.18, train 94.68%
epoch 28, loss: 0.13, train 94.79%
epoch 28, loss: 0.21, train 94.80%
epoch 28, loss: 0.35, train 94.70%
epoch 28, loss: 0.15, train 94.71%
epoch 28, loss: 0.32, train 94.62%
epoch 28, loss: 0.26, train 94.53%
epoch 28, loss: 0.07, train 94.63%
epoch 28, loss: 0.27, train 94.73%
epoch 28, loss: 0.24, train 94.64%
epoch 28, loss: 0.23, train 94.56%
epoch 28, loss: 0.18, train 94.57%
epoch 28, loss: 0.13, train 94.66%
epoch 28, loss: 0.08, train 94.75%
epoch 28, loss: 0.39, train 94.59%
epoch 28, loss: 0.24, train 94.60%
epoch 28, loss: 0.08, train 94.68%
epoch 28, loss: 0.16, train 94.77%
epoch 28, loss: 0.78, train 94.38%
epoch 28, loss: 0.14, train 94.39%
epoch 28, loss: 0.28, train 94.33%
epoch 28, loss: 0.15, train 94.41%
epoch 28, loss: 0.09, train 94.49%
epoch 28, loss: 0.29, train 94.50%
epoch 28, loss: 0.09, train 94.58%
epoch 28, loss: 0.17, train 94.58%
epoch 28, loss: 0.13, train 94.59%
epoch 28, loss: 0.30, train 94.59%
epoch 28, loss: 0.14, train 94.60%
epoch 28, loss: 0.25, train 94.54%
epoch 28, loss: 0.10, train 94.61%
epoch 28, loss: 0.38, train 94.55%
epoch 28, loss: 0.09, train 94.62%
epoch 28, loss: 0.14, train 94.69%
epoch 28, loss: 0.16, train 94.69%
epoch 28, loss: 0.09, train 94.76%
epoch 28, loss: 0.11, train 94.82%
epoch 28, loss: 0.11, train 94.88%
epoch 28, loss: 0.24, train 94.82%
epoch 28, loss: 0.33, train 94.71%
epoch 28, loss: 0.10, train 94.77%
epoch 28, loss: 0.18, train 94.77%
epoch 28, loss: 0.19, train 94.78%
epoch 28, loss: 0.95, train 94.72%
epoch 28, loss: 0.14, train 94.73%
epoch 28, loss: 0.19, train 94.73%
epoch 28, loss: 0.32, train 94.68%
epoch 28, loss: 0.38, train 94.73%
epoch 28, loss: 0.35, train 94.63%
epoch 28, loss: 0.12, train 94.69%
epoch 28, loss: 0.35, train 94.64%
epoch 28, loss: 0.09, train 94.69%
epoch 28, loss: 0.23, train 94.65%
epoch 28, loss: 0.45, train 94.50%
epoch 28, loss: 0.19, train 94.50%
epoch 28, loss: 0.07, train 94.56%
epoch 28, loss: 0.13, train 94.61%
epoch 28, loss: 0.12, train 94.62%
epoch 28, loss: 0.20, train 94.62%
epoch 28, loss: 0.33, train 94.53%
epoch 28, loss: 0.11, train 94.58%
epoch 28, loss: 0.30, train 94.54%
epoch 28, loss: 0.12, train 94.59%
epoch 28, loss: 0.15, train 94.64%
epoch 28, loss: 0.13, train 94.68%
epoch 28, loss: 0.15, train 94.73%
epoch 28, loss: 0.14, train 94.73%
epoch 28, loss: 0.18, train 94.78%
epoch 28, loss: 0.13, train 94.83%
epoch 28, loss: 0.22, train 94.78%
epoch 28, loss: 0.25, train 94.70%
epoch 28, loss: 0.36, train 94.66%
epoch 28, loss: 0.18, train 94.66%
epoch 28, loss: 0.33, train 94.58%
Epoch completed!
epoch 28, total signals 2400, average_loss_per_batch: 0.228189, train 94.58%
Validating
Val set size: 320, validation accuracy 80.94%
epoch 29, loss: 0.12, train 100.00%
epoch 29, loss: 0.37, train 97.50%
epoch 29, loss: 0.15, train 96.67%
epoch 29, loss: 0.16, train 97.50%
epoch 29, loss: 0.19, train 97.00%
epoch 29, loss: 0.16, train 96.67%
epoch 29, loss: 0.25, train 96.43%
epoch 29, loss: 0.13, train 96.88%
epoch 29, loss: 0.08, train 97.22%
epoch 29, loss: 0.35, train 96.00%
epoch 29, loss: 0.46, train 95.00%
epoch 29, loss: 0.19, train 95.00%
epoch 29, loss: 0.09, train 95.38%
epoch 29, loss: 0.10, train 95.71%
epoch 29, loss: 0.11, train 96.00%
epoch 29, loss: 0.15, train 95.94%
epoch 29, loss: 0.23, train 95.88%
epoch 29, loss: 0.29, train 95.56%
epoch 29, loss: 0.09, train 95.79%
epoch 29, loss: 0.13, train 95.75%
epoch 29, loss: 0.10, train 95.95%
epoch 29, loss: 0.08, train 96.14%
epoch 29, loss: 0.11, train 96.30%
epoch 29, loss: 0.11, train 96.46%
epoch 29, loss: 0.45, train 96.20%
epoch 29, loss: 0.10, train 96.35%
epoch 29, loss: 0.10, train 96.48%
epoch 29, loss: 0.19, train 96.43%
epoch 29, loss: 0.13, train 96.55%
epoch 29, loss: 0.12, train 96.67%
epoch 29, loss: 0.43, train 96.13%
epoch 29, loss: 0.16, train 96.25%
epoch 29, loss: 0.14, train 96.36%
epoch 29, loss: 0.05, train 96.47%
epoch 29, loss: 0.09, train 96.57%
epoch 29, loss: 0.47, train 96.25%
epoch 29, loss: 0.13, train 96.22%
epoch 29, loss: 0.09, train 96.32%
epoch 29, loss: 0.29, train 96.28%
epoch 29, loss: 0.15, train 96.38%
epoch 29, loss: 0.08, train 96.46%
epoch 29, loss: 0.20, train 96.43%
epoch 29, loss: 0.15, train 96.51%
epoch 29, loss: 0.18, train 96.59%
epoch 29, loss: 0.18, train 96.67%
epoch 29, loss: 0.14, train 96.74%
epoch 29, loss: 0.45, train 96.60%
epoch 29, loss: 0.12, train 96.67%
epoch 29, loss: 0.16, train 96.73%
epoch 29, loss: 0.13, train 96.80%
epoch 29, loss: 0.15, train 96.86%
epoch 29, loss: 0.37, train 96.63%
epoch 29, loss: 1.03, train 95.94%
epoch 29, loss: 0.11, train 96.02%
epoch 29, loss: 0.16, train 96.09%
epoch 29, loss: 0.13, train 96.16%
epoch 29, loss: 0.44, train 95.96%
epoch 29, loss: 0.16, train 96.03%
epoch 29, loss: 0.31, train 95.85%
epoch 29, loss: 0.21, train 95.83%
epoch 29, loss: 0.25, train 95.82%
epoch 29, loss: 0.15, train 95.89%
epoch 29, loss: 0.17, train 95.87%
epoch 29, loss: 0.21, train 95.78%
epoch 29, loss: 0.16, train 95.85%
epoch 29, loss: 0.09, train 95.91%
epoch 29, loss: 0.37, train 95.90%
epoch 29, loss: 0.07, train 95.96%
epoch 29, loss: 0.09, train 96.01%
epoch 29, loss: 0.34, train 96.07%
epoch 29, loss: 0.53, train 95.85%
epoch 29, loss: 0.31, train 95.76%
epoch 29, loss: 0.12, train 95.82%
epoch 29, loss: 0.11, train 95.88%
epoch 29, loss: 0.41, train 95.87%
epoch 29, loss: 0.09, train 95.92%
epoch 29, loss: 0.13, train 95.97%
epoch 29, loss: 0.24, train 95.90%
epoch 29, loss: 0.12, train 95.95%
epoch 29, loss: 0.11, train 96.00%
epoch 29, loss: 0.11, train 96.05%
epoch 29, loss: 0.32, train 96.10%
epoch 29, loss: 0.33, train 96.08%
epoch 29, loss: 0.24, train 96.01%
epoch 29, loss: 0.25, train 95.94%
epoch 29, loss: 0.16, train 95.93%
epoch 29, loss: 0.36, train 95.86%
epoch 29, loss: 0.20, train 95.80%
epoch 29, loss: 0.51, train 95.67%
epoch 29, loss: 0.08, train 95.72%
epoch 29, loss: 0.29, train 95.71%
epoch 29, loss: 0.47, train 95.65%
epoch 29, loss: 0.22, train 95.65%
epoch 29, loss: 0.07, train 95.69%
epoch 29, loss: 0.29, train 95.63%
epoch 29, loss: 0.20, train 95.62%
epoch 29, loss: 0.23, train 95.62%
epoch 29, loss: 0.24, train 95.61%
epoch 29, loss: 0.14, train 95.66%
epoch 29, loss: 0.52, train 95.60%
epoch 29, loss: 0.35, train 95.59%
epoch 29, loss: 0.21, train 95.59%
epoch 29, loss: 0.09, train 95.63%
epoch 29, loss: 0.18, train 95.62%
epoch 29, loss: 0.16, train 95.57%
epoch 29, loss: 0.11, train 95.61%
epoch 29, loss: 0.11, train 95.65%
epoch 29, loss: 0.24, train 95.65%
epoch 29, loss: 0.15, train 95.64%
epoch 29, loss: 0.23, train 95.68%
epoch 29, loss: 0.15, train 95.68%
epoch 29, loss: 0.32, train 95.62%
epoch 29, loss: 0.18, train 95.62%
epoch 29, loss: 0.14, train 95.61%
epoch 29, loss: 0.43, train 95.52%
epoch 29, loss: 0.15, train 95.56%
epoch 29, loss: 0.15, train 95.56%
epoch 29, loss: 0.14, train 95.55%
epoch 29, loss: 0.24, train 95.50%
epoch 29, loss: 0.13, train 95.54%
Epoch completed!
epoch 29, total signals 2400, average_loss_per_batch: 0.210688, train 95.54%
Validating
Val set size: 320, validation accuracy 82.50%
epoch 30, loss: 0.09, train 100.00%
epoch 30, loss: 0.10, train 100.00%
epoch 30, loss: 0.21, train 98.33%
epoch 30, loss: 0.24, train 97.50%
epoch 30, loss: 0.09, train 98.00%
epoch 30, loss: 0.20, train 97.50%
epoch 30, loss: 0.16, train 97.86%
epoch 30, loss: 0.09, train 98.12%
epoch 30, loss: 0.22, train 97.22%
epoch 30, loss: 0.15, train 97.00%
epoch 30, loss: 0.15, train 96.82%
epoch 30, loss: 0.15, train 96.67%
epoch 30, loss: 0.30, train 95.77%
epoch 30, loss: 0.12, train 96.07%
epoch 30, loss: 0.08, train 96.33%
epoch 30, loss: 0.25, train 96.25%
epoch 30, loss: 0.23, train 95.88%
epoch 30, loss: 0.20, train 96.11%
epoch 30, loss: 0.13, train 96.32%
epoch 30, loss: 0.16, train 96.50%
epoch 30, loss: 0.09, train 96.67%
epoch 30, loss: 0.12, train 96.82%
epoch 30, loss: 0.16, train 96.96%
epoch 30, loss: 0.18, train 96.88%
epoch 30, loss: 0.21, train 96.80%
epoch 30, loss: 0.19, train 96.73%
epoch 30, loss: 0.13, train 96.85%
epoch 30, loss: 0.24, train 96.79%
epoch 30, loss: 0.19, train 96.90%
epoch 30, loss: 0.50, train 96.83%
epoch 30, loss: 0.19, train 96.61%
epoch 30, loss: 0.20, train 96.56%
epoch 30, loss: 0.15, train 96.52%
epoch 30, loss: 0.13, train 96.62%
epoch 30, loss: 0.26, train 96.43%
epoch 30, loss: 1.45, train 95.28%
epoch 30, loss: 0.11, train 95.41%
epoch 30, loss: 0.39, train 95.13%
epoch 30, loss: 0.39, train 95.13%
epoch 30, loss: 0.21, train 95.00%
epoch 30, loss: 0.19, train 95.12%
epoch 30, loss: 0.37, train 95.12%
epoch 30, loss: 0.21, train 95.00%
epoch 30, loss: 0.42, train 94.66%
epoch 30, loss: 0.17, train 94.56%
epoch 30, loss: 0.44, train 94.67%
epoch 30, loss: 0.08, train 94.79%
epoch 30, loss: 0.08, train 94.90%
epoch 30, loss: 0.22, train 94.90%
epoch 30, loss: 0.09, train 95.00%
epoch 30, loss: 0.15, train 95.10%
epoch 30, loss: 0.29, train 95.00%
epoch 30, loss: 0.18, train 95.09%
epoch 30, loss: 0.25, train 95.09%
epoch 30, loss: 0.58, train 94.82%
epoch 30, loss: 0.11, train 94.91%
epoch 30, loss: 0.13, train 95.00%
epoch 30, loss: 0.51, train 94.83%
epoch 30, loss: 0.07, train 94.92%
epoch 30, loss: 0.16, train 94.92%
epoch 30, loss: 0.22, train 94.84%
epoch 30, loss: 0.11, train 94.92%
epoch 30, loss: 0.15, train 95.00%
epoch 30, loss: 0.32, train 94.92%
epoch 30, loss: 0.11, train 95.00%
epoch 30, loss: 0.13, train 95.00%
epoch 30, loss: 0.21, train 95.00%
epoch 30, loss: 0.24, train 95.00%
epoch 30, loss: 0.26, train 95.00%
epoch 30, loss: 0.14, train 95.00%
epoch 30, loss: 0.19, train 95.00%
epoch 30, loss: 0.12, train 95.00%
epoch 30, loss: 0.16, train 95.00%
epoch 30, loss: 0.11, train 95.07%
epoch 30, loss: 0.12, train 95.07%
epoch 30, loss: 0.41, train 95.00%
epoch 30, loss: 0.38, train 95.00%
epoch 30, loss: 0.24, train 95.00%
epoch 30, loss: 0.11, train 95.06%
epoch 30, loss: 0.05, train 95.12%
epoch 30, loss: 0.14, train 95.12%
epoch 30, loss: 0.33, train 95.12%
epoch 30, loss: 0.13, train 95.18%
epoch 30, loss: 0.13, train 95.18%
epoch 30, loss: 0.09, train 95.24%
epoch 30, loss: 0.26, train 95.17%
epoch 30, loss: 0.27, train 95.23%
epoch 30, loss: 0.47, train 95.06%
epoch 30, loss: 0.39, train 95.11%
epoch 30, loss: 0.20, train 95.11%
epoch 30, loss: 0.20, train 95.11%
epoch 30, loss: 0.08, train 95.16%
epoch 30, loss: 0.10, train 95.22%
epoch 30, loss: 0.12, train 95.27%
epoch 30, loss: 0.14, train 95.26%
epoch 30, loss: 0.10, train 95.31%
epoch 30, loss: 0.14, train 95.36%
epoch 30, loss: 0.21, train 95.36%
epoch 30, loss: 0.18, train 95.30%
epoch 30, loss: 0.15, train 95.35%
epoch 30, loss: 0.23, train 95.35%
epoch 30, loss: 0.10, train 95.39%
epoch 30, loss: 0.19, train 95.44%
epoch 30, loss: 0.17, train 95.48%
epoch 30, loss: 0.15, train 95.52%
epoch 30, loss: 0.12, train 95.57%
epoch 30, loss: 0.12, train 95.56%
epoch 30, loss: 0.21, train 95.56%
epoch 30, loss: 0.26, train 95.50%
epoch 30, loss: 0.19, train 95.45%
epoch 30, loss: 0.37, train 95.32%
epoch 30, loss: 0.14, train 95.31%
epoch 30, loss: 0.13, train 95.35%
epoch 30, loss: 0.19, train 95.35%
epoch 30, loss: 0.28, train 95.26%
epoch 30, loss: 0.12, train 95.26%
epoch 30, loss: 0.54, train 95.17%
epoch 30, loss: 0.23, train 95.17%
epoch 30, loss: 0.51, train 95.17%
epoch 30, loss: 0.48, train 95.12%
Epoch completed!
epoch 30, total signals 2400, average_loss_per_batch: 0.215326, train 95.12%
Validating
Val set size: 320, validation accuracy 82.19%
epoch 31, loss: 0.19, train 90.00%
epoch 31, loss: 0.16, train 90.00%
epoch 31, loss: 0.19, train 91.67%
epoch 31, loss: 0.24, train 91.25%
epoch 31, loss: 0.13, train 92.00%
epoch 31, loss: 0.31, train 90.83%
epoch 31, loss: 0.29, train 90.00%
epoch 31, loss: 0.16, train 90.62%
epoch 31, loss: 0.08, train 91.67%
epoch 31, loss: 0.26, train 91.50%
epoch 31, loss: 0.10, train 92.27%
epoch 31, loss: 0.15, train 92.50%
epoch 31, loss: 0.25, train 93.08%
epoch 31, loss: 0.29, train 93.21%
epoch 31, loss: 0.25, train 93.33%
epoch 31, loss: 0.08, train 93.75%
epoch 31, loss: 0.39, train 93.82%
epoch 31, loss: 0.10, train 94.17%
epoch 31, loss: 0.34, train 93.95%
epoch 31, loss: 0.14, train 94.25%
epoch 31, loss: 0.22, train 94.29%
epoch 31, loss: 0.12, train 94.55%
epoch 31, loss: 0.08, train 94.78%
epoch 31, loss: 0.59, train 94.38%
epoch 31, loss: 0.07, train 94.60%
epoch 31, loss: 0.26, train 94.42%
epoch 31, loss: 0.28, train 94.07%
epoch 31, loss: 0.17, train 94.11%
epoch 31, loss: 0.09, train 94.31%
epoch 31, loss: 0.18, train 94.33%
epoch 31, loss: 0.22, train 94.35%
epoch 31, loss: 0.09, train 94.53%
epoch 31, loss: 0.14, train 94.55%
epoch 31, loss: 0.70, train 93.82%
epoch 31, loss: 0.29, train 93.86%
epoch 31, loss: 0.14, train 94.03%
epoch 31, loss: 0.47, train 93.78%
epoch 31, loss: 0.31, train 93.55%
epoch 31, loss: 0.18, train 93.72%
epoch 31, loss: 0.12, train 93.75%
epoch 31, loss: 0.19, train 93.90%
epoch 31, loss: 0.09, train 94.05%
epoch 31, loss: 0.35, train 94.19%
epoch 31, loss: 0.12, train 94.20%
epoch 31, loss: 0.19, train 94.22%
epoch 31, loss: 0.22, train 94.24%
epoch 31, loss: 0.25, train 94.04%
epoch 31, loss: 0.36, train 93.75%
epoch 31, loss: 0.10, train 93.88%
epoch 31, loss: 0.12, train 94.00%
epoch 31, loss: 0.23, train 94.12%
epoch 31, loss: 0.38, train 93.94%
epoch 31, loss: 0.12, train 94.06%
epoch 31, loss: 0.28, train 94.07%
epoch 31, loss: 0.26, train 94.09%
epoch 31, loss: 0.12, train 94.11%
epoch 31, loss: 0.15, train 94.21%
epoch 31, loss: 0.16, train 94.31%
epoch 31, loss: 0.18, train 94.32%
epoch 31, loss: 0.35, train 94.33%
epoch 31, loss: 0.16, train 94.43%
epoch 31, loss: 0.12, train 94.52%
epoch 31, loss: 0.29, train 94.37%
epoch 31, loss: 0.05, train 94.45%
epoch 31, loss: 0.78, train 94.08%
epoch 31, loss: 0.25, train 94.09%
epoch 31, loss: 0.14, train 94.10%
epoch 31, loss: 0.13, train 94.19%
epoch 31, loss: 0.10, train 94.28%
epoch 31, loss: 0.18, train 94.29%
epoch 31, loss: 0.40, train 94.23%
epoch 31, loss: 0.17, train 94.31%
epoch 31, loss: 0.11, train 94.38%
epoch 31, loss: 0.21, train 94.39%
epoch 31, loss: 0.21, train 94.33%
epoch 31, loss: 0.12, train 94.41%
epoch 31, loss: 0.28, train 94.42%
epoch 31, loss: 0.15, train 94.49%
epoch 31, loss: 0.23, train 94.43%
epoch 31, loss: 0.36, train 94.44%
epoch 31, loss: 0.31, train 94.38%
epoch 31, loss: 0.14, train 94.45%
epoch 31, loss: 0.18, train 94.52%
epoch 31, loss: 0.11, train 94.58%
epoch 31, loss: 0.22, train 94.53%
epoch 31, loss: 0.39, train 94.36%
epoch 31, loss: 0.17, train 94.37%
epoch 31, loss: 0.18, train 94.43%
epoch 31, loss: 0.09, train 94.49%
epoch 31, loss: 0.33, train 94.44%
epoch 31, loss: 0.18, train 94.45%
epoch 31, loss: 0.28, train 94.51%
epoch 31, loss: 0.22, train 94.57%
epoch 31, loss: 0.44, train 94.52%
epoch 31, loss: 0.06, train 94.58%
epoch 31, loss: 0.13, train 94.64%
epoch 31, loss: 0.11, train 94.69%
epoch 31, loss: 0.15, train 94.74%
epoch 31, loss: 0.16, train 94.80%
epoch 31, loss: 0.80, train 94.55%
epoch 31, loss: 0.34, train 94.55%
epoch 31, loss: 0.23, train 94.56%
epoch 31, loss: 0.14, train 94.61%
epoch 31, loss: 0.96, train 94.38%
epoch 31, loss: 0.26, train 94.33%
epoch 31, loss: 0.35, train 94.39%
epoch 31, loss: 0.31, train 94.30%
epoch 31, loss: 0.21, train 94.26%
epoch 31, loss: 0.17, train 94.27%
epoch 31, loss: 0.17, train 94.32%
epoch 31, loss: 0.31, train 94.37%
epoch 31, loss: 0.10, train 94.42%
epoch 31, loss: 0.20, train 94.47%
epoch 31, loss: 0.09, train 94.52%
epoch 31, loss: 0.11, train 94.52%
epoch 31, loss: 0.69, train 94.44%
epoch 31, loss: 0.08, train 94.49%
epoch 31, loss: 0.27, train 94.45%
epoch 31, loss: 0.31, train 94.41%
epoch 31, loss: 0.13, train 94.46%
Epoch completed!
epoch 31, total signals 2400, average_loss_per_batch: 0.229787, train 94.46%
Validating
Val set size: 320, validation accuracy 82.50%
epoch 32, loss: 0.41, train 85.00%
epoch 32, loss: 0.09, train 92.50%
epoch 32, loss: 0.13, train 95.00%
epoch 32, loss: 0.17, train 96.25%
epoch 32, loss: 0.09, train 97.00%
epoch 32, loss: 0.22, train 96.67%
epoch 32, loss: 0.08, train 97.14%
epoch 32, loss: 0.23, train 96.88%
epoch 32, loss: 0.09, train 97.22%
epoch 32, loss: 0.25, train 97.50%
epoch 32, loss: 0.10, train 97.73%
epoch 32, loss: 0.12, train 97.92%
epoch 32, loss: 0.41, train 96.54%
epoch 32, loss: 0.25, train 96.07%
epoch 32, loss: 0.09, train 96.33%
epoch 32, loss: 0.24, train 95.94%
epoch 32, loss: 0.35, train 95.59%
epoch 32, loss: 0.10, train 95.83%
epoch 32, loss: 0.51, train 95.79%
epoch 32, loss: 0.23, train 95.75%
epoch 32, loss: 0.17, train 95.95%
epoch 32, loss: 0.12, train 96.14%
epoch 32, loss: 0.20, train 96.09%
epoch 32, loss: 0.07, train 96.25%
epoch 32, loss: 0.08, train 96.40%
epoch 32, loss: 0.16, train 96.35%
epoch 32, loss: 0.14, train 96.30%
epoch 32, loss: 0.12, train 96.43%
epoch 32, loss: 0.09, train 96.55%
epoch 32, loss: 0.12, train 96.67%
epoch 32, loss: 0.17, train 96.77%
epoch 32, loss: 0.23, train 96.72%
epoch 32, loss: 0.15, train 96.82%
epoch 32, loss: 0.13, train 96.76%
epoch 32, loss: 0.15, train 96.71%
epoch 32, loss: 0.18, train 96.67%
epoch 32, loss: 0.09, train 96.76%
epoch 32, loss: 0.05, train 96.84%
epoch 32, loss: 0.15, train 96.79%
epoch 32, loss: 0.11, train 96.88%
epoch 32, loss: 0.16, train 96.71%
epoch 32, loss: 0.45, train 96.55%
epoch 32, loss: 0.07, train 96.63%
epoch 32, loss: 0.17, train 96.59%
epoch 32, loss: 0.38, train 96.56%
epoch 32, loss: 0.11, train 96.63%
epoch 32, loss: 0.27, train 96.60%
epoch 32, loss: 0.40, train 96.25%
epoch 32, loss: 0.47, train 95.82%
epoch 32, loss: 0.14, train 95.90%
epoch 32, loss: 0.13, train 95.98%
epoch 32, loss: 0.12, train 95.96%
epoch 32, loss: 0.16, train 95.94%
epoch 32, loss: 0.12, train 95.93%
epoch 32, loss: 0.06, train 96.00%
epoch 32, loss: 0.14, train 96.07%
epoch 32, loss: 0.65, train 95.61%
epoch 32, loss: 0.11, train 95.69%
epoch 32, loss: 0.14, train 95.68%
epoch 32, loss: 0.10, train 95.75%
epoch 32, loss: 0.11, train 95.82%
epoch 32, loss: 0.59, train 95.24%
epoch 32, loss: 0.33, train 95.32%
epoch 32, loss: 0.38, train 95.16%
epoch 32, loss: 0.07, train 95.23%
epoch 32, loss: 0.21, train 95.30%
epoch 32, loss: 0.12, train 95.37%
epoch 32, loss: 0.20, train 95.37%
epoch 32, loss: 0.34, train 95.36%
epoch 32, loss: 0.28, train 95.36%
epoch 32, loss: 0.20, train 95.35%
epoch 32, loss: 0.32, train 95.21%
epoch 32, loss: 0.12, train 95.21%
epoch 32, loss: 0.52, train 95.07%
epoch 32, loss: 0.24, train 95.07%
epoch 32, loss: 0.16, train 95.07%
epoch 32, loss: 0.16, train 95.06%
epoch 32, loss: 0.22, train 95.13%
epoch 32, loss: 0.13, train 95.19%
epoch 32, loss: 0.16, train 95.19%
epoch 32, loss: 0.10, train 95.25%
epoch 32, loss: 0.13, train 95.24%
epoch 32, loss: 0.57, train 95.18%
epoch 32, loss: 0.17, train 95.24%
epoch 32, loss: 0.32, train 95.18%
epoch 32, loss: 0.37, train 95.23%
epoch 32, loss: 0.10, train 95.29%
epoch 32, loss: 0.10, train 95.34%
epoch 32, loss: 0.20, train 95.39%
epoch 32, loss: 0.07, train 95.44%
epoch 32, loss: 0.17, train 95.49%
epoch 32, loss: 0.07, train 95.54%
epoch 32, loss: 0.20, train 95.48%
epoch 32, loss: 0.15, train 95.53%
epoch 32, loss: 0.27, train 95.47%
epoch 32, loss: 0.11, train 95.52%
epoch 32, loss: 0.13, train 95.52%
epoch 32, loss: 0.19, train 95.51%
epoch 32, loss: 0.28, train 95.45%
epoch 32, loss: 0.18, train 95.45%
epoch 32, loss: 0.10, train 95.50%
epoch 32, loss: 0.20, train 95.49%
epoch 32, loss: 0.25, train 95.49%
epoch 32, loss: 0.15, train 95.53%
epoch 32, loss: 0.11, train 95.52%
epoch 32, loss: 0.17, train 95.57%
epoch 32, loss: 0.44, train 95.56%
epoch 32, loss: 0.09, train 95.60%
epoch 32, loss: 0.13, train 95.64%
epoch 32, loss: 0.19, train 95.64%
epoch 32, loss: 0.11, train 95.68%
epoch 32, loss: 0.12, train 95.71%
epoch 32, loss: 0.16, train 95.75%
epoch 32, loss: 0.50, train 95.57%
epoch 32, loss: 0.06, train 95.61%
epoch 32, loss: 0.21, train 95.60%
epoch 32, loss: 0.11, train 95.64%
epoch 32, loss: 0.13, train 95.64%
epoch 32, loss: 0.29, train 95.59%
epoch 32, loss: 0.08, train 95.62%
Epoch completed!
epoch 32, total signals 2400, average_loss_per_batch: 0.195539, train 95.62%
Validating
Val set size: 320, validation accuracy 80.62%
epoch 33, loss: 0.19, train 95.00%
epoch 33, loss: 0.15, train 95.00%
epoch 33, loss: 0.11, train 95.00%
epoch 33, loss: 0.21, train 95.00%
epoch 33, loss: 0.37, train 95.00%
epoch 33, loss: 0.17, train 95.00%
epoch 33, loss: 0.47, train 94.29%
epoch 33, loss: 0.08, train 95.00%
epoch 33, loss: 0.11, train 95.56%
epoch 33, loss: 0.20, train 95.50%
epoch 33, loss: 0.15, train 95.91%
epoch 33, loss: 0.12, train 96.25%
epoch 33, loss: 0.24, train 96.15%
epoch 33, loss: 0.11, train 96.43%
epoch 33, loss: 0.15, train 96.33%
epoch 33, loss: 0.07, train 96.56%
epoch 33, loss: 0.20, train 96.47%
epoch 33, loss: 0.10, train 96.67%
epoch 33, loss: 0.12, train 96.84%
epoch 33, loss: 0.23, train 96.50%
epoch 33, loss: 0.15, train 96.43%
epoch 33, loss: 0.22, train 96.36%
epoch 33, loss: 0.24, train 96.30%
epoch 33, loss: 0.16, train 96.46%
epoch 33, loss: 0.07, train 96.60%
epoch 33, loss: 0.15, train 96.54%
epoch 33, loss: 0.09, train 96.67%
epoch 33, loss: 0.16, train 96.61%
epoch 33, loss: 0.07, train 96.72%
epoch 33, loss: 0.24, train 96.67%
epoch 33, loss: 0.19, train 96.61%
epoch 33, loss: 0.11, train 96.72%
epoch 33, loss: 0.11, train 96.67%
epoch 33, loss: 0.13, train 96.62%
epoch 33, loss: 0.18, train 96.57%
epoch 33, loss: 0.15, train 96.53%
epoch 33, loss: 0.22, train 96.49%
epoch 33, loss: 0.21, train 96.45%
epoch 33, loss: 0.16, train 96.41%
epoch 33, loss: 0.17, train 96.50%
epoch 33, loss: 0.25, train 96.46%
epoch 33, loss: 0.17, train 96.55%
epoch 33, loss: 0.10, train 96.63%
epoch 33, loss: 0.12, train 96.59%
epoch 33, loss: 0.55, train 96.44%
epoch 33, loss: 0.32, train 96.30%
epoch 33, loss: 0.34, train 96.06%
epoch 33, loss: 0.11, train 96.15%
epoch 33, loss: 0.19, train 96.12%
epoch 33, loss: 0.11, train 96.20%
epoch 33, loss: 0.56, train 95.88%
epoch 33, loss: 0.08, train 95.96%
epoch 33, loss: 0.10, train 96.04%
epoch 33, loss: 0.10, train 96.11%
epoch 33, loss: 0.11, train 96.18%
epoch 33, loss: 0.24, train 96.07%
epoch 33, loss: 0.11, train 96.05%
epoch 33, loss: 0.16, train 96.03%
epoch 33, loss: 0.17, train 96.02%
epoch 33, loss: 0.18, train 96.00%
epoch 33, loss: 0.08, train 96.07%
epoch 33, loss: 0.27, train 96.05%
epoch 33, loss: 0.14, train 96.11%
epoch 33, loss: 0.11, train 96.17%
epoch 33, loss: 0.13, train 96.23%
epoch 33, loss: 0.52, train 96.21%
epoch 33, loss: 0.32, train 96.19%
epoch 33, loss: 0.27, train 96.18%
epoch 33, loss: 0.47, train 96.09%
epoch 33, loss: 0.19, train 96.07%
epoch 33, loss: 0.06, train 96.13%
epoch 33, loss: 0.18, train 96.11%
epoch 33, loss: 0.15, train 96.16%
epoch 33, loss: 0.24, train 96.15%
epoch 33, loss: 0.14, train 96.20%
epoch 33, loss: 0.28, train 96.18%
epoch 33, loss: 0.19, train 96.17%
epoch 33, loss: 0.20, train 96.15%
epoch 33, loss: 0.14, train 96.20%
epoch 33, loss: 0.18, train 96.19%
epoch 33, loss: 0.18, train 96.23%
epoch 33, loss: 0.41, train 96.22%
epoch 33, loss: 0.13, train 96.27%
epoch 33, loss: 0.19, train 96.25%
epoch 33, loss: 0.11, train 96.24%
epoch 33, loss: 0.27, train 96.16%
epoch 33, loss: 0.32, train 96.09%
epoch 33, loss: 0.12, train 96.08%
epoch 33, loss: 0.20, train 96.07%
epoch 33, loss: 0.26, train 96.00%
epoch 33, loss: 0.15, train 95.99%
epoch 33, loss: 0.08, train 96.03%
epoch 33, loss: 0.22, train 95.97%
epoch 33, loss: 0.17, train 95.96%
epoch 33, loss: 0.08, train 96.00%
epoch 33, loss: 0.09, train 96.04%
epoch 33, loss: 0.12, train 96.03%
epoch 33, loss: 0.19, train 95.97%
epoch 33, loss: 0.13, train 96.01%
epoch 33, loss: 0.15, train 96.00%
epoch 33, loss: 0.34, train 95.89%
epoch 33, loss: 0.07, train 95.93%
epoch 33, loss: 0.22, train 95.97%
epoch 33, loss: 0.60, train 95.87%
epoch 33, loss: 0.33, train 95.81%
epoch 33, loss: 0.19, train 95.75%
epoch 33, loss: 0.21, train 95.75%
epoch 33, loss: 0.18, train 95.74%
epoch 33, loss: 0.18, train 95.78%
epoch 33, loss: 0.23, train 95.77%
epoch 33, loss: 0.14, train 95.81%
epoch 33, loss: 0.16, train 95.85%
epoch 33, loss: 0.15, train 95.84%
epoch 33, loss: 0.54, train 95.70%
epoch 33, loss: 0.24, train 95.74%
epoch 33, loss: 0.18, train 95.73%
epoch 33, loss: 0.10, train 95.73%
epoch 33, loss: 0.22, train 95.72%
epoch 33, loss: 0.22, train 95.71%
epoch 33, loss: 0.13, train 95.75%
Epoch completed!
epoch 33, total signals 2400, average_loss_per_batch: 0.194031, train 95.75%
Validating
Val set size: 320, validation accuracy 83.75%
epoch 34, loss: 0.15, train 95.00%
epoch 34, loss: 0.13, train 97.50%
epoch 34, loss: 0.65, train 95.00%
epoch 34, loss: 0.14, train 96.25%
epoch 34, loss: 0.16, train 97.00%
epoch 34, loss: 0.12, train 97.50%
epoch 34, loss: 0.20, train 97.86%
epoch 34, loss: 0.09, train 97.50%
epoch 34, loss: 0.18, train 97.22%
epoch 34, loss: 0.09, train 97.50%
epoch 34, loss: 0.14, train 97.73%
epoch 34, loss: 0.24, train 97.50%
epoch 34, loss: 0.14, train 97.69%
epoch 34, loss: 0.21, train 97.50%
epoch 34, loss: 0.20, train 97.00%
epoch 34, loss: 0.41, train 97.19%
epoch 34, loss: 0.10, train 97.35%
epoch 34, loss: 0.16, train 97.50%
epoch 34, loss: 0.21, train 97.63%
epoch 34, loss: 0.13, train 97.75%
epoch 34, loss: 0.25, train 97.14%
epoch 34, loss: 0.12, train 97.27%
epoch 34, loss: 0.08, train 97.39%
epoch 34, loss: 0.08, train 97.50%
epoch 34, loss: 0.13, train 97.60%
epoch 34, loss: 0.06, train 97.69%
epoch 34, loss: 0.14, train 97.78%
epoch 34, loss: 0.11, train 97.86%
epoch 34, loss: 0.09, train 97.76%
epoch 34, loss: 0.31, train 97.33%
epoch 34, loss: 0.10, train 97.42%
epoch 34, loss: 1.03, train 96.56%
epoch 34, loss: 0.11, train 96.52%
epoch 34, loss: 1.15, train 95.29%
epoch 34, loss: 0.11, train 95.43%
epoch 34, loss: 0.10, train 95.56%
epoch 34, loss: 1.33, train 94.73%
epoch 34, loss: 0.12, train 94.87%
epoch 34, loss: 0.13, train 95.00%
epoch 34, loss: 0.13, train 95.00%
epoch 34, loss: 0.13, train 95.12%
epoch 34, loss: 0.20, train 95.24%
epoch 34, loss: 0.17, train 95.35%
epoch 34, loss: 0.19, train 95.45%
epoch 34, loss: 0.19, train 95.44%
epoch 34, loss: 0.13, train 95.43%
epoch 34, loss: 0.11, train 95.53%
epoch 34, loss: 0.11, train 95.62%
epoch 34, loss: 0.16, train 95.61%
epoch 34, loss: 0.15, train 95.70%
epoch 34, loss: 0.27, train 95.69%
epoch 34, loss: 0.16, train 95.77%
epoch 34, loss: 0.16, train 95.75%
epoch 34, loss: 0.22, train 95.74%
epoch 34, loss: 0.12, train 95.82%
epoch 34, loss: 0.11, train 95.89%
epoch 34, loss: 0.46, train 95.88%
epoch 34, loss: 0.14, train 95.95%
epoch 34, loss: 0.13, train 96.02%
epoch 34, loss: 0.09, train 96.08%
epoch 34, loss: 0.16, train 96.07%
epoch 34, loss: 0.10, train 96.13%
epoch 34, loss: 0.12, train 96.19%
epoch 34, loss: 0.09, train 96.25%
epoch 34, loss: 0.08, train 96.31%
epoch 34, loss: 0.11, train 96.36%
epoch 34, loss: 0.26, train 96.34%
epoch 34, loss: 0.15, train 96.32%
epoch 34, loss: 0.30, train 96.30%
epoch 34, loss: 0.38, train 96.14%
epoch 34, loss: 0.22, train 96.20%
epoch 34, loss: 0.10, train 96.25%
epoch 34, loss: 0.27, train 96.30%
epoch 34, loss: 0.34, train 96.22%
epoch 34, loss: 0.16, train 96.27%
epoch 34, loss: 0.08, train 96.32%
epoch 34, loss: 0.11, train 96.30%
epoch 34, loss: 0.15, train 96.35%
epoch 34, loss: 0.08, train 96.39%
epoch 34, loss: 0.06, train 96.44%
epoch 34, loss: 0.20, train 96.36%
epoch 34, loss: 0.15, train 96.40%
epoch 34, loss: 0.21, train 96.39%
epoch 34, loss: 0.11, train 96.43%
epoch 34, loss: 0.10, train 96.47%
epoch 34, loss: 0.16, train 96.51%
epoch 34, loss: 0.08, train 96.55%
epoch 34, loss: 0.19, train 96.48%
epoch 34, loss: 0.44, train 96.40%
epoch 34, loss: 0.43, train 96.33%
epoch 34, loss: 0.23, train 96.37%
epoch 34, loss: 0.34, train 96.41%
epoch 34, loss: 0.16, train 96.45%
epoch 34, loss: 0.15, train 96.44%
epoch 34, loss: 0.08, train 96.47%
epoch 34, loss: 0.11, train 96.51%
epoch 34, loss: 0.21, train 96.49%
epoch 34, loss: 0.14, train 96.53%
epoch 34, loss: 0.10, train 96.57%
epoch 34, loss: 0.99, train 96.25%
epoch 34, loss: 0.38, train 96.29%
epoch 34, loss: 0.18, train 96.32%
epoch 34, loss: 0.54, train 96.31%
epoch 34, loss: 0.67, train 96.20%
epoch 34, loss: 0.11, train 96.24%
epoch 34, loss: 0.14, train 96.23%
epoch 34, loss: 0.20, train 96.21%
epoch 34, loss: 0.35, train 96.16%
epoch 34, loss: 0.11, train 96.19%
epoch 34, loss: 0.18, train 96.23%
epoch 34, loss: 0.07, train 96.26%
epoch 34, loss: 0.30, train 96.21%
epoch 34, loss: 0.51, train 96.15%
epoch 34, loss: 0.14, train 96.18%
epoch 34, loss: 0.12, train 96.22%
epoch 34, loss: 0.07, train 96.25%
epoch 34, loss: 0.44, train 96.15%
epoch 34, loss: 0.10, train 96.19%
epoch 34, loss: 0.12, train 96.22%
epoch 34, loss: 0.27, train 96.17%
Epoch completed!
epoch 34, total signals 2400, average_loss_per_batch: 0.215641, train 96.17%
Validating
Val set size: 320, validation accuracy 80.94%
epoch 35, loss: 0.09, train 100.00%
epoch 35, loss: 0.42, train 92.50%
epoch 35, loss: 0.10, train 95.00%
epoch 35, loss: 0.16, train 95.00%
epoch 35, loss: 0.04, train 96.00%
epoch 35, loss: 0.27, train 94.17%
epoch 35, loss: 0.09, train 95.00%
epoch 35, loss: 0.11, train 95.00%
epoch 35, loss: 0.25, train 95.00%
epoch 35, loss: 0.08, train 95.50%
epoch 35, loss: 0.05, train 95.91%
epoch 35, loss: 0.14, train 95.83%
epoch 35, loss: 0.12, train 96.15%
epoch 35, loss: 0.25, train 95.71%
epoch 35, loss: 0.09, train 95.67%
epoch 35, loss: 0.33, train 94.69%
epoch 35, loss: 0.23, train 94.71%
epoch 35, loss: 0.17, train 95.00%
epoch 35, loss: 0.09, train 95.26%
epoch 35, loss: 0.42, train 95.00%
epoch 35, loss: 0.15, train 95.00%
epoch 35, loss: 0.33, train 94.77%
epoch 35, loss: 0.17, train 95.00%
epoch 35, loss: 0.09, train 95.21%
epoch 35, loss: 0.23, train 95.20%
epoch 35, loss: 0.09, train 95.38%
epoch 35, loss: 0.13, train 95.56%
epoch 35, loss: 0.12, train 95.71%
epoch 35, loss: 0.19, train 95.86%
epoch 35, loss: 0.14, train 96.00%
epoch 35, loss: 0.18, train 95.81%
epoch 35, loss: 0.15, train 95.94%
epoch 35, loss: 0.22, train 95.91%
epoch 35, loss: 0.04, train 96.03%
epoch 35, loss: 0.16, train 96.14%
epoch 35, loss: 0.09, train 96.25%
epoch 35, loss: 0.20, train 96.22%
epoch 35, loss: 0.18, train 96.18%
epoch 35, loss: 0.13, train 96.15%
epoch 35, loss: 0.18, train 96.12%
epoch 35, loss: 0.17, train 96.10%
epoch 35, loss: 0.20, train 96.07%
epoch 35, loss: 0.09, train 96.16%
epoch 35, loss: 0.07, train 96.25%
epoch 35, loss: 0.19, train 96.22%
epoch 35, loss: 0.27, train 96.09%
epoch 35, loss: 0.15, train 96.17%
epoch 35, loss: 0.14, train 96.25%
epoch 35, loss: 0.17, train 96.33%
epoch 35, loss: 0.17, train 96.40%
epoch 35, loss: 0.13, train 96.47%
epoch 35, loss: 0.47, train 96.35%
epoch 35, loss: 0.11, train 96.42%
epoch 35, loss: 0.13, train 96.39%
epoch 35, loss: 0.10, train 96.45%
epoch 35, loss: 0.15, train 96.52%
epoch 35, loss: 0.16, train 96.49%
epoch 35, loss: 0.15, train 96.55%
epoch 35, loss: 0.10, train 96.61%
epoch 35, loss: 0.07, train 96.67%
epoch 35, loss: 0.15, train 96.64%
epoch 35, loss: 0.11, train 96.69%
epoch 35, loss: 0.09, train 96.75%
epoch 35, loss: 0.13, train 96.80%
epoch 35, loss: 0.48, train 96.69%
epoch 35, loss: 0.13, train 96.74%
epoch 35, loss: 0.15, train 96.72%
epoch 35, loss: 0.25, train 96.76%
epoch 35, loss: 0.20, train 96.74%
epoch 35, loss: 0.26, train 96.64%
epoch 35, loss: 0.15, train 96.62%
epoch 35, loss: 0.34, train 96.67%
epoch 35, loss: 0.52, train 96.64%
epoch 35, loss: 0.21, train 96.62%
epoch 35, loss: 0.26, train 96.53%
epoch 35, loss: 0.25, train 96.51%
epoch 35, loss: 0.19, train 96.49%
epoch 35, loss: 0.07, train 96.54%
epoch 35, loss: 0.17, train 96.58%
epoch 35, loss: 0.14, train 96.62%
epoch 35, loss: 0.21, train 96.54%
epoch 35, loss: 0.16, train 96.52%
epoch 35, loss: 0.16, train 96.51%
epoch 35, loss: 0.19, train 96.49%
epoch 35, loss: 0.77, train 96.41%
epoch 35, loss: 0.18, train 96.40%
epoch 35, loss: 0.12, train 96.44%
epoch 35, loss: 0.19, train 96.42%
epoch 35, loss: 0.11, train 96.40%
epoch 35, loss: 0.31, train 96.33%
epoch 35, loss: 0.15, train 96.37%
epoch 35, loss: 0.19, train 96.36%
epoch 35, loss: 0.24, train 96.34%
epoch 35, loss: 0.11, train 96.33%
epoch 35, loss: 0.09, train 96.37%
epoch 35, loss: 0.16, train 96.41%
epoch 35, loss: 0.08, train 96.44%
epoch 35, loss: 0.10, train 96.48%
epoch 35, loss: 0.10, train 96.52%
epoch 35, loss: 0.07, train 96.55%
epoch 35, loss: 0.16, train 96.53%
epoch 35, loss: 0.23, train 96.42%
epoch 35, loss: 0.16, train 96.46%
epoch 35, loss: 0.23, train 96.44%
epoch 35, loss: 0.12, train 96.48%
epoch 35, loss: 0.15, train 96.46%
epoch 35, loss: 0.11, train 96.50%
epoch 35, loss: 0.70, train 96.39%
epoch 35, loss: 0.22, train 96.38%
epoch 35, loss: 0.09, train 96.41%
epoch 35, loss: 0.60, train 96.31%
epoch 35, loss: 0.14, train 96.34%
epoch 35, loss: 0.15, train 96.37%
epoch 35, loss: 0.14, train 96.40%
epoch 35, loss: 0.06, train 96.43%
epoch 35, loss: 0.17, train 96.47%
epoch 35, loss: 0.25, train 96.37%
epoch 35, loss: 0.21, train 96.36%
epoch 35, loss: 0.11, train 96.39%
epoch 35, loss: 0.36, train 96.42%
Epoch completed!
epoch 35, total signals 2400, average_loss_per_batch: 0.184749, train 96.42%
Validating
Val set size: 320, validation accuracy 79.38%
epoch 36, loss: 0.16, train 100.00%
epoch 36, loss: 0.16, train 97.50%
epoch 36, loss: 0.12, train 96.67%
epoch 36, loss: 0.14, train 97.50%
epoch 36, loss: 0.22, train 96.00%
epoch 36, loss: 0.21, train 95.83%
epoch 36, loss: 0.05, train 96.43%
epoch 36, loss: 0.32, train 96.88%
epoch 36, loss: 0.17, train 96.67%
epoch 36, loss: 0.12, train 96.50%
epoch 36, loss: 0.11, train 96.82%
epoch 36, loss: 0.31, train 97.08%
epoch 36, loss: 0.16, train 97.31%
epoch 36, loss: 0.14, train 97.50%
epoch 36, loss: 0.30, train 97.00%
epoch 36, loss: 0.19, train 97.19%
epoch 36, loss: 0.24, train 97.06%
epoch 36, loss: 0.10, train 97.22%
epoch 36, loss: 0.34, train 97.37%
epoch 36, loss: 0.11, train 97.50%
epoch 36, loss: 0.09, train 97.62%
epoch 36, loss: 0.26, train 97.50%
epoch 36, loss: 0.19, train 97.61%
epoch 36, loss: 0.12, train 97.71%
epoch 36, loss: 0.11, train 97.80%
epoch 36, loss: 0.18, train 97.69%
epoch 36, loss: 0.11, train 97.78%
epoch 36, loss: 0.10, train 97.86%
epoch 36, loss: 0.15, train 97.76%
epoch 36, loss: 0.09, train 97.83%
epoch 36, loss: 0.12, train 97.90%
epoch 36, loss: 0.10, train 97.81%
epoch 36, loss: 0.16, train 97.73%
epoch 36, loss: 0.07, train 97.79%
epoch 36, loss: 0.25, train 97.71%
epoch 36, loss: 0.11, train 97.78%
epoch 36, loss: 0.10, train 97.84%
epoch 36, loss: 0.10, train 97.89%
epoch 36, loss: 0.31, train 97.82%
epoch 36, loss: 0.29, train 97.75%
epoch 36, loss: 0.11, train 97.80%
epoch 36, loss: 0.13, train 97.74%
epoch 36, loss: 0.13, train 97.79%
epoch 36, loss: 0.18, train 97.73%
epoch 36, loss: 0.41, train 97.33%
epoch 36, loss: 0.15, train 97.28%
epoch 36, loss: 0.31, train 97.23%
epoch 36, loss: 0.32, train 96.98%
epoch 36, loss: 0.14, train 97.04%
epoch 36, loss: 0.17, train 97.10%
epoch 36, loss: 0.14, train 97.06%
epoch 36, loss: 0.18, train 97.12%
epoch 36, loss: 0.18, train 97.08%
epoch 36, loss: 0.12, train 97.13%
epoch 36, loss: 0.13, train 97.09%
epoch 36, loss: 0.06, train 97.14%
epoch 36, loss: 0.15, train 97.19%
epoch 36, loss: 0.14, train 97.16%
epoch 36, loss: 0.33, train 97.20%
epoch 36, loss: 0.16, train 97.25%
epoch 36, loss: 0.28, train 97.30%
epoch 36, loss: 0.12, train 97.26%
epoch 36, loss: 0.12, train 97.30%
epoch 36, loss: 0.11, train 97.34%
epoch 36, loss: 0.20, train 97.38%
epoch 36, loss: 0.13, train 97.35%
epoch 36, loss: 0.14, train 97.39%
epoch 36, loss: 0.09, train 97.43%
epoch 36, loss: 0.31, train 97.46%
epoch 36, loss: 0.17, train 97.43%
epoch 36, loss: 0.11, train 97.39%
epoch 36, loss: 0.24, train 97.29%
epoch 36, loss: 0.31, train 97.19%
epoch 36, loss: 0.13, train 97.23%
epoch 36, loss: 0.11, train 97.20%
epoch 36, loss: 0.10, train 97.24%
epoch 36, loss: 0.16, train 97.21%
epoch 36, loss: 0.18, train 97.24%
epoch 36, loss: 0.24, train 97.22%
epoch 36, loss: 0.16, train 97.25%
epoch 36, loss: 0.07, train 97.28%
epoch 36, loss: 0.33, train 97.26%
epoch 36, loss: 0.09, train 97.29%
epoch 36, loss: 0.21, train 97.26%
epoch 36, loss: 0.12, train 97.29%
epoch 36, loss: 0.24, train 97.21%
epoch 36, loss: 0.12, train 97.18%
epoch 36, loss: 0.28, train 97.05%
epoch 36, loss: 0.36, train 97.02%
epoch 36, loss: 0.23, train 96.89%
epoch 36, loss: 0.11, train 96.92%
epoch 36, loss: 0.08, train 96.96%
epoch 36, loss: 0.39, train 96.94%
epoch 36, loss: 0.07, train 96.97%
epoch 36, loss: 0.12, train 97.00%
epoch 36, loss: 0.03, train 97.03%
epoch 36, loss: 0.17, train 97.01%
epoch 36, loss: 0.26, train 96.89%
epoch 36, loss: 0.14, train 96.87%
epoch 36, loss: 0.10, train 96.90%
epoch 36, loss: 0.09, train 96.93%
epoch 36, loss: 0.07, train 96.96%
epoch 36, loss: 0.21, train 96.89%
epoch 36, loss: 0.06, train 96.92%
epoch 36, loss: 0.41, train 96.81%
epoch 36, loss: 0.26, train 96.79%
epoch 36, loss: 0.10, train 96.82%
epoch 36, loss: 0.44, train 96.81%
epoch 36, loss: 0.16, train 96.79%
epoch 36, loss: 0.15, train 96.82%
epoch 36, loss: 0.29, train 96.80%
epoch 36, loss: 0.05, train 96.83%
epoch 36, loss: 0.08, train 96.86%
epoch 36, loss: 0.07, train 96.89%
epoch 36, loss: 0.19, train 96.91%
epoch 36, loss: 0.16, train 96.94%
epoch 36, loss: 0.12, train 96.97%
epoch 36, loss: 0.33, train 96.86%
epoch 36, loss: 0.10, train 96.89%
epoch 36, loss: 0.10, train 96.92%
Epoch completed!
epoch 36, total signals 2400, average_loss_per_batch: 0.172910, train 96.92%
Validating
Val set size: 320, validation accuracy 82.50%
epoch 37, loss: 0.67, train 90.00%
epoch 37, loss: 0.20, train 92.50%
epoch 37, loss: 0.12, train 95.00%
epoch 37, loss: 0.09, train 96.25%
epoch 37, loss: 0.16, train 97.00%
epoch 37, loss: 0.11, train 97.50%
epoch 37, loss: 0.36, train 97.86%
epoch 37, loss: 0.09, train 98.12%
epoch 37, loss: 0.09, train 98.33%
epoch 37, loss: 0.06, train 98.50%
epoch 37, loss: 0.21, train 98.18%
epoch 37, loss: 0.18, train 97.92%
epoch 37, loss: 0.12, train 98.08%
epoch 37, loss: 0.12, train 98.21%
epoch 37, loss: 0.09, train 98.33%
epoch 37, loss: 0.27, train 98.44%
epoch 37, loss: 0.14, train 98.24%
epoch 37, loss: 0.05, train 98.33%
epoch 37, loss: 0.19, train 97.89%
epoch 37, loss: 0.36, train 97.75%
epoch 37, loss: 0.10, train 97.86%
epoch 37, loss: 0.07, train 97.95%
epoch 37, loss: 0.10, train 98.04%
epoch 37, loss: 0.10, train 98.12%
epoch 37, loss: 0.16, train 98.00%
epoch 37, loss: 0.13, train 98.08%
epoch 37, loss: 0.07, train 98.15%
epoch 37, loss: 0.14, train 98.21%
epoch 37, loss: 0.15, train 98.10%
epoch 37, loss: 0.16, train 98.17%
epoch 37, loss: 0.16, train 98.06%
epoch 37, loss: 0.09, train 98.12%
epoch 37, loss: 0.25, train 98.03%
epoch 37, loss: 0.12, train 98.09%
epoch 37, loss: 0.12, train 98.14%
epoch 37, loss: 0.11, train 98.19%
epoch 37, loss: 0.15, train 98.11%
epoch 37, loss: 0.46, train 98.03%
epoch 37, loss: 0.06, train 98.08%
epoch 37, loss: 0.18, train 98.12%
epoch 37, loss: 0.19, train 98.05%
epoch 37, loss: 0.15, train 98.10%
epoch 37, loss: 0.11, train 98.02%
epoch 37, loss: 0.09, train 98.07%
epoch 37, loss: 0.59, train 97.44%
epoch 37, loss: 0.05, train 97.50%
epoch 37, loss: 0.19, train 97.45%
epoch 37, loss: 0.09, train 97.50%
epoch 37, loss: 0.39, train 97.35%
epoch 37, loss: 0.39, train 97.10%
epoch 37, loss: 0.04, train 97.16%
epoch 37, loss: 0.15, train 97.21%
epoch 37, loss: 0.36, train 97.26%
epoch 37, loss: 0.08, train 97.31%
epoch 37, loss: 0.07, train 97.36%
epoch 37, loss: 0.18, train 97.32%
epoch 37, loss: 0.10, train 97.37%
epoch 37, loss: 0.07, train 97.41%
epoch 37, loss: 0.48, train 97.03%
epoch 37, loss: 0.11, train 97.08%
epoch 37, loss: 0.14, train 97.05%
epoch 37, loss: 0.19, train 97.10%
epoch 37, loss: 0.38, train 97.06%
epoch 37, loss: 0.10, train 97.11%
epoch 37, loss: 0.13, train 97.08%
epoch 37, loss: 0.09, train 97.12%
epoch 37, loss: 0.18, train 97.09%
epoch 37, loss: 0.15, train 97.06%
epoch 37, loss: 0.20, train 97.10%
epoch 37, loss: 0.11, train 97.14%
epoch 37, loss: 0.13, train 97.18%
epoch 37, loss: 0.09, train 97.22%
epoch 37, loss: 0.09, train 97.26%
epoch 37, loss: 0.28, train 97.23%
epoch 37, loss: 0.11, train 97.27%
epoch 37, loss: 0.14, train 97.24%
epoch 37, loss: 0.23, train 97.21%
epoch 37, loss: 0.07, train 97.24%
epoch 37, loss: 0.23, train 97.15%
epoch 37, loss: 0.18, train 97.19%
epoch 37, loss: 0.49, train 97.04%
epoch 37, loss: 0.36, train 97.01%
epoch 37, loss: 0.22, train 96.99%
epoch 37, loss: 0.22, train 96.90%
epoch 37, loss: 0.20, train 96.88%
epoch 37, loss: 0.41, train 96.80%
epoch 37, loss: 0.05, train 96.84%
epoch 37, loss: 0.12, train 96.88%
epoch 37, loss: 0.15, train 96.91%
epoch 37, loss: 0.12, train 96.94%
epoch 37, loss: 0.19, train 96.98%
epoch 37, loss: 0.58, train 96.85%
epoch 37, loss: 0.07, train 96.88%
epoch 37, loss: 0.63, train 96.76%
epoch 37, loss: 0.18, train 96.79%
epoch 37, loss: 0.17, train 96.82%
epoch 37, loss: 0.26, train 96.75%
epoch 37, loss: 0.13, train 96.79%
epoch 37, loss: 0.17, train 96.77%
epoch 37, loss: 0.04, train 96.80%
epoch 37, loss: 0.23, train 96.73%
epoch 37, loss: 0.19, train 96.72%
epoch 37, loss: 0.47, train 96.70%
epoch 37, loss: 0.37, train 96.73%
epoch 37, loss: 0.44, train 96.71%
epoch 37, loss: 0.15, train 96.75%
epoch 37, loss: 0.15, train 96.73%
epoch 37, loss: 0.55, train 96.57%
epoch 37, loss: 0.06, train 96.61%
epoch 37, loss: 0.08, train 96.64%
epoch 37, loss: 0.09, train 96.67%
epoch 37, loss: 0.13, train 96.70%
epoch 37, loss: 0.46, train 96.55%
epoch 37, loss: 0.41, train 96.45%
epoch 37, loss: 0.17, train 96.43%
epoch 37, loss: 0.11, train 96.47%
epoch 37, loss: 0.12, train 96.50%
epoch 37, loss: 0.16, train 96.53%
epoch 37, loss: 0.26, train 96.55%
epoch 37, loss: 0.21, train 96.58%
Epoch completed!
epoch 37, total signals 2400, average_loss_per_batch: 0.193640, train 96.58%
Validating
Val set size: 320, validation accuracy 80.94%
epoch 38, loss: 0.21, train 95.00%
epoch 38, loss: 0.08, train 97.50%
epoch 38, loss: 0.06, train 98.33%
epoch 38, loss: 0.27, train 98.75%
epoch 38, loss: 0.19, train 99.00%
epoch 38, loss: 0.05, train 99.17%
epoch 38, loss: 0.35, train 99.29%
epoch 38, loss: 0.11, train 99.38%
epoch 38, loss: 0.22, train 98.89%
epoch 38, loss: 0.08, train 99.00%
epoch 38, loss: 0.08, train 99.09%
epoch 38, loss: 0.13, train 99.17%
epoch 38, loss: 0.15, train 98.85%
epoch 38, loss: 0.35, train 97.86%
epoch 38, loss: 0.12, train 98.00%
epoch 38, loss: 0.09, train 98.12%
epoch 38, loss: 0.36, train 97.65%
epoch 38, loss: 0.23, train 97.78%
epoch 38, loss: 0.12, train 97.89%
epoch 38, loss: 0.09, train 98.00%
epoch 38, loss: 0.45, train 96.90%
epoch 38, loss: 0.26, train 96.59%
epoch 38, loss: 0.10, train 96.74%
epoch 38, loss: 0.08, train 96.88%
epoch 38, loss: 0.09, train 97.00%
epoch 38, loss: 0.08, train 97.12%
epoch 38, loss: 0.36, train 97.04%
epoch 38, loss: 0.17, train 97.14%
epoch 38, loss: 0.09, train 97.24%
epoch 38, loss: 0.10, train 97.17%
epoch 38, loss: 0.22, train 97.10%
epoch 38, loss: 0.12, train 97.03%
epoch 38, loss: 0.13, train 97.12%
epoch 38, loss: 0.10, train 97.21%
epoch 38, loss: 0.20, train 97.14%
epoch 38, loss: 0.09, train 97.22%
epoch 38, loss: 0.10, train 97.30%
epoch 38, loss: 0.27, train 97.24%
epoch 38, loss: 0.16, train 97.18%
epoch 38, loss: 0.14, train 97.12%
epoch 38, loss: 0.08, train 97.20%
epoch 38, loss: 0.10, train 97.26%
epoch 38, loss: 0.24, train 97.09%
epoch 38, loss: 0.23, train 97.16%
epoch 38, loss: 0.09, train 97.22%
epoch 38, loss: 0.22, train 97.17%
epoch 38, loss: 0.16, train 97.13%
epoch 38, loss: 0.08, train 97.19%
epoch 38, loss: 0.12, train 97.24%
epoch 38, loss: 0.10, train 97.30%
epoch 38, loss: 0.06, train 97.35%
epoch 38, loss: 0.24, train 97.31%
epoch 38, loss: 0.21, train 97.17%
epoch 38, loss: 0.12, train 97.22%
epoch 38, loss: 0.17, train 97.27%
epoch 38, loss: 0.20, train 97.14%
epoch 38, loss: 0.26, train 97.02%
epoch 38, loss: 0.15, train 96.98%
epoch 38, loss: 0.10, train 97.03%
epoch 38, loss: 0.17, train 97.00%
epoch 38, loss: 0.11, train 97.05%
epoch 38, loss: 0.09, train 97.10%
epoch 38, loss: 0.13, train 97.06%
epoch 38, loss: 0.15, train 97.11%
epoch 38, loss: 0.41, train 97.08%
epoch 38, loss: 0.08, train 97.12%
epoch 38, loss: 0.09, train 97.16%
epoch 38, loss: 0.17, train 97.13%
epoch 38, loss: 0.10, train 97.17%
epoch 38, loss: 0.07, train 97.21%
epoch 38, loss: 0.27, train 97.11%
epoch 38, loss: 0.11, train 97.15%
epoch 38, loss: 0.15, train 97.05%
epoch 38, loss: 0.12, train 97.03%
epoch 38, loss: 0.13, train 97.07%
epoch 38, loss: 0.13, train 97.11%
epoch 38, loss: 0.09, train 97.14%
epoch 38, loss: 0.19, train 97.05%
epoch 38, loss: 0.34, train 97.03%
epoch 38, loss: 0.47, train 96.81%
epoch 38, loss: 0.21, train 96.79%
epoch 38, loss: 0.31, train 96.83%
epoch 38, loss: 0.09, train 96.87%
epoch 38, loss: 0.18, train 96.85%
epoch 38, loss: 0.17, train 96.82%
epoch 38, loss: 0.21, train 96.80%
epoch 38, loss: 0.12, train 96.84%
epoch 38, loss: 0.22, train 96.82%
epoch 38, loss: 0.28, train 96.85%
epoch 38, loss: 0.31, train 96.78%
epoch 38, loss: 0.65, train 96.65%
epoch 38, loss: 0.15, train 96.68%
epoch 38, loss: 0.05, train 96.72%
epoch 38, loss: 0.10, train 96.76%
epoch 38, loss: 0.21, train 96.74%
epoch 38, loss: 0.10, train 96.77%
epoch 38, loss: 0.21, train 96.75%
epoch 38, loss: 0.28, train 96.68%
epoch 38, loss: 0.19, train 96.62%
epoch 38, loss: 0.12, train 96.65%
epoch 38, loss: 0.24, train 96.63%
epoch 38, loss: 0.12, train 96.67%
epoch 38, loss: 0.29, train 96.60%
epoch 38, loss: 0.10, train 96.63%
epoch 38, loss: 0.10, train 96.67%
epoch 38, loss: 0.18, train 96.70%
epoch 38, loss: 0.15, train 96.73%
epoch 38, loss: 0.26, train 96.71%
epoch 38, loss: 0.26, train 96.74%
epoch 38, loss: 0.10, train 96.77%
epoch 38, loss: 0.40, train 96.71%
epoch 38, loss: 0.17, train 96.70%
epoch 38, loss: 0.07, train 96.73%
epoch 38, loss: 0.10, train 96.75%
epoch 38, loss: 0.11, train 96.74%
epoch 38, loss: 0.11, train 96.72%
epoch 38, loss: 0.49, train 96.67%
epoch 38, loss: 0.12, train 96.69%
epoch 38, loss: 0.13, train 96.72%
epoch 38, loss: 0.11, train 96.75%
Epoch completed!
epoch 38, total signals 2400, average_loss_per_batch: 0.174415, train 96.75%
Validating
Val set size: 320, validation accuracy 82.81%
epoch 39, loss: 0.10, train 95.00%
epoch 39, loss: 0.11, train 95.00%
epoch 39, loss: 0.11, train 96.67%
epoch 39, loss: 0.12, train 97.50%
epoch 39, loss: 0.14, train 98.00%
epoch 39, loss: 0.21, train 97.50%
epoch 39, loss: 0.09, train 97.86%
epoch 39, loss: 0.28, train 97.50%
epoch 39, loss: 0.12, train 97.78%
epoch 39, loss: 0.29, train 97.00%
epoch 39, loss: 0.14, train 96.82%
epoch 39, loss: 0.66, train 95.42%
epoch 39, loss: 0.08, train 95.77%
epoch 39, loss: 0.10, train 96.07%
epoch 39, loss: 0.26, train 95.67%
epoch 39, loss: 0.26, train 95.31%
epoch 39, loss: 0.09, train 95.59%
epoch 39, loss: 0.36, train 95.00%
epoch 39, loss: 0.26, train 95.00%
epoch 39, loss: 0.14, train 95.00%
epoch 39, loss: 0.04, train 95.24%
epoch 39, loss: 0.07, train 95.45%
epoch 39, loss: 0.11, train 95.43%
epoch 39, loss: 0.09, train 95.62%
epoch 39, loss: 0.11, train 95.80%
epoch 39, loss: 0.05, train 95.96%
epoch 39, loss: 0.07, train 96.11%
epoch 39, loss: 0.13, train 96.25%
epoch 39, loss: 0.11, train 96.38%
epoch 39, loss: 0.54, train 95.83%
epoch 39, loss: 0.07, train 95.97%
epoch 39, loss: 0.18, train 95.94%
epoch 39, loss: 0.13, train 96.06%
epoch 39, loss: 0.17, train 96.18%
epoch 39, loss: 0.04, train 96.29%
epoch 39, loss: 0.33, train 95.83%
epoch 39, loss: 0.23, train 95.68%
epoch 39, loss: 0.20, train 95.66%
epoch 39, loss: 0.11, train 95.77%
epoch 39, loss: 0.13, train 95.88%
epoch 39, loss: 0.12, train 95.98%
epoch 39, loss: 0.12, train 96.07%
epoch 39, loss: 0.11, train 96.16%
epoch 39, loss: 0.15, train 96.25%
epoch 39, loss: 0.27, train 96.33%
epoch 39, loss: 0.23, train 96.30%
epoch 39, loss: 0.15, train 96.28%
epoch 39, loss: 0.14, train 96.25%
epoch 39, loss: 0.20, train 96.33%
epoch 39, loss: 0.25, train 96.30%
epoch 39, loss: 0.27, train 96.27%
epoch 39, loss: 0.08, train 96.35%
epoch 39, loss: 0.13, train 96.42%
epoch 39, loss: 0.16, train 96.39%
epoch 39, loss: 0.17, train 96.27%
epoch 39, loss: 0.11, train 96.25%
epoch 39, loss: 0.37, train 96.14%
epoch 39, loss: 0.26, train 96.03%
epoch 39, loss: 0.23, train 95.93%
epoch 39, loss: 0.13, train 95.92%
epoch 39, loss: 0.23, train 95.74%
epoch 39, loss: 0.16, train 95.81%
epoch 39, loss: 0.53, train 95.63%
epoch 39, loss: 0.14, train 95.70%
epoch 39, loss: 0.07, train 95.77%
epoch 39, loss: 0.15, train 95.83%
epoch 39, loss: 0.12, train 95.82%
epoch 39, loss: 0.53, train 95.66%
epoch 39, loss: 0.05, train 95.72%
epoch 39, loss: 0.19, train 95.71%
epoch 39, loss: 0.18, train 95.70%
epoch 39, loss: 0.04, train 95.76%
epoch 39, loss: 0.21, train 95.82%
epoch 39, loss: 0.13, train 95.88%
epoch 39, loss: 0.18, train 95.87%
epoch 39, loss: 0.32, train 95.79%
epoch 39, loss: 0.38, train 95.84%
epoch 39, loss: 0.23, train 95.77%
epoch 39, loss: 0.50, train 95.76%
epoch 39, loss: 0.11, train 95.75%
epoch 39, loss: 0.08, train 95.80%
epoch 39, loss: 0.22, train 95.73%
epoch 39, loss: 0.07, train 95.78%
epoch 39, loss: 0.08, train 95.83%
epoch 39, loss: 0.16, train 95.88%
epoch 39, loss: 0.55, train 95.87%
epoch 39, loss: 0.20, train 95.86%
epoch 39, loss: 0.16, train 95.91%
epoch 39, loss: 0.07, train 95.96%
epoch 39, loss: 0.22, train 96.00%
epoch 39, loss: 0.18, train 96.04%
epoch 39, loss: 0.12, train 96.09%
epoch 39, loss: 0.23, train 96.08%
epoch 39, loss: 0.14, train 96.12%
epoch 39, loss: 0.22, train 96.16%
epoch 39, loss: 0.17, train 96.20%
epoch 39, loss: 0.13, train 96.24%
epoch 39, loss: 0.31, train 96.17%
epoch 39, loss: 0.08, train 96.21%
epoch 39, loss: 0.27, train 96.20%
epoch 39, loss: 0.19, train 96.19%
epoch 39, loss: 0.79, train 96.03%
epoch 39, loss: 0.24, train 95.97%
epoch 39, loss: 0.11, train 96.01%
epoch 39, loss: 0.14, train 96.05%
epoch 39, loss: 0.11, train 96.08%
epoch 39, loss: 0.05, train 96.12%
epoch 39, loss: 0.14, train 96.16%
epoch 39, loss: 0.21, train 96.19%
epoch 39, loss: 0.49, train 96.18%
epoch 39, loss: 0.36, train 96.17%
epoch 39, loss: 0.13, train 96.21%
epoch 39, loss: 0.24, train 96.19%
epoch 39, loss: 0.11, train 96.23%
epoch 39, loss: 0.31, train 96.26%
epoch 39, loss: 0.27, train 96.29%
epoch 39, loss: 0.10, train 96.32%
epoch 39, loss: 0.10, train 96.36%
epoch 39, loss: 0.14, train 96.39%
epoch 39, loss: 0.11, train 96.42%
Epoch completed!
epoch 39, total signals 2400, average_loss_per_batch: 0.190515, train 96.42%
Validating
Val set size: 320, validation accuracy 82.19%
epoch 40, loss: 0.12, train 100.00%
epoch 40, loss: 0.38, train 100.00%
epoch 40, loss: 0.22, train 98.33%
epoch 40, loss: 0.19, train 97.50%
epoch 40, loss: 0.15, train 98.00%
epoch 40, loss: 0.28, train 98.33%
epoch 40, loss: 0.13, train 98.57%
epoch 40, loss: 0.04, train 98.75%
epoch 40, loss: 0.09, train 98.89%
epoch 40, loss: 0.12, train 99.00%
epoch 40, loss: 0.17, train 98.64%
epoch 40, loss: 0.10, train 98.75%
epoch 40, loss: 0.11, train 98.85%
epoch 40, loss: 0.59, train 97.86%
epoch 40, loss: 0.07, train 98.00%
epoch 40, loss: 0.11, train 98.12%
epoch 40, loss: 0.13, train 98.24%
epoch 40, loss: 0.11, train 98.33%
epoch 40, loss: 0.16, train 98.42%
epoch 40, loss: 0.27, train 98.00%
epoch 40, loss: 0.10, train 98.10%
epoch 40, loss: 0.14, train 97.95%
epoch 40, loss: 0.10, train 98.04%
epoch 40, loss: 0.09, train 98.12%
epoch 40, loss: 0.21, train 98.00%
epoch 40, loss: 0.06, train 98.08%
epoch 40, loss: 0.13, train 98.15%
epoch 40, loss: 0.14, train 98.21%
epoch 40, loss: 0.33, train 98.28%
epoch 40, loss: 0.08, train 98.33%
epoch 40, loss: 0.12, train 98.39%
epoch 40, loss: 0.11, train 98.44%
epoch 40, loss: 0.17, train 98.48%
epoch 40, loss: 0.10, train 98.38%
epoch 40, loss: 0.06, train 98.43%
epoch 40, loss: 0.33, train 98.33%
epoch 40, loss: 0.14, train 98.38%
epoch 40, loss: 0.18, train 98.29%
epoch 40, loss: 0.06, train 98.33%
epoch 40, loss: 0.04, train 98.38%
epoch 40, loss: 0.14, train 98.41%
epoch 40, loss: 0.05, train 98.45%
epoch 40, loss: 0.17, train 98.37%
epoch 40, loss: 0.10, train 98.30%
epoch 40, loss: 0.16, train 98.33%
epoch 40, loss: 0.22, train 98.15%
epoch 40, loss: 0.07, train 98.19%
epoch 40, loss: 0.16, train 98.23%
epoch 40, loss: 0.12, train 98.16%
epoch 40, loss: 0.22, train 98.10%
epoch 40, loss: 0.08, train 98.14%
epoch 40, loss: 0.17, train 98.17%
epoch 40, loss: 0.39, train 98.02%
epoch 40, loss: 0.50, train 97.96%
epoch 40, loss: 0.22, train 98.00%
epoch 40, loss: 0.07, train 98.04%
epoch 40, loss: 0.28, train 97.89%
epoch 40, loss: 0.11, train 97.93%
epoch 40, loss: 0.10, train 97.97%
epoch 40, loss: 0.11, train 98.00%
epoch 40, loss: 0.19, train 97.95%
epoch 40, loss: 0.35, train 97.90%
epoch 40, loss: 0.07, train 97.94%
epoch 40, loss: 0.18, train 97.89%
epoch 40, loss: 0.08, train 97.92%
epoch 40, loss: 0.09, train 97.95%
epoch 40, loss: 0.20, train 97.91%
epoch 40, loss: 0.29, train 97.94%
epoch 40, loss: 0.19, train 97.90%
epoch 40, loss: 0.17, train 97.86%
epoch 40, loss: 0.28, train 97.82%
epoch 40, loss: 0.08, train 97.85%
epoch 40, loss: 0.22, train 97.81%
epoch 40, loss: 0.14, train 97.84%
epoch 40, loss: 0.25, train 97.73%
epoch 40, loss: 0.24, train 97.63%
epoch 40, loss: 0.05, train 97.66%
epoch 40, loss: 0.14, train 97.69%
epoch 40, loss: 0.16, train 97.72%
epoch 40, loss: 0.30, train 97.56%
epoch 40, loss: 0.14, train 97.53%
epoch 40, loss: 0.14, train 97.56%
epoch 40, loss: 0.29, train 97.47%
epoch 40, loss: 0.22, train 97.38%
epoch 40, loss: 0.18, train 97.41%
epoch 40, loss: 0.11, train 97.44%
epoch 40, loss: 0.19, train 97.41%
epoch 40, loss: 0.17, train 97.39%
epoch 40, loss: 0.18, train 97.42%
epoch 40, loss: 0.13, train 97.39%
epoch 40, loss: 0.18, train 97.36%
epoch 40, loss: 0.25, train 97.28%
epoch 40, loss: 0.06, train 97.31%
epoch 40, loss: 0.11, train 97.34%
epoch 40, loss: 0.09, train 97.37%
epoch 40, loss: 0.11, train 97.40%
epoch 40, loss: 0.07, train 97.42%
epoch 40, loss: 0.15, train 97.40%
epoch 40, loss: 0.14, train 97.42%
epoch 40, loss: 0.14, train 97.45%
epoch 40, loss: 0.10, train 97.43%
epoch 40, loss: 0.15, train 97.45%
epoch 40, loss: 0.21, train 97.43%
epoch 40, loss: 0.17, train 97.40%
epoch 40, loss: 0.30, train 97.29%
epoch 40, loss: 0.29, train 97.31%
epoch 40, loss: 0.12, train 97.34%
epoch 40, loss: 0.10, train 97.36%
epoch 40, loss: 0.17, train 97.39%
epoch 40, loss: 0.20, train 97.36%
epoch 40, loss: 0.49, train 97.30%
epoch 40, loss: 0.10, train 97.28%
epoch 40, loss: 0.19, train 97.26%
epoch 40, loss: 0.49, train 97.24%
epoch 40, loss: 0.17, train 97.22%
epoch 40, loss: 0.08, train 97.24%
epoch 40, loss: 0.23, train 97.22%
epoch 40, loss: 0.09, train 97.25%
epoch 40, loss: 0.10, train 97.27%
epoch 40, loss: 0.24, train 97.21%
Epoch completed!
epoch 40, total signals 2400, average_loss_per_batch: 0.169829, train 97.21%
Validating
Val set size: 320, validation accuracy 83.12%
epoch 41, loss: 0.45, train 90.00%
epoch 41, loss: 0.06, train 95.00%
epoch 41, loss: 0.58, train 91.67%
epoch 41, loss: 0.27, train 91.25%
epoch 41, loss: 0.23, train 93.00%
epoch 41, loss: 0.11, train 94.17%
epoch 41, loss: 0.14, train 94.29%
epoch 41, loss: 0.07, train 95.00%
epoch 41, loss: 0.30, train 95.56%
epoch 41, loss: 0.14, train 96.00%
epoch 41, loss: 0.10, train 96.36%
epoch 41, loss: 0.10, train 96.67%
epoch 41, loss: 0.18, train 96.92%
epoch 41, loss: 0.07, train 97.14%
epoch 41, loss: 0.12, train 97.33%
epoch 41, loss: 0.22, train 96.88%
epoch 41, loss: 0.08, train 97.06%
epoch 41, loss: 0.31, train 96.67%
epoch 41, loss: 0.17, train 96.84%
epoch 41, loss: 0.33, train 97.00%
epoch 41, loss: 0.18, train 96.90%
epoch 41, loss: 0.15, train 96.82%
epoch 41, loss: 0.13, train 96.96%
epoch 41, loss: 0.66, train 96.25%
epoch 41, loss: 0.05, train 96.40%
epoch 41, loss: 0.07, train 96.54%
epoch 41, loss: 0.15, train 96.67%
epoch 41, loss: 0.16, train 96.61%
epoch 41, loss: 0.24, train 96.38%
epoch 41, loss: 0.07, train 96.50%
epoch 41, loss: 0.13, train 96.45%
epoch 41, loss: 0.06, train 96.56%
epoch 41, loss: 0.13, train 96.67%
epoch 41, loss: 0.13, train 96.76%
epoch 41, loss: 0.15, train 96.71%
epoch 41, loss: 0.07, train 96.81%
epoch 41, loss: 0.37, train 96.49%
epoch 41, loss: 0.05, train 96.58%
epoch 41, loss: 0.12, train 96.67%
epoch 41, loss: 0.10, train 96.75%
epoch 41, loss: 0.60, train 96.10%
epoch 41, loss: 0.11, train 96.19%
epoch 41, loss: 0.11, train 96.28%
epoch 41, loss: 0.10, train 96.36%
epoch 41, loss: 0.09, train 96.44%
epoch 41, loss: 0.13, train 96.52%
epoch 41, loss: 0.16, train 96.60%
epoch 41, loss: 0.05, train 96.67%
epoch 41, loss: 0.09, train 96.73%
epoch 41, loss: 0.20, train 96.80%
epoch 41, loss: 0.11, train 96.86%
epoch 41, loss: 0.13, train 96.92%
epoch 41, loss: 0.08, train 96.98%
epoch 41, loss: 0.15, train 96.94%
epoch 41, loss: 0.65, train 96.73%
epoch 41, loss: 0.10, train 96.79%
epoch 41, loss: 0.14, train 96.84%
epoch 41, loss: 0.07, train 96.90%
epoch 41, loss: 0.05, train 96.95%
epoch 41, loss: 0.06, train 97.00%
epoch 41, loss: 0.14, train 96.97%
epoch 41, loss: 0.09, train 97.02%
epoch 41, loss: 0.19, train 96.98%
epoch 41, loss: 0.08, train 97.03%
epoch 41, loss: 0.06, train 97.08%
epoch 41, loss: 0.21, train 97.12%
epoch 41, loss: 0.09, train 97.16%
epoch 41, loss: 0.12, train 97.21%
epoch 41, loss: 0.33, train 97.03%
epoch 41, loss: 0.06, train 97.07%
epoch 41, loss: 0.38, train 96.90%
epoch 41, loss: 0.10, train 96.94%
epoch 41, loss: 0.11, train 96.99%
epoch 41, loss: 0.37, train 96.96%
epoch 41, loss: 0.21, train 96.93%
epoch 41, loss: 0.06, train 96.97%
epoch 41, loss: 0.39, train 96.95%
epoch 41, loss: 0.21, train 96.92%
epoch 41, loss: 0.27, train 96.77%
epoch 41, loss: 0.14, train 96.81%
epoch 41, loss: 0.09, train 96.85%
epoch 41, loss: 0.14, train 96.89%
epoch 41, loss: 0.14, train 96.93%
epoch 41, loss: 0.42, train 96.85%
epoch 41, loss: 0.08, train 96.88%
epoch 41, loss: 0.14, train 96.92%
epoch 41, loss: 0.08, train 96.95%
epoch 41, loss: 0.22, train 96.93%
epoch 41, loss: 0.33, train 96.97%
epoch 41, loss: 0.12, train 96.94%
epoch 41, loss: 0.19, train 96.98%
epoch 41, loss: 0.10, train 97.01%
epoch 41, loss: 0.15, train 97.04%
epoch 41, loss: 0.26, train 97.02%
epoch 41, loss: 0.09, train 97.05%
epoch 41, loss: 0.08, train 97.08%
epoch 41, loss: 0.15, train 97.11%
epoch 41, loss: 0.10, train 97.14%
epoch 41, loss: 0.18, train 97.17%
epoch 41, loss: 0.11, train 97.20%
epoch 41, loss: 0.20, train 97.18%
epoch 41, loss: 0.10, train 97.21%
epoch 41, loss: 0.22, train 97.18%
epoch 41, loss: 0.12, train 97.21%
epoch 41, loss: 0.11, train 97.24%
epoch 41, loss: 0.12, train 97.22%
epoch 41, loss: 0.10, train 97.24%
epoch 41, loss: 0.10, train 97.27%
epoch 41, loss: 0.08, train 97.29%
epoch 41, loss: 0.12, train 97.27%
epoch 41, loss: 0.10, train 97.30%
epoch 41, loss: 0.14, train 97.32%
epoch 41, loss: 0.14, train 97.35%
epoch 41, loss: 0.45, train 97.19%
epoch 41, loss: 0.14, train 97.22%
epoch 41, loss: 1.00, train 96.90%
epoch 41, loss: 0.19, train 96.88%
epoch 41, loss: 0.08, train 96.91%
epoch 41, loss: 0.11, train 96.93%
epoch 41, loss: 0.16, train 96.92%
Epoch completed!
epoch 41, total signals 2400, average_loss_per_batch: 0.174478, train 96.92%
Validating
Val set size: 320, validation accuracy 82.19%
epoch 42, loss: 0.17, train 95.00%
epoch 42, loss: 0.34, train 97.50%
epoch 42, loss: 0.41, train 98.33%
epoch 42, loss: 0.66, train 92.50%
epoch 42, loss: 0.09, train 94.00%
epoch 42, loss: 0.10, train 95.00%
epoch 42, loss: 0.38, train 95.71%
epoch 42, loss: 0.11, train 96.25%
epoch 42, loss: 0.09, train 96.67%
epoch 42, loss: 0.09, train 97.00%
epoch 42, loss: 0.11, train 96.82%
epoch 42, loss: 0.05, train 97.08%
epoch 42, loss: 0.52, train 95.77%
epoch 42, loss: 0.17, train 96.07%
epoch 42, loss: 0.22, train 96.00%
epoch 42, loss: 0.05, train 96.25%
epoch 42, loss: 0.08, train 96.47%
epoch 42, loss: 0.15, train 96.39%
epoch 42, loss: 0.24, train 96.32%
epoch 42, loss: 0.11, train 96.50%
epoch 42, loss: 0.17, train 96.67%
epoch 42, loss: 0.14, train 96.59%
epoch 42, loss: 0.11, train 96.74%
epoch 42, loss: 0.09, train 96.88%
epoch 42, loss: 0.04, train 97.00%
epoch 42, loss: 0.10, train 97.12%
epoch 42, loss: 0.23, train 97.04%
epoch 42, loss: 0.41, train 97.14%
epoch 42, loss: 0.09, train 97.24%
epoch 42, loss: 0.13, train 97.33%
epoch 42, loss: 0.04, train 97.42%
epoch 42, loss: 0.91, train 96.56%
epoch 42, loss: 0.58, train 96.36%
epoch 42, loss: 0.21, train 96.18%
epoch 42, loss: 0.06, train 96.29%
epoch 42, loss: 0.42, train 96.39%
epoch 42, loss: 0.11, train 96.35%
epoch 42, loss: 0.17, train 96.32%
epoch 42, loss: 0.06, train 96.41%
epoch 42, loss: 0.18, train 96.38%
epoch 42, loss: 0.28, train 96.34%
epoch 42, loss: 0.03, train 96.43%
epoch 42, loss: 0.15, train 96.40%
epoch 42, loss: 0.15, train 96.48%
epoch 42, loss: 0.14, train 96.44%
epoch 42, loss: 0.26, train 96.41%
epoch 42, loss: 0.20, train 96.38%
epoch 42, loss: 0.06, train 96.46%
epoch 42, loss: 0.05, train 96.53%
epoch 42, loss: 0.09, train 96.60%
epoch 42, loss: 0.11, train 96.67%
epoch 42, loss: 0.58, train 96.63%
epoch 42, loss: 0.19, train 96.60%
epoch 42, loss: 0.08, train 96.67%
epoch 42, loss: 0.13, train 96.64%
epoch 42, loss: 0.07, train 96.70%
epoch 42, loss: 0.29, train 96.67%
epoch 42, loss: 0.21, train 96.72%
epoch 42, loss: 0.12, train 96.69%
epoch 42, loss: 0.41, train 96.67%
epoch 42, loss: 0.34, train 96.64%
epoch 42, loss: 0.15, train 96.69%
epoch 42, loss: 0.10, train 96.75%
epoch 42, loss: 0.13, train 96.80%
epoch 42, loss: 0.09, train 96.85%
epoch 42, loss: 0.14, train 96.82%
epoch 42, loss: 0.07, train 96.87%
epoch 42, loss: 0.08, train 96.91%
epoch 42, loss: 0.09, train 96.96%
epoch 42, loss: 0.34, train 96.93%
epoch 42, loss: 0.18, train 96.97%
epoch 42, loss: 0.17, train 96.94%
epoch 42, loss: 0.30, train 96.85%
epoch 42, loss: 0.19, train 96.82%
epoch 42, loss: 0.09, train 96.87%
epoch 42, loss: 0.22, train 96.84%
epoch 42, loss: 0.47, train 96.69%
epoch 42, loss: 0.24, train 96.67%
epoch 42, loss: 0.13, train 96.65%
epoch 42, loss: 0.25, train 96.62%
epoch 42, loss: 0.10, train 96.67%
epoch 42, loss: 0.13, train 96.71%
epoch 42, loss: 0.21, train 96.69%
epoch 42, loss: 0.23, train 96.67%
epoch 42, loss: 0.08, train 96.71%
epoch 42, loss: 0.17, train 96.69%
epoch 42, loss: 0.14, train 96.72%
epoch 42, loss: 0.12, train 96.70%
epoch 42, loss: 0.10, train 96.74%
epoch 42, loss: 0.16, train 96.78%
epoch 42, loss: 0.32, train 96.65%
epoch 42, loss: 0.13, train 96.63%
epoch 42, loss: 0.15, train 96.61%
epoch 42, loss: 0.17, train 96.60%
epoch 42, loss: 0.12, train 96.63%
epoch 42, loss: 0.29, train 96.67%
epoch 42, loss: 0.25, train 96.55%
epoch 42, loss: 0.10, train 96.58%
epoch 42, loss: 0.12, train 96.62%
epoch 42, loss: 0.13, train 96.60%
epoch 42, loss: 0.09, train 96.63%
epoch 42, loss: 0.06, train 96.67%
epoch 42, loss: 0.14, train 96.65%
epoch 42, loss: 0.12, train 96.68%
epoch 42, loss: 0.27, train 96.62%
epoch 42, loss: 0.19, train 96.60%
epoch 42, loss: 0.29, train 96.54%
epoch 42, loss: 0.14, train 96.53%
epoch 42, loss: 0.24, train 96.51%
epoch 42, loss: 0.16, train 96.45%
epoch 42, loss: 0.21, train 96.44%
epoch 42, loss: 0.49, train 96.29%
epoch 42, loss: 0.09, train 96.33%
epoch 42, loss: 0.20, train 96.27%
epoch 42, loss: 0.15, train 96.30%
epoch 42, loss: 0.05, train 96.34%
epoch 42, loss: 0.17, train 96.32%
epoch 42, loss: 0.17, train 96.31%
epoch 42, loss: 0.12, train 96.34%
epoch 42, loss: 0.19, train 96.33%
Epoch completed!
epoch 42, total signals 2400, average_loss_per_batch: 0.187442, train 96.33%
Validating
Val set size: 320, validation accuracy 85.00%
epoch 43, loss: 0.06, train 100.00%
epoch 43, loss: 0.40, train 90.00%
epoch 43, loss: 0.10, train 93.33%
epoch 43, loss: 0.13, train 95.00%
epoch 43, loss: 0.22, train 95.00%
epoch 43, loss: 0.08, train 95.83%
epoch 43, loss: 0.06, train 96.43%
epoch 43, loss: 0.13, train 96.88%
epoch 43, loss: 0.23, train 96.67%
epoch 43, loss: 0.07, train 97.00%
epoch 43, loss: 0.07, train 97.27%
epoch 43, loss: 0.13, train 97.08%
epoch 43, loss: 0.32, train 97.31%
epoch 43, loss: 1.21, train 93.93%
epoch 43, loss: 0.11, train 94.33%
epoch 43, loss: 0.15, train 94.38%
epoch 43, loss: 0.20, train 94.41%
epoch 43, loss: 0.14, train 94.72%
epoch 43, loss: 0.12, train 95.00%
epoch 43, loss: 0.24, train 94.75%
epoch 43, loss: 0.08, train 95.00%
epoch 43, loss: 0.63, train 95.00%
epoch 43, loss: 0.23, train 94.78%
epoch 43, loss: 0.04, train 95.00%
epoch 43, loss: 0.28, train 94.80%
epoch 43, loss: 0.13, train 95.00%
epoch 43, loss: 0.41, train 94.81%
epoch 43, loss: 0.18, train 95.00%
epoch 43, loss: 0.15, train 95.00%
epoch 43, loss: 0.11, train 95.00%
epoch 43, loss: 0.06, train 95.16%
epoch 43, loss: 0.17, train 95.31%
epoch 43, loss: 0.89, train 94.85%
epoch 43, loss: 0.17, train 94.71%
epoch 43, loss: 0.33, train 94.43%
epoch 43, loss: 0.11, train 94.58%
epoch 43, loss: 0.08, train 94.73%
epoch 43, loss: 0.16, train 94.74%
epoch 43, loss: 0.25, train 94.74%
epoch 43, loss: 0.15, train 94.75%
epoch 43, loss: 0.07, train 94.88%
epoch 43, loss: 0.13, train 95.00%
epoch 43, loss: 0.09, train 95.12%
epoch 43, loss: 0.18, train 95.23%
epoch 43, loss: 0.62, train 94.89%
epoch 43, loss: 0.19, train 95.00%
epoch 43, loss: 0.17, train 95.00%
epoch 43, loss: 0.15, train 95.00%
epoch 43, loss: 0.17, train 95.10%
epoch 43, loss: 0.17, train 95.10%
epoch 43, loss: 0.15, train 95.10%
epoch 43, loss: 0.26, train 95.10%
epoch 43, loss: 0.17, train 95.19%
epoch 43, loss: 0.06, train 95.28%
epoch 43, loss: 0.09, train 95.36%
epoch 43, loss: 0.10, train 95.45%
epoch 43, loss: 0.09, train 95.53%
epoch 43, loss: 0.63, train 95.52%
epoch 43, loss: 0.10, train 95.59%
epoch 43, loss: 0.06, train 95.67%
epoch 43, loss: 0.14, train 95.74%
epoch 43, loss: 0.34, train 95.73%
epoch 43, loss: 0.16, train 95.71%
epoch 43, loss: 0.14, train 95.78%
epoch 43, loss: 0.19, train 95.77%
epoch 43, loss: 0.13, train 95.76%
epoch 43, loss: 0.37, train 95.75%
epoch 43, loss: 0.10, train 95.81%
epoch 43, loss: 0.16, train 95.80%
epoch 43, loss: 0.14, train 95.86%
epoch 43, loss: 0.18, train 95.92%
epoch 43, loss: 0.15, train 95.97%
epoch 43, loss: 0.15, train 96.03%
epoch 43, loss: 0.22, train 96.08%
epoch 43, loss: 0.23, train 96.07%
epoch 43, loss: 0.14, train 96.12%
epoch 43, loss: 0.16, train 96.17%
epoch 43, loss: 0.13, train 96.22%
epoch 43, loss: 0.44, train 96.01%
epoch 43, loss: 0.12, train 96.06%
epoch 43, loss: 0.11, train 96.11%
epoch 43, loss: 0.51, train 95.98%
epoch 43, loss: 0.11, train 96.02%
epoch 43, loss: 0.23, train 96.01%
epoch 43, loss: 0.13, train 96.06%
epoch 43, loss: 0.11, train 96.10%
epoch 43, loss: 0.46, train 95.92%
epoch 43, loss: 0.16, train 95.91%
epoch 43, loss: 0.09, train 95.96%
epoch 43, loss: 0.10, train 96.00%
epoch 43, loss: 0.14, train 95.99%
epoch 43, loss: 0.17, train 96.03%
epoch 43, loss: 0.09, train 96.02%
epoch 43, loss: 0.08, train 96.06%
epoch 43, loss: 0.09, train 96.11%
epoch 43, loss: 0.36, train 96.09%
epoch 43, loss: 0.16, train 96.13%
epoch 43, loss: 0.31, train 96.17%
epoch 43, loss: 0.07, train 96.21%
epoch 43, loss: 0.09, train 96.25%
epoch 43, loss: 0.10, train 96.29%
epoch 43, loss: 0.11, train 96.32%
epoch 43, loss: 0.10, train 96.36%
epoch 43, loss: 0.17, train 96.39%
epoch 43, loss: 0.61, train 96.29%
epoch 43, loss: 0.16, train 96.27%
epoch 43, loss: 0.18, train 96.26%
epoch 43, loss: 0.24, train 96.30%
epoch 43, loss: 0.13, train 96.33%
epoch 43, loss: 0.14, train 96.32%
epoch 43, loss: 0.09, train 96.35%
epoch 43, loss: 0.26, train 96.29%
epoch 43, loss: 0.11, train 96.28%
epoch 43, loss: 0.08, train 96.32%
epoch 43, loss: 0.31, train 96.35%
epoch 43, loss: 0.12, train 96.38%
epoch 43, loss: 0.09, train 96.41%
epoch 43, loss: 0.21, train 96.44%
epoch 43, loss: 0.07, train 96.47%
epoch 43, loss: 0.16, train 96.46%
Epoch completed!
epoch 43, total signals 2400, average_loss_per_batch: 0.193467, train 96.46%
Validating
Val set size: 320, validation accuracy 81.56%
epoch 44, loss: 0.32, train 100.00%
epoch 44, loss: 0.27, train 95.00%
epoch 44, loss: 0.13, train 96.67%
epoch 44, loss: 0.15, train 96.25%
epoch 44, loss: 0.11, train 97.00%
epoch 44, loss: 0.16, train 96.67%
epoch 44, loss: 0.13, train 96.43%
epoch 44, loss: 0.24, train 95.00%
epoch 44, loss: 0.10, train 95.56%
epoch 44, loss: 0.09, train 96.00%
epoch 44, loss: 0.11, train 96.36%
epoch 44, loss: 0.09, train 96.67%
epoch 44, loss: 0.07, train 96.92%
epoch 44, loss: 0.07, train 97.14%
epoch 44, loss: 0.09, train 97.33%
epoch 44, loss: 0.10, train 97.50%
epoch 44, loss: 0.12, train 97.65%
epoch 44, loss: 0.15, train 97.50%
epoch 44, loss: 0.07, train 97.63%
epoch 44, loss: 0.06, train 97.75%
epoch 44, loss: 0.06, train 97.86%
epoch 44, loss: 0.13, train 97.73%
epoch 44, loss: 0.06, train 97.83%
epoch 44, loss: 0.10, train 97.92%
epoch 44, loss: 0.14, train 97.80%
epoch 44, loss: 0.13, train 97.69%
epoch 44, loss: 0.19, train 97.59%
epoch 44, loss: 0.06, train 97.68%
epoch 44, loss: 0.17, train 97.59%
epoch 44, loss: 0.18, train 97.50%
epoch 44, loss: 0.43, train 97.58%
epoch 44, loss: 0.15, train 97.66%
epoch 44, loss: 0.18, train 97.42%
epoch 44, loss: 0.08, train 97.50%
epoch 44, loss: 0.11, train 97.57%
epoch 44, loss: 0.13, train 97.64%
epoch 44, loss: 0.23, train 97.57%
epoch 44, loss: 0.12, train 97.63%
epoch 44, loss: 0.09, train 97.69%
epoch 44, loss: 0.10, train 97.75%
epoch 44, loss: 0.37, train 97.80%
epoch 44, loss: 0.12, train 97.86%
epoch 44, loss: 0.13, train 97.91%
epoch 44, loss: 0.12, train 97.95%
epoch 44, loss: 0.17, train 97.89%
epoch 44, loss: 0.21, train 97.83%
epoch 44, loss: 0.30, train 97.77%
epoch 44, loss: 0.70, train 97.29%
epoch 44, loss: 0.17, train 97.14%
epoch 44, loss: 0.14, train 97.20%
epoch 44, loss: 0.13, train 97.25%
epoch 44, loss: 0.09, train 97.31%
epoch 44, loss: 0.07, train 97.36%
epoch 44, loss: 0.08, train 97.41%
epoch 44, loss: 0.28, train 97.27%
epoch 44, loss: 0.17, train 97.23%
epoch 44, loss: 0.32, train 97.28%
epoch 44, loss: 0.35, train 97.16%
epoch 44, loss: 0.15, train 97.20%
epoch 44, loss: 0.10, train 97.25%
epoch 44, loss: 0.18, train 97.30%
epoch 44, loss: 0.17, train 97.34%
epoch 44, loss: 0.17, train 97.38%
epoch 44, loss: 0.08, train 97.42%
epoch 44, loss: 0.26, train 97.38%
epoch 44, loss: 0.23, train 97.35%
epoch 44, loss: 0.33, train 97.31%
epoch 44, loss: 0.13, train 97.35%
epoch 44, loss: 0.18, train 97.39%
epoch 44, loss: 0.11, train 97.36%
epoch 44, loss: 0.27, train 97.32%
epoch 44, loss: 0.37, train 97.36%
epoch 44, loss: 0.10, train 97.40%
epoch 44, loss: 0.10, train 97.43%
epoch 44, loss: 0.11, train 97.47%
epoch 44, loss: 0.07, train 97.50%
epoch 44, loss: 0.42, train 97.34%
epoch 44, loss: 0.07, train 97.37%
epoch 44, loss: 0.17, train 97.34%
epoch 44, loss: 0.18, train 97.31%
epoch 44, loss: 0.08, train 97.35%
epoch 44, loss: 0.32, train 97.38%
epoch 44, loss: 0.10, train 97.41%
epoch 44, loss: 0.11, train 97.44%
epoch 44, loss: 0.14, train 97.47%
epoch 44, loss: 0.10, train 97.50%
epoch 44, loss: 0.11, train 97.53%
epoch 44, loss: 0.08, train 97.50%
epoch 44, loss: 0.16, train 97.47%
epoch 44, loss: 0.16, train 97.44%
epoch 44, loss: 0.08, train 97.47%
epoch 44, loss: 0.12, train 97.50%
epoch 44, loss: 0.06, train 97.53%
epoch 44, loss: 0.07, train 97.55%
epoch 44, loss: 0.18, train 97.58%
epoch 44, loss: 0.20, train 97.50%
epoch 44, loss: 0.09, train 97.53%
epoch 44, loss: 0.16, train 97.45%
epoch 44, loss: 0.09, train 97.47%
epoch 44, loss: 0.12, train 97.45%
epoch 44, loss: 0.05, train 97.48%
epoch 44, loss: 0.16, train 97.50%
epoch 44, loss: 0.07, train 97.52%
epoch 44, loss: 0.12, train 97.50%
epoch 44, loss: 0.24, train 97.48%
epoch 44, loss: 0.04, train 97.50%
epoch 44, loss: 0.17, train 97.48%
epoch 44, loss: 0.07, train 97.50%
epoch 44, loss: 0.07, train 97.52%
epoch 44, loss: 0.42, train 97.36%
epoch 44, loss: 0.13, train 97.39%
epoch 44, loss: 0.17, train 97.41%
epoch 44, loss: 0.17, train 97.43%
epoch 44, loss: 0.10, train 97.46%
epoch 44, loss: 0.10, train 97.48%
epoch 44, loss: 0.14, train 97.46%
epoch 44, loss: 0.09, train 97.48%
epoch 44, loss: 0.13, train 97.46%
epoch 44, loss: 0.14, train 97.44%
epoch 44, loss: 0.23, train 97.46%
Epoch completed!
epoch 44, total signals 2400, average_loss_per_batch: 0.155504, train 97.46%
Validating
Val set size: 320, validation accuracy 81.25%
epoch 45, loss: 0.06, train 100.00%
epoch 45, loss: 0.16, train 97.50%
epoch 45, loss: 0.06, train 98.33%
epoch 45, loss: 0.07, train 98.75%
epoch 45, loss: 0.16, train 97.00%
epoch 45, loss: 0.10, train 97.50%
epoch 45, loss: 0.07, train 97.86%
epoch 45, loss: 0.13, train 97.50%
epoch 45, loss: 0.25, train 97.22%
epoch 45, loss: 0.06, train 97.50%
epoch 45, loss: 0.14, train 97.73%
epoch 45, loss: 0.12, train 97.50%
epoch 45, loss: 0.19, train 97.31%
epoch 45, loss: 0.15, train 97.50%
epoch 45, loss: 0.11, train 97.67%
epoch 45, loss: 0.13, train 97.81%
epoch 45, loss: 0.32, train 97.94%
epoch 45, loss: 0.16, train 97.78%
epoch 45, loss: 0.10, train 97.89%
epoch 45, loss: 0.11, train 98.00%
epoch 45, loss: 0.15, train 98.10%
epoch 45, loss: 0.15, train 98.18%
epoch 45, loss: 0.19, train 98.04%
epoch 45, loss: 0.10, train 98.12%
epoch 45, loss: 0.09, train 98.20%
epoch 45, loss: 0.28, train 98.27%
epoch 45, loss: 0.19, train 98.15%
epoch 45, loss: 0.07, train 98.21%
epoch 45, loss: 0.07, train 98.28%
epoch 45, loss: 0.08, train 98.33%
epoch 45, loss: 0.06, train 98.39%
epoch 45, loss: 0.12, train 98.44%
epoch 45, loss: 0.10, train 98.48%
epoch 45, loss: 0.12, train 98.53%
epoch 45, loss: 0.08, train 98.57%
epoch 45, loss: 0.11, train 98.47%
epoch 45, loss: 0.08, train 98.51%
epoch 45, loss: 0.10, train 98.55%
epoch 45, loss: 0.19, train 98.46%
epoch 45, loss: 0.06, train 98.50%
epoch 45, loss: 0.20, train 98.29%
epoch 45, loss: 0.09, train 98.33%
epoch 45, loss: 0.13, train 98.37%
epoch 45, loss: 0.17, train 98.18%
epoch 45, loss: 0.07, train 98.22%
epoch 45, loss: 0.18, train 98.26%
epoch 45, loss: 0.07, train 98.30%
epoch 45, loss: 0.36, train 98.12%
epoch 45, loss: 0.35, train 98.06%
epoch 45, loss: 0.07, train 98.10%
epoch 45, loss: 0.11, train 98.14%
epoch 45, loss: 0.10, train 98.17%
epoch 45, loss: 0.15, train 98.11%
epoch 45, loss: 0.04, train 98.15%
epoch 45, loss: 0.12, train 98.18%
epoch 45, loss: 0.11, train 98.21%
epoch 45, loss: 0.05, train 98.25%
epoch 45, loss: 0.11, train 98.28%
epoch 45, loss: 0.11, train 98.31%
epoch 45, loss: 0.29, train 98.17%
epoch 45, loss: 0.06, train 98.20%
epoch 45, loss: 0.13, train 98.15%
epoch 45, loss: 0.05, train 98.17%
epoch 45, loss: 0.12, train 98.20%
epoch 45, loss: 0.13, train 98.15%
epoch 45, loss: 0.08, train 98.18%
epoch 45, loss: 0.09, train 98.21%
epoch 45, loss: 0.14, train 98.16%
epoch 45, loss: 0.18, train 98.12%
epoch 45, loss: 0.10, train 98.14%
epoch 45, loss: 0.08, train 98.17%
epoch 45, loss: 0.08, train 98.19%
epoch 45, loss: 0.28, train 98.08%
epoch 45, loss: 0.20, train 98.04%
epoch 45, loss: 0.10, train 98.07%
epoch 45, loss: 0.11, train 98.03%
epoch 45, loss: 0.05, train 98.05%
epoch 45, loss: 0.44, train 97.95%
epoch 45, loss: 0.08, train 97.97%
epoch 45, loss: 0.30, train 98.00%
epoch 45, loss: 0.34, train 97.84%
epoch 45, loss: 0.21, train 97.74%
epoch 45, loss: 0.20, train 97.71%
epoch 45, loss: 0.57, train 97.50%
epoch 45, loss: 0.10, train 97.53%
epoch 45, loss: 0.08, train 97.56%
epoch 45, loss: 0.10, train 97.59%
epoch 45, loss: 0.08, train 97.61%
epoch 45, loss: 0.08, train 97.64%
epoch 45, loss: 0.34, train 97.61%
epoch 45, loss: 0.05, train 97.64%
epoch 45, loss: 0.23, train 97.66%
epoch 45, loss: 0.21, train 97.63%
epoch 45, loss: 0.42, train 97.55%
epoch 45, loss: 0.05, train 97.58%
epoch 45, loss: 0.14, train 97.60%
epoch 45, loss: 0.18, train 97.58%
epoch 45, loss: 0.13, train 97.60%
epoch 45, loss: 0.13, train 97.63%
epoch 45, loss: 0.09, train 97.65%
epoch 45, loss: 0.23, train 97.57%
epoch 45, loss: 0.48, train 97.55%
epoch 45, loss: 0.14, train 97.57%
epoch 45, loss: 0.11, train 97.60%
epoch 45, loss: 0.49, train 97.52%
epoch 45, loss: 0.14, train 97.55%
epoch 45, loss: 0.14, train 97.57%
epoch 45, loss: 0.30, train 97.45%
epoch 45, loss: 0.16, train 97.48%
epoch 45, loss: 0.13, train 97.50%
epoch 45, loss: 0.09, train 97.52%
epoch 45, loss: 0.16, train 97.50%
epoch 45, loss: 0.27, train 97.48%
epoch 45, loss: 0.13, train 97.46%
epoch 45, loss: 0.32, train 97.43%
epoch 45, loss: 0.10, train 97.46%
epoch 45, loss: 0.13, train 97.48%
epoch 45, loss: 0.09, train 97.50%
epoch 45, loss: 0.05, train 97.52%
epoch 45, loss: 0.16, train 97.54%
Epoch completed!
epoch 45, total signals 2400, average_loss_per_batch: 0.152023, train 97.54%
Validating
Val set size: 320, validation accuracy 81.56%
epoch 46, loss: 0.11, train 95.00%
epoch 46, loss: 0.17, train 97.50%
epoch 46, loss: 0.11, train 98.33%
epoch 46, loss: 0.12, train 98.75%
epoch 46, loss: 0.30, train 99.00%
epoch 46, loss: 0.06, train 99.17%
epoch 46, loss: 0.10, train 99.29%
epoch 46, loss: 0.49, train 96.25%
epoch 46, loss: 0.10, train 96.67%
epoch 46, loss: 0.15, train 97.00%
epoch 46, loss: 0.07, train 97.27%
epoch 46, loss: 0.09, train 97.50%
epoch 46, loss: 0.31, train 96.54%
epoch 46, loss: 0.48, train 96.07%
epoch 46, loss: 0.33, train 95.33%
epoch 46, loss: 0.05, train 95.62%
epoch 46, loss: 0.06, train 95.88%
epoch 46, loss: 0.14, train 96.11%
epoch 46, loss: 0.09, train 96.32%
epoch 46, loss: 0.09, train 96.50%
epoch 46, loss: 0.07, train 96.67%
epoch 46, loss: 0.11, train 96.82%
epoch 46, loss: 0.15, train 96.74%
epoch 46, loss: 0.12, train 96.67%
epoch 46, loss: 0.36, train 96.40%
epoch 46, loss: 0.19, train 96.35%
epoch 46, loss: 0.06, train 96.48%
epoch 46, loss: 0.49, train 96.25%
epoch 46, loss: 0.13, train 96.21%
epoch 46, loss: 0.10, train 96.33%
epoch 46, loss: 0.12, train 96.45%
epoch 46, loss: 0.15, train 96.41%
epoch 46, loss: 0.10, train 96.52%
epoch 46, loss: 0.13, train 96.62%
epoch 46, loss: 0.08, train 96.71%
epoch 46, loss: 0.10, train 96.81%
epoch 46, loss: 0.07, train 96.89%
epoch 46, loss: 0.14, train 96.84%
epoch 46, loss: 0.06, train 96.92%
epoch 46, loss: 0.26, train 97.00%
epoch 46, loss: 0.13, train 97.07%
epoch 46, loss: 0.11, train 97.14%
epoch 46, loss: 0.10, train 97.21%
epoch 46, loss: 0.31, train 97.05%
epoch 46, loss: 0.33, train 97.11%
epoch 46, loss: 0.09, train 97.17%
epoch 46, loss: 0.16, train 97.13%
epoch 46, loss: 0.18, train 97.08%
epoch 46, loss: 0.11, train 97.04%
epoch 46, loss: 0.30, train 96.80%
epoch 46, loss: 0.42, train 96.86%
epoch 46, loss: 0.18, train 96.92%
epoch 46, loss: 0.08, train 96.98%
epoch 46, loss: 0.13, train 96.94%
epoch 46, loss: 0.07, train 97.00%
epoch 46, loss: 0.13, train 97.05%
epoch 46, loss: 0.14, train 97.11%
epoch 46, loss: 0.14, train 97.16%
epoch 46, loss: 0.10, train 97.12%
epoch 46, loss: 0.07, train 97.17%
epoch 46, loss: 0.11, train 97.13%
epoch 46, loss: 0.30, train 97.02%
epoch 46, loss: 0.07, train 97.06%
epoch 46, loss: 0.40, train 97.11%
epoch 46, loss: 0.19, train 97.08%
epoch 46, loss: 0.16, train 97.05%
epoch 46, loss: 0.06, train 97.09%
epoch 46, loss: 0.06, train 97.13%
epoch 46, loss: 0.06, train 97.17%
epoch 46, loss: 0.43, train 97.14%
epoch 46, loss: 0.09, train 97.18%
epoch 46, loss: 0.24, train 97.08%
epoch 46, loss: 0.06, train 97.12%
epoch 46, loss: 0.18, train 97.16%
epoch 46, loss: 0.17, train 97.20%
epoch 46, loss: 0.08, train 97.24%
epoch 46, loss: 0.10, train 97.27%
epoch 46, loss: 0.21, train 97.18%
epoch 46, loss: 0.13, train 97.15%
epoch 46, loss: 0.05, train 97.19%
epoch 46, loss: 0.11, train 97.22%
epoch 46, loss: 0.10, train 97.26%
epoch 46, loss: 0.12, train 97.29%
epoch 46, loss: 0.12, train 97.32%
epoch 46, loss: 0.39, train 97.18%
epoch 46, loss: 0.16, train 97.15%
epoch 46, loss: 0.22, train 97.07%
epoch 46, loss: 0.05, train 97.10%
epoch 46, loss: 0.14, train 97.13%
epoch 46, loss: 0.10, train 97.17%
epoch 46, loss: 0.37, train 97.09%
epoch 46, loss: 0.19, train 97.07%
epoch 46, loss: 0.09, train 97.10%
epoch 46, loss: 0.25, train 97.02%
epoch 46, loss: 0.08, train 97.05%
epoch 46, loss: 0.06, train 97.08%
epoch 46, loss: 0.24, train 96.96%
epoch 46, loss: 0.13, train 96.99%
epoch 46, loss: 0.12, train 96.97%
epoch 46, loss: 0.11, train 97.00%
epoch 46, loss: 0.07, train 97.03%
epoch 46, loss: 0.09, train 97.06%
epoch 46, loss: 0.07, train 97.09%
epoch 46, loss: 0.59, train 96.97%
epoch 46, loss: 0.17, train 96.95%
epoch 46, loss: 0.20, train 96.93%
epoch 46, loss: 0.13, train 96.96%
epoch 46, loss: 0.17, train 96.99%
epoch 46, loss: 0.10, train 97.02%
epoch 46, loss: 0.13, train 97.00%
epoch 46, loss: 0.10, train 97.03%
epoch 46, loss: 0.33, train 96.96%
epoch 46, loss: 0.13, train 96.99%
epoch 46, loss: 0.14, train 97.02%
epoch 46, loss: 0.67, train 96.78%
epoch 46, loss: 0.07, train 96.81%
epoch 46, loss: 0.13, train 96.79%
epoch 46, loss: 0.26, train 96.78%
epoch 46, loss: 0.10, train 96.81%
epoch 46, loss: 0.20, train 96.83%
Epoch completed!
epoch 46, total signals 2400, average_loss_per_batch: 0.165282, train 96.83%
Validating
Val set size: 320, validation accuracy 82.81%
epoch 47, loss: 0.25, train 95.00%
epoch 47, loss: 0.25, train 92.50%
epoch 47, loss: 0.24, train 93.33%
epoch 47, loss: 0.06, train 95.00%
epoch 47, loss: 0.45, train 92.00%
epoch 47, loss: 0.05, train 93.33%
epoch 47, loss: 0.15, train 94.29%
epoch 47, loss: 0.06, train 95.00%
epoch 47, loss: 0.07, train 95.56%
epoch 47, loss: 0.14, train 96.00%
epoch 47, loss: 0.08, train 96.36%
epoch 47, loss: 0.34, train 96.67%
epoch 47, loss: 0.10, train 96.92%
epoch 47, loss: 0.12, train 97.14%
epoch 47, loss: 0.22, train 96.67%
epoch 47, loss: 0.45, train 96.56%
epoch 47, loss: 0.08, train 96.76%
epoch 47, loss: 0.08, train 96.94%
epoch 47, loss: 0.06, train 97.11%
epoch 47, loss: 0.06, train 97.25%
epoch 47, loss: 0.11, train 97.38%
epoch 47, loss: 0.34, train 97.50%
epoch 47, loss: 0.12, train 97.61%
epoch 47, loss: 0.17, train 97.50%
epoch 47, loss: 0.11, train 97.60%
epoch 47, loss: 0.41, train 97.12%
epoch 47, loss: 0.23, train 96.85%
epoch 47, loss: 0.56, train 96.25%
epoch 47, loss: 0.10, train 96.38%
epoch 47, loss: 0.60, train 95.67%
epoch 47, loss: 0.08, train 95.81%
epoch 47, loss: 0.17, train 95.94%
epoch 47, loss: 0.11, train 96.06%
epoch 47, loss: 0.22, train 96.03%
epoch 47, loss: 0.27, train 95.86%
epoch 47, loss: 0.35, train 95.56%
epoch 47, loss: 0.09, train 95.68%
epoch 47, loss: 0.13, train 95.79%
epoch 47, loss: 0.13, train 95.90%
epoch 47, loss: 0.39, train 95.88%
epoch 47, loss: 0.11, train 95.98%
epoch 47, loss: 0.17, train 96.07%
epoch 47, loss: 0.27, train 95.93%
epoch 47, loss: 0.06, train 96.02%
epoch 47, loss: 0.09, train 96.11%
epoch 47, loss: 0.10, train 96.09%
epoch 47, loss: 0.65, train 95.64%
epoch 47, loss: 0.20, train 95.62%
epoch 47, loss: 0.24, train 95.51%
epoch 47, loss: 0.09, train 95.60%
epoch 47, loss: 0.16, train 95.69%
epoch 47, loss: 0.08, train 95.77%
epoch 47, loss: 0.14, train 95.75%
epoch 47, loss: 0.08, train 95.83%
epoch 47, loss: 0.13, train 95.91%
epoch 47, loss: 0.26, train 95.71%
epoch 47, loss: 0.28, train 95.70%
epoch 47, loss: 0.10, train 95.78%
epoch 47, loss: 0.20, train 95.85%
epoch 47, loss: 0.07, train 95.92%
epoch 47, loss: 0.09, train 95.98%
epoch 47, loss: 0.19, train 95.97%
epoch 47, loss: 0.19, train 95.95%
epoch 47, loss: 0.32, train 95.86%
epoch 47, loss: 0.05, train 95.92%
epoch 47, loss: 0.13, train 95.98%
epoch 47, loss: 0.19, train 95.90%
epoch 47, loss: 0.16, train 95.88%
epoch 47, loss: 0.11, train 95.94%
epoch 47, loss: 0.10, train 96.00%
epoch 47, loss: 0.07, train 96.06%
epoch 47, loss: 0.11, train 96.04%
epoch 47, loss: 0.12, train 96.10%
epoch 47, loss: 0.07, train 96.15%
epoch 47, loss: 0.08, train 96.20%
epoch 47, loss: 0.06, train 96.25%
epoch 47, loss: 0.19, train 96.30%
epoch 47, loss: 0.15, train 96.35%
epoch 47, loss: 0.29, train 96.20%
epoch 47, loss: 0.06, train 96.25%
epoch 47, loss: 0.19, train 96.23%
epoch 47, loss: 0.18, train 96.22%
epoch 47, loss: 0.04, train 96.27%
epoch 47, loss: 0.08, train 96.31%
epoch 47, loss: 0.09, train 96.35%
epoch 47, loss: 0.22, train 96.34%
epoch 47, loss: 0.08, train 96.38%
epoch 47, loss: 0.37, train 96.36%
epoch 47, loss: 0.10, train 96.40%
epoch 47, loss: 0.12, train 96.44%
epoch 47, loss: 0.06, train 96.48%
epoch 47, loss: 0.22, train 96.47%
epoch 47, loss: 0.33, train 96.40%
epoch 47, loss: 0.40, train 96.17%
epoch 47, loss: 0.11, train 96.21%
epoch 47, loss: 0.22, train 96.20%
epoch 47, loss: 0.08, train 96.24%
epoch 47, loss: 0.09, train 96.28%
epoch 47, loss: 0.08, train 96.31%
epoch 47, loss: 0.12, train 96.35%
epoch 47, loss: 0.12, train 96.39%
epoch 47, loss: 0.05, train 96.42%
epoch 47, loss: 0.55, train 96.26%
epoch 47, loss: 0.08, train 96.30%
epoch 47, loss: 0.15, train 96.24%
epoch 47, loss: 0.08, train 96.27%
epoch 47, loss: 0.14, train 96.31%
epoch 47, loss: 0.40, train 96.20%
epoch 47, loss: 0.17, train 96.19%
epoch 47, loss: 0.17, train 96.18%
epoch 47, loss: 0.11, train 96.22%
epoch 47, loss: 0.15, train 96.25%
epoch 47, loss: 0.21, train 96.24%
epoch 47, loss: 0.16, train 96.23%
epoch 47, loss: 0.16, train 96.22%
epoch 47, loss: 0.18, train 96.16%
epoch 47, loss: 0.07, train 96.20%
epoch 47, loss: 0.17, train 96.23%
epoch 47, loss: 0.06, train 96.26%
epoch 47, loss: 0.34, train 96.21%
Epoch completed!
epoch 47, total signals 2400, average_loss_per_batch: 0.174293, train 96.21%
Validating
Val set size: 320, validation accuracy 82.50%
epoch 48, loss: 0.39, train 90.00%
epoch 48, loss: 0.08, train 95.00%
epoch 48, loss: 0.08, train 96.67%
epoch 48, loss: 0.08, train 97.50%
epoch 48, loss: 0.06, train 98.00%
epoch 48, loss: 0.10, train 98.33%
epoch 48, loss: 0.15, train 98.57%
epoch 48, loss: 0.08, train 98.75%
epoch 48, loss: 0.11, train 98.89%
epoch 48, loss: 0.39, train 98.50%
epoch 48, loss: 0.13, train 98.64%
epoch 48, loss: 0.13, train 98.75%
epoch 48, loss: 0.12, train 98.85%
epoch 48, loss: 0.06, train 98.93%
epoch 48, loss: 0.34, train 98.67%
epoch 48, loss: 0.10, train 98.75%
epoch 48, loss: 0.09, train 98.82%
epoch 48, loss: 0.06, train 98.89%
epoch 48, loss: 0.26, train 98.42%
epoch 48, loss: 0.06, train 98.50%
epoch 48, loss: 0.33, train 98.57%
epoch 48, loss: 0.16, train 98.41%
epoch 48, loss: 0.11, train 98.48%
epoch 48, loss: 0.13, train 98.33%
epoch 48, loss: 0.04, train 98.40%
epoch 48, loss: 0.06, train 98.46%
epoch 48, loss: 0.14, train 98.52%
epoch 48, loss: 0.32, train 98.57%
epoch 48, loss: 0.20, train 98.45%
epoch 48, loss: 0.17, train 98.50%
epoch 48, loss: 0.21, train 98.23%
epoch 48, loss: 0.13, train 98.28%
epoch 48, loss: 0.38, train 98.18%
epoch 48, loss: 0.08, train 98.24%
epoch 48, loss: 0.09, train 98.29%
epoch 48, loss: 0.17, train 98.19%
epoch 48, loss: 0.07, train 98.24%
epoch 48, loss: 0.21, train 98.16%
epoch 48, loss: 0.24, train 98.08%
epoch 48, loss: 0.07, train 98.12%
epoch 48, loss: 0.06, train 98.17%
epoch 48, loss: 0.15, train 98.21%
epoch 48, loss: 0.07, train 98.26%
epoch 48, loss: 0.43, train 98.07%
epoch 48, loss: 0.09, train 98.11%
epoch 48, loss: 0.10, train 98.15%
epoch 48, loss: 0.22, train 98.09%
epoch 48, loss: 0.08, train 98.12%
epoch 48, loss: 0.06, train 98.16%
epoch 48, loss: 0.08, train 98.20%
epoch 48, loss: 0.19, train 98.24%
epoch 48, loss: 0.12, train 98.27%
epoch 48, loss: 0.15, train 98.21%
epoch 48, loss: 0.10, train 98.24%
epoch 48, loss: 0.08, train 98.27%
epoch 48, loss: 0.41, train 98.04%
epoch 48, loss: 0.07, train 98.07%
epoch 48, loss: 0.13, train 98.02%
epoch 48, loss: 0.26, train 97.97%
epoch 48, loss: 0.28, train 97.83%
epoch 48, loss: 0.22, train 97.79%
epoch 48, loss: 0.10, train 97.82%
epoch 48, loss: 0.45, train 97.78%
epoch 48, loss: 0.11, train 97.81%
epoch 48, loss: 0.10, train 97.85%
epoch 48, loss: 0.14, train 97.88%
epoch 48, loss: 0.09, train 97.91%
epoch 48, loss: 0.12, train 97.94%
epoch 48, loss: 0.08, train 97.97%
epoch 48, loss: 0.10, train 97.93%
epoch 48, loss: 0.15, train 97.89%
epoch 48, loss: 0.09, train 97.92%
epoch 48, loss: 0.11, train 97.95%
epoch 48, loss: 0.04, train 97.97%
epoch 48, loss: 0.20, train 97.87%
epoch 48, loss: 0.10, train 97.83%
epoch 48, loss: 0.08, train 97.86%
epoch 48, loss: 0.26, train 97.82%
epoch 48, loss: 0.11, train 97.85%
epoch 48, loss: 0.07, train 97.88%
epoch 48, loss: 0.13, train 97.90%
epoch 48, loss: 0.15, train 97.93%
epoch 48, loss: 0.12, train 97.95%
epoch 48, loss: 0.18, train 97.92%
epoch 48, loss: 0.23, train 97.88%
epoch 48, loss: 0.09, train 97.91%
epoch 48, loss: 0.06, train 97.93%
epoch 48, loss: 0.21, train 97.90%
epoch 48, loss: 0.37, train 97.75%
epoch 48, loss: 0.40, train 97.67%
epoch 48, loss: 0.06, train 97.69%
epoch 48, loss: 0.25, train 97.72%
epoch 48, loss: 0.13, train 97.69%
epoch 48, loss: 0.15, train 97.66%
epoch 48, loss: 0.12, train 97.68%
epoch 48, loss: 0.12, train 97.66%
epoch 48, loss: 0.24, train 97.63%
epoch 48, loss: 0.08, train 97.65%
epoch 48, loss: 0.13, train 97.68%
epoch 48, loss: 0.17, train 97.65%
epoch 48, loss: 0.25, train 97.52%
epoch 48, loss: 0.15, train 97.45%
epoch 48, loss: 0.09, train 97.48%
epoch 48, loss: 0.23, train 97.36%
epoch 48, loss: 0.10, train 97.38%
epoch 48, loss: 0.10, train 97.41%
epoch 48, loss: 0.09, train 97.43%
epoch 48, loss: 0.07, train 97.45%
epoch 48, loss: 0.04, train 97.48%
epoch 48, loss: 0.19, train 97.45%
epoch 48, loss: 0.12, train 97.48%
epoch 48, loss: 0.12, train 97.46%
epoch 48, loss: 0.16, train 97.43%
epoch 48, loss: 0.12, train 97.46%
epoch 48, loss: 0.11, train 97.48%
epoch 48, loss: 0.09, train 97.50%
epoch 48, loss: 0.19, train 97.44%
epoch 48, loss: 0.29, train 97.46%
epoch 48, loss: 0.11, train 97.44%
epoch 48, loss: 0.57, train 97.29%
Epoch completed!
epoch 48, total signals 2400, average_loss_per_batch: 0.155020, train 97.29%
Validating
Val set size: 320, validation accuracy 81.88%
epoch 49, loss: 0.07, train 100.00%
epoch 49, loss: 0.15, train 100.00%
epoch 49, loss: 0.13, train 100.00%
epoch 49, loss: 0.16, train 100.00%
epoch 49, loss: 0.05, train 100.00%
epoch 49, loss: 0.07, train 100.00%
epoch 49, loss: 0.08, train 100.00%
epoch 49, loss: 0.07, train 100.00%
epoch 49, loss: 0.04, train 100.00%
epoch 49, loss: 0.21, train 98.50%
epoch 49, loss: 0.20, train 98.64%
epoch 49, loss: 0.21, train 97.92%
epoch 49, loss: 0.22, train 97.69%
epoch 49, loss: 0.49, train 97.14%
epoch 49, loss: 0.10, train 97.33%
epoch 49, loss: 0.35, train 97.50%
epoch 49, loss: 0.14, train 97.65%
epoch 49, loss: 0.11, train 97.50%
epoch 49, loss: 0.09, train 97.63%
epoch 49, loss: 0.10, train 97.75%
epoch 49, loss: 0.22, train 97.62%
epoch 49, loss: 0.07, train 97.73%
epoch 49, loss: 0.09, train 97.83%
epoch 49, loss: 0.69, train 96.88%
epoch 49, loss: 0.06, train 97.00%
epoch 49, loss: 0.60, train 96.35%
epoch 49, loss: 0.26, train 96.30%
epoch 49, loss: 0.39, train 96.07%
epoch 49, loss: 0.13, train 96.03%
epoch 49, loss: 0.13, train 96.17%
epoch 49, loss: 0.06, train 96.29%
epoch 49, loss: 0.05, train 96.41%
epoch 49, loss: 0.10, train 96.52%
epoch 49, loss: 0.12, train 96.62%
epoch 49, loss: 0.26, train 96.43%
epoch 49, loss: 0.31, train 96.53%
epoch 49, loss: 0.39, train 96.49%
epoch 49, loss: 0.06, train 96.58%
epoch 49, loss: 0.16, train 96.54%
epoch 49, loss: 0.13, train 96.50%
epoch 49, loss: 0.07, train 96.59%
epoch 49, loss: 0.21, train 96.55%
epoch 49, loss: 0.09, train 96.63%
epoch 49, loss: 0.08, train 96.70%
epoch 49, loss: 0.12, train 96.67%
epoch 49, loss: 0.07, train 96.74%
epoch 49, loss: 0.09, train 96.81%
epoch 49, loss: 1.04, train 96.25%
epoch 49, loss: 0.04, train 96.33%
epoch 49, loss: 0.09, train 96.30%
epoch 49, loss: 0.08, train 96.37%
epoch 49, loss: 0.42, train 96.25%
epoch 49, loss: 0.04, train 96.32%
epoch 49, loss: 0.80, train 96.02%
epoch 49, loss: 0.10, train 96.09%
epoch 49, loss: 0.08, train 96.16%
epoch 49, loss: 0.15, train 96.23%
epoch 49, loss: 0.10, train 96.29%
epoch 49, loss: 0.16, train 96.19%
epoch 49, loss: 0.15, train 96.17%
epoch 49, loss: 0.10, train 96.23%
epoch 49, loss: 0.09, train 96.29%
epoch 49, loss: 0.18, train 96.27%
epoch 49, loss: 0.13, train 96.33%
epoch 49, loss: 0.10, train 96.38%
epoch 49, loss: 0.04, train 96.44%
epoch 49, loss: 0.25, train 96.42%
epoch 49, loss: 0.46, train 96.40%
epoch 49, loss: 0.08, train 96.45%
epoch 49, loss: 0.04, train 96.50%
epoch 49, loss: 0.06, train 96.55%
epoch 49, loss: 0.71, train 96.18%
epoch 49, loss: 0.11, train 96.23%
epoch 49, loss: 0.17, train 96.28%
epoch 49, loss: 0.07, train 96.27%
epoch 49, loss: 0.09, train 96.32%
epoch 49, loss: 0.08, train 96.36%
epoch 49, loss: 0.38, train 96.28%
epoch 49, loss: 0.61, train 96.14%
epoch 49, loss: 0.05, train 96.19%
epoch 49, loss: 0.13, train 96.23%
epoch 49, loss: 0.09, train 96.28%
epoch 49, loss: 0.07, train 96.33%
epoch 49, loss: 0.14, train 96.37%
epoch 49, loss: 0.30, train 96.41%
epoch 49, loss: 0.16, train 96.40%
epoch 49, loss: 0.13, train 96.38%
epoch 49, loss: 0.14, train 96.42%
epoch 49, loss: 0.13, train 96.46%
epoch 49, loss: 0.24, train 96.39%
epoch 49, loss: 0.06, train 96.43%
epoch 49, loss: 0.40, train 96.41%
epoch 49, loss: 0.16, train 96.40%
epoch 49, loss: 0.09, train 96.44%
epoch 49, loss: 0.17, train 96.37%
epoch 49, loss: 0.16, train 96.41%
epoch 49, loss: 0.07, train 96.44%
epoch 49, loss: 0.36, train 96.48%
epoch 49, loss: 0.05, train 96.52%
epoch 49, loss: 0.43, train 96.45%
epoch 49, loss: 0.08, train 96.49%
epoch 49, loss: 0.18, train 96.47%
epoch 49, loss: 0.38, train 96.50%
epoch 49, loss: 0.13, train 96.49%
epoch 49, loss: 0.16, train 96.48%
epoch 49, loss: 0.16, train 96.46%
epoch 49, loss: 0.23, train 96.45%
epoch 49, loss: 0.16, train 96.44%
epoch 49, loss: 0.23, train 96.42%
epoch 49, loss: 0.13, train 96.45%
epoch 49, loss: 0.11, train 96.49%
epoch 49, loss: 0.87, train 96.38%
epoch 49, loss: 0.10, train 96.42%
epoch 49, loss: 0.17, train 96.45%
epoch 49, loss: 0.22, train 96.43%
epoch 49, loss: 0.04, train 96.47%
epoch 49, loss: 0.32, train 96.41%
epoch 49, loss: 0.07, train 96.44%
epoch 49, loss: 0.07, train 96.47%
epoch 49, loss: 0.10, train 96.50%
Epoch completed!
epoch 49, total signals 2400, average_loss_per_batch: 0.186999, train 96.50%
Validating
Val set size: 320, validation accuracy 80.00%
Training Completed!
Testing
en de es fr ko zh sv no
[[37  0  0  0  0  1  0  2]
 [ 1 35  0  1  0  0  1  2]
 [ 2  0 32  1  0  0  4  1]
 [ 2  1  0 30  0  2  2  3]
 [ 2  1  0  1 30  2  2  2]
 [ 4  1  0  1  3 30  0  1]
 [ 3  3  1  1  1  1 22  8]
 [ 2  0  2  4  0  0 14 18]]
Test set size: 320, Test accuracy 73.12%
